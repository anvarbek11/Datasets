{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPMmgpLj6BPl1Bdq2DLxexK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anvarbek11/Datasets/blob/main/ExamPrep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnERXuyj0tAN",
        "outputId": "deae4757-4229-4800-ac79-9d5c382b7cf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is your name?fsf\n",
            "What is your email address?fsaf\n",
            "YOur name:fsf\n",
            "Your email address:fsaf\n"
          ]
        }
      ],
      "source": [
        "#1\n",
        "name = input(\"What is your name?\")\n",
        "email = input(\"What is your email address?\")\n",
        "print(\"YOur name:\" + name)\n",
        "print(\"Your email address:\"+email)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2\n",
        "number = input(\"Enter a number:\")\n",
        "number = float(number)\n",
        "square = number**2\n",
        "print(f\"Square is: {square}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_nPVYBF08Kd",
        "outputId": "e3d40fbd-1c2b-4769-d36f-99d7d78fbb4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a number:2\n",
            "Square is: 4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3\n",
        "a = int(input(\"Enter length of rectangle: \"))\n",
        "b = int(input(\"Enter height of rectangle: \"))\n",
        "area = a*b\n",
        "print(f\" Area is {area}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25UtZOQC1eP0",
        "outputId": "ff1d34f1-5426-4ed2-bb0a-0f8a5a52c3c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter length of rectangle: 2\n",
            "Enter height of rectangle: 2\n",
            " Area is 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4\n",
        "print(7*(2-5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z4_W3sw81wl1",
        "outputId": "378c37d4-afb9-4737-f87b-39bc6dc08cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5\n",
        "integer = 197\n",
        "last_dgt = 197%10\n",
        "print(last_dgt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YhAfcDb2CUE",
        "outputId": "cadcf8a7-5a11-4b1b-d91c-5709f28e8e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6\n",
        "speed1 = 35\n",
        "speed2 = 3.6*speed1\n",
        "print(f\"{speed2}-km/h\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu_2eEja2PVl",
        "outputId": "11c0339b-8e26-459f-cdb0-e34b1e4274d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126.0-km/h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7\n",
        "def add_hours(time_str, hours_to_add):\n",
        "    hour, minute = map(int, time_str.split(':'))\n",
        "    hour = (hour + hours_to_add) % 24\n",
        "    return '{:02}:{:02}'.format(hour, minute)\n",
        "\n",
        "# Example usage:\n",
        "current_time = '17:15'\n",
        "new_time = add_hours(current_time, 2)\n",
        "print(\"New time after adding 2 hours:\", new_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1bZg2en2yHj",
        "outputId": "834dc3cd-7d50-4e49-cdcb-ef18afa011e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New time after adding 2 hours: 19:15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#8\n",
        "user = int(input(\"Enter the amount of money:  \"))\n",
        "toy_cars = 5\n",
        "how_many_cars = user//toy_cars\n",
        "how_much_money = toy_cars - user%toy_cars\n",
        "print(f\"how_manu_cars:{how_many_cars}\")\n",
        "print(f\"how_manu_cars:{how_much_money}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDS5UkQi4knV",
        "outputId": "c057fd50-7cc9-4e16-e7ec-b5c16c01cd71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the amount of money:  7\n",
            "how_manu_cars:1\n",
            "how_manu_cars:3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#9\n",
        "for x in range(10,0,-2):\n",
        "  print(\"squared\",x,\"is\",x**2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlXZqEHt6RDO",
        "outputId": "249b66de-be1d-431c-8a52-c33b0b66c385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "squared 10 is 100\n",
            "squared 8 is 64\n",
            "squared 6 is 36\n",
            "squared 4 is 16\n",
            "squared 2 is 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#10\n",
        "for x in range(1,100,2):\n",
        "  print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdrpFGhD7Dml",
        "outputId": "97af4dd9-caa4-4f3a-a929-c8bbd0e5865e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "3\n",
            "5\n",
            "7\n",
            "9\n",
            "11\n",
            "13\n",
            "15\n",
            "17\n",
            "19\n",
            "21\n",
            "23\n",
            "25\n",
            "27\n",
            "29\n",
            "31\n",
            "33\n",
            "35\n",
            "37\n",
            "39\n",
            "41\n",
            "43\n",
            "45\n",
            "47\n",
            "49\n",
            "51\n",
            "53\n",
            "55\n",
            "57\n",
            "59\n",
            "61\n",
            "63\n",
            "65\n",
            "67\n",
            "69\n",
            "71\n",
            "73\n",
            "75\n",
            "77\n",
            "79\n",
            "81\n",
            "83\n",
            "85\n",
            "87\n",
            "89\n",
            "91\n",
            "93\n",
            "95\n",
            "97\n",
            "99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#11\n",
        "for x in range(100,0,-2):\n",
        "  print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyW8-iMD7ape",
        "outputId": "bedaffa9-f30b-478b-83c9-0782a5115b6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "98\n",
            "96\n",
            "94\n",
            "92\n",
            "90\n",
            "88\n",
            "86\n",
            "84\n",
            "82\n",
            "80\n",
            "78\n",
            "76\n",
            "74\n",
            "72\n",
            "70\n",
            "68\n",
            "66\n",
            "64\n",
            "62\n",
            "60\n",
            "58\n",
            "56\n",
            "54\n",
            "52\n",
            "50\n",
            "48\n",
            "46\n",
            "44\n",
            "42\n",
            "40\n",
            "38\n",
            "36\n",
            "34\n",
            "32\n",
            "30\n",
            "28\n",
            "26\n",
            "24\n",
            "22\n",
            "20\n",
            "18\n",
            "16\n",
            "14\n",
            "12\n",
            "10\n",
            "8\n",
            "6\n",
            "4\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#12\n",
        "counter = 1\n",
        "while counter<100:\n",
        "  print(counter)\n",
        "  counter = counter+2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C78-_HRh7ute",
        "outputId": "dc2342bf-a721-4c95-9699-1da8dfe6d688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "3\n",
            "5\n",
            "7\n",
            "9\n",
            "11\n",
            "13\n",
            "15\n",
            "17\n",
            "19\n",
            "21\n",
            "23\n",
            "25\n",
            "27\n",
            "29\n",
            "31\n",
            "33\n",
            "35\n",
            "37\n",
            "39\n",
            "41\n",
            "43\n",
            "45\n",
            "47\n",
            "49\n",
            "51\n",
            "53\n",
            "55\n",
            "57\n",
            "59\n",
            "61\n",
            "63\n",
            "65\n",
            "67\n",
            "69\n",
            "71\n",
            "73\n",
            "75\n",
            "77\n",
            "79\n",
            "81\n",
            "83\n",
            "85\n",
            "87\n",
            "89\n",
            "91\n",
            "93\n",
            "95\n",
            "97\n",
            "99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#12\n",
        "for n in range(101):\n",
        "  if n%2!=0:\n",
        "    print(f\"{n} is odd\")\n",
        "for n in range(100,0,-1):\n",
        "  if n%2==0:\n",
        "    print(f\"{n} is even\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGedCpfk8U6u",
        "outputId": "1b3be0d7-c0d8-4a21-b265-5b70bd8eda95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 is odd\n",
            "3 is odd\n",
            "5 is odd\n",
            "7 is odd\n",
            "9 is odd\n",
            "11 is odd\n",
            "13 is odd\n",
            "15 is odd\n",
            "17 is odd\n",
            "19 is odd\n",
            "21 is odd\n",
            "23 is odd\n",
            "25 is odd\n",
            "27 is odd\n",
            "29 is odd\n",
            "31 is odd\n",
            "33 is odd\n",
            "35 is odd\n",
            "37 is odd\n",
            "39 is odd\n",
            "41 is odd\n",
            "43 is odd\n",
            "45 is odd\n",
            "47 is odd\n",
            "49 is odd\n",
            "51 is odd\n",
            "53 is odd\n",
            "55 is odd\n",
            "57 is odd\n",
            "59 is odd\n",
            "61 is odd\n",
            "63 is odd\n",
            "65 is odd\n",
            "67 is odd\n",
            "69 is odd\n",
            "71 is odd\n",
            "73 is odd\n",
            "75 is odd\n",
            "77 is odd\n",
            "79 is odd\n",
            "81 is odd\n",
            "83 is odd\n",
            "85 is odd\n",
            "87 is odd\n",
            "89 is odd\n",
            "91 is odd\n",
            "93 is odd\n",
            "95 is odd\n",
            "97 is odd\n",
            "99 is odd\n",
            "100 is even\n",
            "98 is even\n",
            "96 is even\n",
            "94 is even\n",
            "92 is even\n",
            "90 is even\n",
            "88 is even\n",
            "86 is even\n",
            "84 is even\n",
            "82 is even\n",
            "80 is even\n",
            "78 is even\n",
            "76 is even\n",
            "74 is even\n",
            "72 is even\n",
            "70 is even\n",
            "68 is even\n",
            "66 is even\n",
            "64 is even\n",
            "62 is even\n",
            "60 is even\n",
            "58 is even\n",
            "56 is even\n",
            "54 is even\n",
            "52 is even\n",
            "50 is even\n",
            "48 is even\n",
            "46 is even\n",
            "44 is even\n",
            "42 is even\n",
            "40 is even\n",
            "38 is even\n",
            "36 is even\n",
            "34 is even\n",
            "32 is even\n",
            "30 is even\n",
            "28 is even\n",
            "26 is even\n",
            "24 is even\n",
            "22 is even\n",
            "20 is even\n",
            "18 is even\n",
            "16 is even\n",
            "14 is even\n",
            "12 is even\n",
            "10 is even\n",
            "8 is even\n",
            "6 is even\n",
            "4 is even\n",
            "2 is even\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#13\n",
        "for x in range(1,11):\n",
        "  if x%2 == 0:\n",
        "    print(x,\"is even\")\n",
        "  else:\n",
        "    print(x,\"is odd\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pInapq2u81g_",
        "outputId": "5c4d38b2-5748-49cb-9325-1d6b44c4beb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 is odd\n",
            "2 is even\n",
            "3 is odd\n",
            "4 is even\n",
            "5 is odd\n",
            "6 is even\n",
            "7 is odd\n",
            "8 is even\n",
            "9 is odd\n",
            "10 is even\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. based on the previous example program, write a Python program that counts how\n",
        "many digits 1 or 2 are present in a given integer, e.g., 20201918"
      ],
      "metadata": {
        "id": "TYCjuzCLR5EI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Assigments2\n",
        "#14\n",
        "integer = 20201918\n",
        "counts = 0\n",
        "while integer>0:\n",
        "  digit = integer%10\n",
        "  if digit==1 or digit==2:\n",
        "    counts += 1\n",
        "  integer=integer//10\n",
        "print(counts)\n"
      ],
      "metadata": {
        "id": "FA3fypGo9cGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3abda2e-bcd0-453b-fb31-7e6a0a20881b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. assignment: write a Python program to find the minimum of two integers read from\n",
        "user input"
      ],
      "metadata": {
        "id": "zTj4JkAmR1Yk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#15\n",
        "a = int(input(\"Enter first number: \"))\n",
        "b=int(input(\"Enter second number: \"))\n",
        "if a>b:\n",
        "  print(\"secon number is bigger\",a)\n",
        "else:\n",
        "  print(\"first number is  bigger\",b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sh6HdV9JgWV",
        "outputId": "e09a21ce-6b8c-4587-f3e7-5d2c8bf6ed12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter first number: 2\n",
            "Enter second number: 3\n",
            "b is bigger 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. assignment: write a Python program to find the largest of three given integers"
      ],
      "metadata": {
        "id": "gMRtLXCpRtjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#16\n",
        "a = int(input(\"Enter first number: \"))\n",
        "b=int(input(\"Enter second number: \"))\n",
        "c=int(input(\"Enter third number: \"))\n",
        "if a>b and a>c:\n",
        "  print(\"secon number is bigger\",a)\n",
        "elif b>a and b>c:\n",
        "  print(\"Second number is bigger \",b)\n",
        "else:\n",
        "  print(\"Third number is  bigger\",c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_pUQaXfLz-t",
        "outputId": "2b831a50-861b-45c8-aaa7-cd215d295690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter first number: 1\n",
            "Enter second number: 2\n",
            "Enter third number: 3\n",
            "Third number is  bigger 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "assignment: write a Python program to determine whether a given number is even or\n",
        "odd"
      ],
      "metadata": {
        "id": "rP5rup2rRqLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#17\n",
        "given_number = int(input(\"Enter an integer number: \"))\n",
        "if given_number%2 == 0:\n",
        "  print(\"This is even number\")\n",
        "else:\n",
        "  print(\"This is odd number\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRnc3XJyMS2m",
        "outputId": "96236a76-17cf-4fe9-a4bf-57877500b1a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter an integer number: 22\n",
            "This is even number\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "assignment: write a Python program to determine whether a given number is even or\n",
        "odd"
      ],
      "metadata": {
        "id": "wuZtTTdlRjTN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#18\n",
        "num1 = 0\n",
        "num2 = 1\n",
        "number = int(input(\"Enter the number of times : \"))\n",
        "print(num1)\n",
        "while number>1:\n",
        "  print(num2)\n",
        "  nth = num1+num2\n",
        "  num1=num2\n",
        "  num2=nth\n",
        "  number -=1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0nXLASkNJcO",
        "outputId": "d6d23772-eb44-499c-8eba-eed1b3e9123a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the number of times : 5\n",
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "assignment: write a Python program to compute the Fibonacci sequence"
      ],
      "metadata": {
        "id": "3gNS9N5TRbcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fibonacci(n):\n",
        "    fib_sequence = [0, 1]  # Initialize Fibonacci sequence with the first two terms\n",
        "    while len(fib_sequence) < n:\n",
        "        next_term = fib_sequence[-1] + fib_sequence[-2]  # Compute the next term\n",
        "        fib_sequence.append(next_term)  # Add the next term to the sequence\n",
        "    return fib_sequence\n",
        "\n",
        "# Example usage:\n",
        "num_terms = int(input(\"Enter the number of terms for the Fibonacci sequence: \"))\n",
        "fib_sequence = fibonacci(num_terms)\n",
        "print(\"Fibonacci sequence:\")\n",
        "print(fib_sequence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgewbnzZPWkv",
        "outputId": "bc48981b-9692-4d7b-884b-a546dad86381"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the number of terms for the Fibonacci sequence: 5\n",
            "Fibonacci sequence:\n",
            "[0, 1, 1, 2, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. print the ( ) Pythagorean table for the addition operation: in this setting the value\n",
        "of each cell of index r,c (row and col, respectively) is the sum of r and c."
      ],
      "metadata": {
        "id": "A9mS1GEKR-gN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_pythagorean_table(n):\n",
        "    for i in range(1, n+1):\n",
        "        row = []\n",
        "        for j in range(1, n+1):\n",
        "            row.append(i + j)\n",
        "        print(row)\n",
        "\n",
        "# Example usage:\n",
        "size = int(input(\"Enter the size of the Pythagorean table: \"))\n",
        "print(\"Pythagorean Table:\")\n",
        "print_pythagorean_table(size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zs8e0RFJQLTe",
        "outputId": "bb746b77-276f-423f-d7cb-13d68a041e9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the size of the Pythagorean table: 5\n",
            "Pythagorean Table:\n",
            "[2, 3, 4, 5, 6]\n",
            "[3, 4, 5, 6, 7]\n",
            "[4, 5, 6, 7, 8]\n",
            "[5, 6, 7, 8, 9]\n",
            "[6, 7, 8, 9, 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_pythagorean_table(n):\n",
        "  for i in range(1,n+1):\n",
        "    row = []\n",
        "    for j in range(1,n+1):\n",
        "      row.append(i*j)\n",
        "    print(row)\n",
        "size = int(input(\"enter the size of the Pythagorean table:\"))\n",
        "print_pythagorean_table(size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ6Wtn7uSxJo",
        "outputId": "972cca81-71dd-4006-a505-e27270662bc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter the size of the Pythagorean table:5\n",
            "[1, 2, 3, 4, 5]\n",
            "[2, 4, 6, 8, 10]\n",
            "[3, 6, 9, 12, 15]\n",
            "[4, 8, 12, 16, 20]\n",
            "[5, 10, 15, 20, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. print the same matrix as in ex 3, but only even numbers should be printed; alignment\n",
        "should be preserved, and instead of odd numbers simply print a dash '-' character"
      ],
      "metadata": {
        "id": "Qy5hWDmCY_EQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_even_or_dash(number):\n",
        "  for num in numbers:\n",
        "    if num % 2 == 0:\n",
        "        print(num)\n",
        "    else:\n",
        "        print('-')\n",
        "\n",
        "# Example usage:\n",
        "print(\"Even or Dash:\")\n",
        "numbers = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "print_even_or_dash(numbers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9jUWNmgIXFWB",
        "outputId": "5293edda-18dd-47d5-aa7c-fd7fe21598db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Even or Dash:\n",
            "-\n",
            "2\n",
            "-\n",
            "4\n",
            "-\n",
            "6\n",
            "-\n",
            "8\n",
            "-\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. trip planner. consider a list of months m = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\",\n",
        "\"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]; write a program that asks the user\n",
        "to type an integer in [1,12] as the leaving date, and then another integer\n",
        "corresponding to the length (in months). the program must return the month in which\n",
        "the user is expected to come back."
      ],
      "metadata": {
        "id": "MoAZxJVlZI35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
        "leaving_data = int(input(\"Enter your leaving data [1,12]>>> \"))\n",
        "length_month = int(input(\"Enter length of the stay>>> \"))\n",
        "print(m[(leaving_data+length_month-1)%12])\n"
      ],
      "metadata": {
        "id": "GNWPVXLcYZjC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aca33c1a-a8e6-4280-b482-a52906d38da4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your leaving data [1,12]>>> 24\n",
            "Enter length of the stay>>> 12\n",
            "Dec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def trip_planner(leaving_date, trip_length):\n",
        "    # List of months\n",
        "    months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
        "\n",
        "    # Calculate the index of the return month\n",
        "    return_month_index = (leaving_date + trip_length - 1) % 12\n",
        "\n",
        "    # Get the name of the return month\n",
        "    return_month = months[return_month_index]\n",
        "\n",
        "    return return_month\n",
        "\n",
        "# Main function\n",
        "def main():\n",
        "    # Ask the user for leaving date\n",
        "    leaving_date = int(input(\"Enter the leaving month (1-12): \"))\n",
        "    while leaving_date < 1 or leaving_date > 12:\n",
        "        leaving_date = int(input(\"Invalid input. Please enter a number between 1 and 12: \"))\n",
        "\n",
        "    # Ask the user for trip length\n",
        "    trip_length = int(input(\"Enter the length of the trip (in months): \"))\n",
        "\n",
        "    # Calculate the return month\n",
        "    return_month = trip_planner(leaving_date, trip_length)\n",
        "\n",
        "    # Print the return month\n",
        "    print(\"You are expected to come back in\", return_month)\n",
        "\n",
        "# Call the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZgAh-g5qG9N",
        "outputId": "e3a57e3d-dab4-41f5-e175-c7824afff1b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the leaving month (1-12): 2\n",
            "Enter the length of the trip (in months): 2\n",
            "You are expected to come back in Apr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.a perfect square is a number that can be expressed as the product of an integer by\n",
        "itself: e.g.,9, 16, 25 are perfect squares. write a program that computes all perfect\n",
        "squares 10000."
      ],
      "metadata": {
        "id": "fAptKGb1taBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "square = 1\n",
        "num=1\n",
        "while square<10000:\n",
        "  square = num**2\n",
        "  print(square)\n",
        "  num +=1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lmjS4g5s2I2",
        "outputId": "8d7e5545-f266-4943-b01a-4189c2e7693d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "4\n",
            "9\n",
            "16\n",
            "25\n",
            "36\n",
            "49\n",
            "64\n",
            "81\n",
            "100\n",
            "121\n",
            "144\n",
            "169\n",
            "196\n",
            "225\n",
            "256\n",
            "289\n",
            "324\n",
            "361\n",
            "400\n",
            "441\n",
            "484\n",
            "529\n",
            "576\n",
            "625\n",
            "676\n",
            "729\n",
            "784\n",
            "841\n",
            "900\n",
            "961\n",
            "1024\n",
            "1089\n",
            "1156\n",
            "1225\n",
            "1296\n",
            "1369\n",
            "1444\n",
            "1521\n",
            "1600\n",
            "1681\n",
            "1764\n",
            "1849\n",
            "1936\n",
            "2025\n",
            "2116\n",
            "2209\n",
            "2304\n",
            "2401\n",
            "2500\n",
            "2601\n",
            "2704\n",
            "2809\n",
            "2916\n",
            "3025\n",
            "3136\n",
            "3249\n",
            "3364\n",
            "3481\n",
            "3600\n",
            "3721\n",
            "3844\n",
            "3969\n",
            "4096\n",
            "4225\n",
            "4356\n",
            "4489\n",
            "4624\n",
            "4761\n",
            "4900\n",
            "5041\n",
            "5184\n",
            "5329\n",
            "5476\n",
            "5625\n",
            "5776\n",
            "5929\n",
            "6084\n",
            "6241\n",
            "6400\n",
            "6561\n",
            "6724\n",
            "6889\n",
            "7056\n",
            "7225\n",
            "7396\n",
            "7569\n",
            "7744\n",
            "7921\n",
            "8100\n",
            "8281\n",
            "8464\n",
            "8649\n",
            "8836\n",
            "9025\n",
            "9216\n",
            "9409\n",
            "9604\n",
            "9801\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_perfect_squares():\n",
        "    perfect_squares = []\n",
        "    for i in range(1, 101):\n",
        "        square = i * i\n",
        "        if square <= 10000:\n",
        "            perfect_squares.append(square)\n",
        "        else:\n",
        "            break\n",
        "    return perfect_squares\n",
        "\n",
        "# Call the function to compute perfect squares\n",
        "perfect_squares = compute_perfect_squares()\n",
        "\n",
        "# Print the perfect squares\n",
        "print(\"Perfect squares up to 10000:\")\n",
        "print(perfect_squares)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_6HNwlZufdX",
        "outputId": "c299d965-6905-48d3-876a-cee84a866502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perfect squares up to 10000:\n",
            "[1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, 256, 289, 324, 361, 400, 441, 484, 529, 576, 625, 676, 729, 784, 841, 900, 961, 1024, 1089, 1156, 1225, 1296, 1369, 1444, 1521, 1600, 1681, 1764, 1849, 1936, 2025, 2116, 2209, 2304, 2401, 2500, 2601, 2704, 2809, 2916, 3025, 3136, 3249, 3364, 3481, 3600, 3721, 3844, 3969, 4096, 4225, 4356, 4489, 4624, 4761, 4900, 5041, 5184, 5329, 5476, 5625, 5776, 5929, 6084, 6241, 6400, 6561, 6724, 6889, 7056, 7225, 7396, 7569, 7744, 7921, 8100, 8281, 8464, 8649, 8836, 9025, 9216, 9409, 9604, 9801, 10000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.modify the previous program to count how many perfect squares were found, and\n",
        "verify this amounts to 100 integers."
      ],
      "metadata": {
        "id": "0vgJs_mKwHqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_square = []\n",
        "counts = 0\n",
        "for i in range (1,101):\n",
        "  square = i**2\n",
        "  if square<=10000:\n",
        "    final_square.append(square)\n",
        "    counts +=1\n",
        "print(final_square)\n",
        "print(f\"Number of perfect squares: {counts}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2j8rh5HwAa_",
        "outputId": "6e5e8f9a-d420-4885-9346-f305c4c9ded3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144, 169, 196, 225, 256, 289, 324, 361, 400, 441, 484, 529, 576, 625, 676, 729, 784, 841, 900, 961, 1024, 1089, 1156, 1225, 1296, 1369, 1444, 1521, 1600, 1681, 1764, 1849, 1936, 2025, 2116, 2209, 2304, 2401, 2500, 2601, 2704, 2809, 2916, 3025, 3136, 3249, 3364, 3481, 3600, 3721, 3844, 3969, 4096, 4225, 4356, 4489, 4624, 4761, 4900, 5041, 5184, 5329, 5476, 5625, 5776, 5929, 6084, 6241, 6400, 6561, 6724, 6889, 7056, 7225, 7396, 7569, 7744, 7921, 8100, 8281, 8464, 8649, 8836, 9025, 9216, 9409, 9604, 9801, 10000]\n",
            "Number of perfect squares: 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.write a program scanning al integers in [1, 10000] and, for each figure, prints whether\n",
        "it is a perfect square or not."
      ],
      "metadata": {
        "id": "ABbUXhJ6xV9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from math import sqrt\n",
        "\n",
        "for i in range(1,10001):\n",
        "  if int(i**0.5)**2==i:\n",
        "    print(f\"{i} is perfect square\")\n",
        "  else:\n",
        "    print(f\"{i} is not perfect square\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9-kMEXZwz_o",
        "outputId": "493e4b17-5b77-4a4d-d86e-e32663e56b0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "5001 is not perfect square\n",
            "5002 is not perfect square\n",
            "5003 is not perfect square\n",
            "5004 is not perfect square\n",
            "5005 is not perfect square\n",
            "5006 is not perfect square\n",
            "5007 is not perfect square\n",
            "5008 is not perfect square\n",
            "5009 is not perfect square\n",
            "5010 is not perfect square\n",
            "5011 is not perfect square\n",
            "5012 is not perfect square\n",
            "5013 is not perfect square\n",
            "5014 is not perfect square\n",
            "5015 is not perfect square\n",
            "5016 is not perfect square\n",
            "5017 is not perfect square\n",
            "5018 is not perfect square\n",
            "5019 is not perfect square\n",
            "5020 is not perfect square\n",
            "5021 is not perfect square\n",
            "5022 is not perfect square\n",
            "5023 is not perfect square\n",
            "5024 is not perfect square\n",
            "5025 is not perfect square\n",
            "5026 is not perfect square\n",
            "5027 is not perfect square\n",
            "5028 is not perfect square\n",
            "5029 is not perfect square\n",
            "5030 is not perfect square\n",
            "5031 is not perfect square\n",
            "5032 is not perfect square\n",
            "5033 is not perfect square\n",
            "5034 is not perfect square\n",
            "5035 is not perfect square\n",
            "5036 is not perfect square\n",
            "5037 is not perfect square\n",
            "5038 is not perfect square\n",
            "5039 is not perfect square\n",
            "5040 is not perfect square\n",
            "5041 is perfect square\n",
            "5042 is not perfect square\n",
            "5043 is not perfect square\n",
            "5044 is not perfect square\n",
            "5045 is not perfect square\n",
            "5046 is not perfect square\n",
            "5047 is not perfect square\n",
            "5048 is not perfect square\n",
            "5049 is not perfect square\n",
            "5050 is not perfect square\n",
            "5051 is not perfect square\n",
            "5052 is not perfect square\n",
            "5053 is not perfect square\n",
            "5054 is not perfect square\n",
            "5055 is not perfect square\n",
            "5056 is not perfect square\n",
            "5057 is not perfect square\n",
            "5058 is not perfect square\n",
            "5059 is not perfect square\n",
            "5060 is not perfect square\n",
            "5061 is not perfect square\n",
            "5062 is not perfect square\n",
            "5063 is not perfect square\n",
            "5064 is not perfect square\n",
            "5065 is not perfect square\n",
            "5066 is not perfect square\n",
            "5067 is not perfect square\n",
            "5068 is not perfect square\n",
            "5069 is not perfect square\n",
            "5070 is not perfect square\n",
            "5071 is not perfect square\n",
            "5072 is not perfect square\n",
            "5073 is not perfect square\n",
            "5074 is not perfect square\n",
            "5075 is not perfect square\n",
            "5076 is not perfect square\n",
            "5077 is not perfect square\n",
            "5078 is not perfect square\n",
            "5079 is not perfect square\n",
            "5080 is not perfect square\n",
            "5081 is not perfect square\n",
            "5082 is not perfect square\n",
            "5083 is not perfect square\n",
            "5084 is not perfect square\n",
            "5085 is not perfect square\n",
            "5086 is not perfect square\n",
            "5087 is not perfect square\n",
            "5088 is not perfect square\n",
            "5089 is not perfect square\n",
            "5090 is not perfect square\n",
            "5091 is not perfect square\n",
            "5092 is not perfect square\n",
            "5093 is not perfect square\n",
            "5094 is not perfect square\n",
            "5095 is not perfect square\n",
            "5096 is not perfect square\n",
            "5097 is not perfect square\n",
            "5098 is not perfect square\n",
            "5099 is not perfect square\n",
            "5100 is not perfect square\n",
            "5101 is not perfect square\n",
            "5102 is not perfect square\n",
            "5103 is not perfect square\n",
            "5104 is not perfect square\n",
            "5105 is not perfect square\n",
            "5106 is not perfect square\n",
            "5107 is not perfect square\n",
            "5108 is not perfect square\n",
            "5109 is not perfect square\n",
            "5110 is not perfect square\n",
            "5111 is not perfect square\n",
            "5112 is not perfect square\n",
            "5113 is not perfect square\n",
            "5114 is not perfect square\n",
            "5115 is not perfect square\n",
            "5116 is not perfect square\n",
            "5117 is not perfect square\n",
            "5118 is not perfect square\n",
            "5119 is not perfect square\n",
            "5120 is not perfect square\n",
            "5121 is not perfect square\n",
            "5122 is not perfect square\n",
            "5123 is not perfect square\n",
            "5124 is not perfect square\n",
            "5125 is not perfect square\n",
            "5126 is not perfect square\n",
            "5127 is not perfect square\n",
            "5128 is not perfect square\n",
            "5129 is not perfect square\n",
            "5130 is not perfect square\n",
            "5131 is not perfect square\n",
            "5132 is not perfect square\n",
            "5133 is not perfect square\n",
            "5134 is not perfect square\n",
            "5135 is not perfect square\n",
            "5136 is not perfect square\n",
            "5137 is not perfect square\n",
            "5138 is not perfect square\n",
            "5139 is not perfect square\n",
            "5140 is not perfect square\n",
            "5141 is not perfect square\n",
            "5142 is not perfect square\n",
            "5143 is not perfect square\n",
            "5144 is not perfect square\n",
            "5145 is not perfect square\n",
            "5146 is not perfect square\n",
            "5147 is not perfect square\n",
            "5148 is not perfect square\n",
            "5149 is not perfect square\n",
            "5150 is not perfect square\n",
            "5151 is not perfect square\n",
            "5152 is not perfect square\n",
            "5153 is not perfect square\n",
            "5154 is not perfect square\n",
            "5155 is not perfect square\n",
            "5156 is not perfect square\n",
            "5157 is not perfect square\n",
            "5158 is not perfect square\n",
            "5159 is not perfect square\n",
            "5160 is not perfect square\n",
            "5161 is not perfect square\n",
            "5162 is not perfect square\n",
            "5163 is not perfect square\n",
            "5164 is not perfect square\n",
            "5165 is not perfect square\n",
            "5166 is not perfect square\n",
            "5167 is not perfect square\n",
            "5168 is not perfect square\n",
            "5169 is not perfect square\n",
            "5170 is not perfect square\n",
            "5171 is not perfect square\n",
            "5172 is not perfect square\n",
            "5173 is not perfect square\n",
            "5174 is not perfect square\n",
            "5175 is not perfect square\n",
            "5176 is not perfect square\n",
            "5177 is not perfect square\n",
            "5178 is not perfect square\n",
            "5179 is not perfect square\n",
            "5180 is not perfect square\n",
            "5181 is not perfect square\n",
            "5182 is not perfect square\n",
            "5183 is not perfect square\n",
            "5184 is perfect square\n",
            "5185 is not perfect square\n",
            "5186 is not perfect square\n",
            "5187 is not perfect square\n",
            "5188 is not perfect square\n",
            "5189 is not perfect square\n",
            "5190 is not perfect square\n",
            "5191 is not perfect square\n",
            "5192 is not perfect square\n",
            "5193 is not perfect square\n",
            "5194 is not perfect square\n",
            "5195 is not perfect square\n",
            "5196 is not perfect square\n",
            "5197 is not perfect square\n",
            "5198 is not perfect square\n",
            "5199 is not perfect square\n",
            "5200 is not perfect square\n",
            "5201 is not perfect square\n",
            "5202 is not perfect square\n",
            "5203 is not perfect square\n",
            "5204 is not perfect square\n",
            "5205 is not perfect square\n",
            "5206 is not perfect square\n",
            "5207 is not perfect square\n",
            "5208 is not perfect square\n",
            "5209 is not perfect square\n",
            "5210 is not perfect square\n",
            "5211 is not perfect square\n",
            "5212 is not perfect square\n",
            "5213 is not perfect square\n",
            "5214 is not perfect square\n",
            "5215 is not perfect square\n",
            "5216 is not perfect square\n",
            "5217 is not perfect square\n",
            "5218 is not perfect square\n",
            "5219 is not perfect square\n",
            "5220 is not perfect square\n",
            "5221 is not perfect square\n",
            "5222 is not perfect square\n",
            "5223 is not perfect square\n",
            "5224 is not perfect square\n",
            "5225 is not perfect square\n",
            "5226 is not perfect square\n",
            "5227 is not perfect square\n",
            "5228 is not perfect square\n",
            "5229 is not perfect square\n",
            "5230 is not perfect square\n",
            "5231 is not perfect square\n",
            "5232 is not perfect square\n",
            "5233 is not perfect square\n",
            "5234 is not perfect square\n",
            "5235 is not perfect square\n",
            "5236 is not perfect square\n",
            "5237 is not perfect square\n",
            "5238 is not perfect square\n",
            "5239 is not perfect square\n",
            "5240 is not perfect square\n",
            "5241 is not perfect square\n",
            "5242 is not perfect square\n",
            "5243 is not perfect square\n",
            "5244 is not perfect square\n",
            "5245 is not perfect square\n",
            "5246 is not perfect square\n",
            "5247 is not perfect square\n",
            "5248 is not perfect square\n",
            "5249 is not perfect square\n",
            "5250 is not perfect square\n",
            "5251 is not perfect square\n",
            "5252 is not perfect square\n",
            "5253 is not perfect square\n",
            "5254 is not perfect square\n",
            "5255 is not perfect square\n",
            "5256 is not perfect square\n",
            "5257 is not perfect square\n",
            "5258 is not perfect square\n",
            "5259 is not perfect square\n",
            "5260 is not perfect square\n",
            "5261 is not perfect square\n",
            "5262 is not perfect square\n",
            "5263 is not perfect square\n",
            "5264 is not perfect square\n",
            "5265 is not perfect square\n",
            "5266 is not perfect square\n",
            "5267 is not perfect square\n",
            "5268 is not perfect square\n",
            "5269 is not perfect square\n",
            "5270 is not perfect square\n",
            "5271 is not perfect square\n",
            "5272 is not perfect square\n",
            "5273 is not perfect square\n",
            "5274 is not perfect square\n",
            "5275 is not perfect square\n",
            "5276 is not perfect square\n",
            "5277 is not perfect square\n",
            "5278 is not perfect square\n",
            "5279 is not perfect square\n",
            "5280 is not perfect square\n",
            "5281 is not perfect square\n",
            "5282 is not perfect square\n",
            "5283 is not perfect square\n",
            "5284 is not perfect square\n",
            "5285 is not perfect square\n",
            "5286 is not perfect square\n",
            "5287 is not perfect square\n",
            "5288 is not perfect square\n",
            "5289 is not perfect square\n",
            "5290 is not perfect square\n",
            "5291 is not perfect square\n",
            "5292 is not perfect square\n",
            "5293 is not perfect square\n",
            "5294 is not perfect square\n",
            "5295 is not perfect square\n",
            "5296 is not perfect square\n",
            "5297 is not perfect square\n",
            "5298 is not perfect square\n",
            "5299 is not perfect square\n",
            "5300 is not perfect square\n",
            "5301 is not perfect square\n",
            "5302 is not perfect square\n",
            "5303 is not perfect square\n",
            "5304 is not perfect square\n",
            "5305 is not perfect square\n",
            "5306 is not perfect square\n",
            "5307 is not perfect square\n",
            "5308 is not perfect square\n",
            "5309 is not perfect square\n",
            "5310 is not perfect square\n",
            "5311 is not perfect square\n",
            "5312 is not perfect square\n",
            "5313 is not perfect square\n",
            "5314 is not perfect square\n",
            "5315 is not perfect square\n",
            "5316 is not perfect square\n",
            "5317 is not perfect square\n",
            "5318 is not perfect square\n",
            "5319 is not perfect square\n",
            "5320 is not perfect square\n",
            "5321 is not perfect square\n",
            "5322 is not perfect square\n",
            "5323 is not perfect square\n",
            "5324 is not perfect square\n",
            "5325 is not perfect square\n",
            "5326 is not perfect square\n",
            "5327 is not perfect square\n",
            "5328 is not perfect square\n",
            "5329 is perfect square\n",
            "5330 is not perfect square\n",
            "5331 is not perfect square\n",
            "5332 is not perfect square\n",
            "5333 is not perfect square\n",
            "5334 is not perfect square\n",
            "5335 is not perfect square\n",
            "5336 is not perfect square\n",
            "5337 is not perfect square\n",
            "5338 is not perfect square\n",
            "5339 is not perfect square\n",
            "5340 is not perfect square\n",
            "5341 is not perfect square\n",
            "5342 is not perfect square\n",
            "5343 is not perfect square\n",
            "5344 is not perfect square\n",
            "5345 is not perfect square\n",
            "5346 is not perfect square\n",
            "5347 is not perfect square\n",
            "5348 is not perfect square\n",
            "5349 is not perfect square\n",
            "5350 is not perfect square\n",
            "5351 is not perfect square\n",
            "5352 is not perfect square\n",
            "5353 is not perfect square\n",
            "5354 is not perfect square\n",
            "5355 is not perfect square\n",
            "5356 is not perfect square\n",
            "5357 is not perfect square\n",
            "5358 is not perfect square\n",
            "5359 is not perfect square\n",
            "5360 is not perfect square\n",
            "5361 is not perfect square\n",
            "5362 is not perfect square\n",
            "5363 is not perfect square\n",
            "5364 is not perfect square\n",
            "5365 is not perfect square\n",
            "5366 is not perfect square\n",
            "5367 is not perfect square\n",
            "5368 is not perfect square\n",
            "5369 is not perfect square\n",
            "5370 is not perfect square\n",
            "5371 is not perfect square\n",
            "5372 is not perfect square\n",
            "5373 is not perfect square\n",
            "5374 is not perfect square\n",
            "5375 is not perfect square\n",
            "5376 is not perfect square\n",
            "5377 is not perfect square\n",
            "5378 is not perfect square\n",
            "5379 is not perfect square\n",
            "5380 is not perfect square\n",
            "5381 is not perfect square\n",
            "5382 is not perfect square\n",
            "5383 is not perfect square\n",
            "5384 is not perfect square\n",
            "5385 is not perfect square\n",
            "5386 is not perfect square\n",
            "5387 is not perfect square\n",
            "5388 is not perfect square\n",
            "5389 is not perfect square\n",
            "5390 is not perfect square\n",
            "5391 is not perfect square\n",
            "5392 is not perfect square\n",
            "5393 is not perfect square\n",
            "5394 is not perfect square\n",
            "5395 is not perfect square\n",
            "5396 is not perfect square\n",
            "5397 is not perfect square\n",
            "5398 is not perfect square\n",
            "5399 is not perfect square\n",
            "5400 is not perfect square\n",
            "5401 is not perfect square\n",
            "5402 is not perfect square\n",
            "5403 is not perfect square\n",
            "5404 is not perfect square\n",
            "5405 is not perfect square\n",
            "5406 is not perfect square\n",
            "5407 is not perfect square\n",
            "5408 is not perfect square\n",
            "5409 is not perfect square\n",
            "5410 is not perfect square\n",
            "5411 is not perfect square\n",
            "5412 is not perfect square\n",
            "5413 is not perfect square\n",
            "5414 is not perfect square\n",
            "5415 is not perfect square\n",
            "5416 is not perfect square\n",
            "5417 is not perfect square\n",
            "5418 is not perfect square\n",
            "5419 is not perfect square\n",
            "5420 is not perfect square\n",
            "5421 is not perfect square\n",
            "5422 is not perfect square\n",
            "5423 is not perfect square\n",
            "5424 is not perfect square\n",
            "5425 is not perfect square\n",
            "5426 is not perfect square\n",
            "5427 is not perfect square\n",
            "5428 is not perfect square\n",
            "5429 is not perfect square\n",
            "5430 is not perfect square\n",
            "5431 is not perfect square\n",
            "5432 is not perfect square\n",
            "5433 is not perfect square\n",
            "5434 is not perfect square\n",
            "5435 is not perfect square\n",
            "5436 is not perfect square\n",
            "5437 is not perfect square\n",
            "5438 is not perfect square\n",
            "5439 is not perfect square\n",
            "5440 is not perfect square\n",
            "5441 is not perfect square\n",
            "5442 is not perfect square\n",
            "5443 is not perfect square\n",
            "5444 is not perfect square\n",
            "5445 is not perfect square\n",
            "5446 is not perfect square\n",
            "5447 is not perfect square\n",
            "5448 is not perfect square\n",
            "5449 is not perfect square\n",
            "5450 is not perfect square\n",
            "5451 is not perfect square\n",
            "5452 is not perfect square\n",
            "5453 is not perfect square\n",
            "5454 is not perfect square\n",
            "5455 is not perfect square\n",
            "5456 is not perfect square\n",
            "5457 is not perfect square\n",
            "5458 is not perfect square\n",
            "5459 is not perfect square\n",
            "5460 is not perfect square\n",
            "5461 is not perfect square\n",
            "5462 is not perfect square\n",
            "5463 is not perfect square\n",
            "5464 is not perfect square\n",
            "5465 is not perfect square\n",
            "5466 is not perfect square\n",
            "5467 is not perfect square\n",
            "5468 is not perfect square\n",
            "5469 is not perfect square\n",
            "5470 is not perfect square\n",
            "5471 is not perfect square\n",
            "5472 is not perfect square\n",
            "5473 is not perfect square\n",
            "5474 is not perfect square\n",
            "5475 is not perfect square\n",
            "5476 is perfect square\n",
            "5477 is not perfect square\n",
            "5478 is not perfect square\n",
            "5479 is not perfect square\n",
            "5480 is not perfect square\n",
            "5481 is not perfect square\n",
            "5482 is not perfect square\n",
            "5483 is not perfect square\n",
            "5484 is not perfect square\n",
            "5485 is not perfect square\n",
            "5486 is not perfect square\n",
            "5487 is not perfect square\n",
            "5488 is not perfect square\n",
            "5489 is not perfect square\n",
            "5490 is not perfect square\n",
            "5491 is not perfect square\n",
            "5492 is not perfect square\n",
            "5493 is not perfect square\n",
            "5494 is not perfect square\n",
            "5495 is not perfect square\n",
            "5496 is not perfect square\n",
            "5497 is not perfect square\n",
            "5498 is not perfect square\n",
            "5499 is not perfect square\n",
            "5500 is not perfect square\n",
            "5501 is not perfect square\n",
            "5502 is not perfect square\n",
            "5503 is not perfect square\n",
            "5504 is not perfect square\n",
            "5505 is not perfect square\n",
            "5506 is not perfect square\n",
            "5507 is not perfect square\n",
            "5508 is not perfect square\n",
            "5509 is not perfect square\n",
            "5510 is not perfect square\n",
            "5511 is not perfect square\n",
            "5512 is not perfect square\n",
            "5513 is not perfect square\n",
            "5514 is not perfect square\n",
            "5515 is not perfect square\n",
            "5516 is not perfect square\n",
            "5517 is not perfect square\n",
            "5518 is not perfect square\n",
            "5519 is not perfect square\n",
            "5520 is not perfect square\n",
            "5521 is not perfect square\n",
            "5522 is not perfect square\n",
            "5523 is not perfect square\n",
            "5524 is not perfect square\n",
            "5525 is not perfect square\n",
            "5526 is not perfect square\n",
            "5527 is not perfect square\n",
            "5528 is not perfect square\n",
            "5529 is not perfect square\n",
            "5530 is not perfect square\n",
            "5531 is not perfect square\n",
            "5532 is not perfect square\n",
            "5533 is not perfect square\n",
            "5534 is not perfect square\n",
            "5535 is not perfect square\n",
            "5536 is not perfect square\n",
            "5537 is not perfect square\n",
            "5538 is not perfect square\n",
            "5539 is not perfect square\n",
            "5540 is not perfect square\n",
            "5541 is not perfect square\n",
            "5542 is not perfect square\n",
            "5543 is not perfect square\n",
            "5544 is not perfect square\n",
            "5545 is not perfect square\n",
            "5546 is not perfect square\n",
            "5547 is not perfect square\n",
            "5548 is not perfect square\n",
            "5549 is not perfect square\n",
            "5550 is not perfect square\n",
            "5551 is not perfect square\n",
            "5552 is not perfect square\n",
            "5553 is not perfect square\n",
            "5554 is not perfect square\n",
            "5555 is not perfect square\n",
            "5556 is not perfect square\n",
            "5557 is not perfect square\n",
            "5558 is not perfect square\n",
            "5559 is not perfect square\n",
            "5560 is not perfect square\n",
            "5561 is not perfect square\n",
            "5562 is not perfect square\n",
            "5563 is not perfect square\n",
            "5564 is not perfect square\n",
            "5565 is not perfect square\n",
            "5566 is not perfect square\n",
            "5567 is not perfect square\n",
            "5568 is not perfect square\n",
            "5569 is not perfect square\n",
            "5570 is not perfect square\n",
            "5571 is not perfect square\n",
            "5572 is not perfect square\n",
            "5573 is not perfect square\n",
            "5574 is not perfect square\n",
            "5575 is not perfect square\n",
            "5576 is not perfect square\n",
            "5577 is not perfect square\n",
            "5578 is not perfect square\n",
            "5579 is not perfect square\n",
            "5580 is not perfect square\n",
            "5581 is not perfect square\n",
            "5582 is not perfect square\n",
            "5583 is not perfect square\n",
            "5584 is not perfect square\n",
            "5585 is not perfect square\n",
            "5586 is not perfect square\n",
            "5587 is not perfect square\n",
            "5588 is not perfect square\n",
            "5589 is not perfect square\n",
            "5590 is not perfect square\n",
            "5591 is not perfect square\n",
            "5592 is not perfect square\n",
            "5593 is not perfect square\n",
            "5594 is not perfect square\n",
            "5595 is not perfect square\n",
            "5596 is not perfect square\n",
            "5597 is not perfect square\n",
            "5598 is not perfect square\n",
            "5599 is not perfect square\n",
            "5600 is not perfect square\n",
            "5601 is not perfect square\n",
            "5602 is not perfect square\n",
            "5603 is not perfect square\n",
            "5604 is not perfect square\n",
            "5605 is not perfect square\n",
            "5606 is not perfect square\n",
            "5607 is not perfect square\n",
            "5608 is not perfect square\n",
            "5609 is not perfect square\n",
            "5610 is not perfect square\n",
            "5611 is not perfect square\n",
            "5612 is not perfect square\n",
            "5613 is not perfect square\n",
            "5614 is not perfect square\n",
            "5615 is not perfect square\n",
            "5616 is not perfect square\n",
            "5617 is not perfect square\n",
            "5618 is not perfect square\n",
            "5619 is not perfect square\n",
            "5620 is not perfect square\n",
            "5621 is not perfect square\n",
            "5622 is not perfect square\n",
            "5623 is not perfect square\n",
            "5624 is not perfect square\n",
            "5625 is perfect square\n",
            "5626 is not perfect square\n",
            "5627 is not perfect square\n",
            "5628 is not perfect square\n",
            "5629 is not perfect square\n",
            "5630 is not perfect square\n",
            "5631 is not perfect square\n",
            "5632 is not perfect square\n",
            "5633 is not perfect square\n",
            "5634 is not perfect square\n",
            "5635 is not perfect square\n",
            "5636 is not perfect square\n",
            "5637 is not perfect square\n",
            "5638 is not perfect square\n",
            "5639 is not perfect square\n",
            "5640 is not perfect square\n",
            "5641 is not perfect square\n",
            "5642 is not perfect square\n",
            "5643 is not perfect square\n",
            "5644 is not perfect square\n",
            "5645 is not perfect square\n",
            "5646 is not perfect square\n",
            "5647 is not perfect square\n",
            "5648 is not perfect square\n",
            "5649 is not perfect square\n",
            "5650 is not perfect square\n",
            "5651 is not perfect square\n",
            "5652 is not perfect square\n",
            "5653 is not perfect square\n",
            "5654 is not perfect square\n",
            "5655 is not perfect square\n",
            "5656 is not perfect square\n",
            "5657 is not perfect square\n",
            "5658 is not perfect square\n",
            "5659 is not perfect square\n",
            "5660 is not perfect square\n",
            "5661 is not perfect square\n",
            "5662 is not perfect square\n",
            "5663 is not perfect square\n",
            "5664 is not perfect square\n",
            "5665 is not perfect square\n",
            "5666 is not perfect square\n",
            "5667 is not perfect square\n",
            "5668 is not perfect square\n",
            "5669 is not perfect square\n",
            "5670 is not perfect square\n",
            "5671 is not perfect square\n",
            "5672 is not perfect square\n",
            "5673 is not perfect square\n",
            "5674 is not perfect square\n",
            "5675 is not perfect square\n",
            "5676 is not perfect square\n",
            "5677 is not perfect square\n",
            "5678 is not perfect square\n",
            "5679 is not perfect square\n",
            "5680 is not perfect square\n",
            "5681 is not perfect square\n",
            "5682 is not perfect square\n",
            "5683 is not perfect square\n",
            "5684 is not perfect square\n",
            "5685 is not perfect square\n",
            "5686 is not perfect square\n",
            "5687 is not perfect square\n",
            "5688 is not perfect square\n",
            "5689 is not perfect square\n",
            "5690 is not perfect square\n",
            "5691 is not perfect square\n",
            "5692 is not perfect square\n",
            "5693 is not perfect square\n",
            "5694 is not perfect square\n",
            "5695 is not perfect square\n",
            "5696 is not perfect square\n",
            "5697 is not perfect square\n",
            "5698 is not perfect square\n",
            "5699 is not perfect square\n",
            "5700 is not perfect square\n",
            "5701 is not perfect square\n",
            "5702 is not perfect square\n",
            "5703 is not perfect square\n",
            "5704 is not perfect square\n",
            "5705 is not perfect square\n",
            "5706 is not perfect square\n",
            "5707 is not perfect square\n",
            "5708 is not perfect square\n",
            "5709 is not perfect square\n",
            "5710 is not perfect square\n",
            "5711 is not perfect square\n",
            "5712 is not perfect square\n",
            "5713 is not perfect square\n",
            "5714 is not perfect square\n",
            "5715 is not perfect square\n",
            "5716 is not perfect square\n",
            "5717 is not perfect square\n",
            "5718 is not perfect square\n",
            "5719 is not perfect square\n",
            "5720 is not perfect square\n",
            "5721 is not perfect square\n",
            "5722 is not perfect square\n",
            "5723 is not perfect square\n",
            "5724 is not perfect square\n",
            "5725 is not perfect square\n",
            "5726 is not perfect square\n",
            "5727 is not perfect square\n",
            "5728 is not perfect square\n",
            "5729 is not perfect square\n",
            "5730 is not perfect square\n",
            "5731 is not perfect square\n",
            "5732 is not perfect square\n",
            "5733 is not perfect square\n",
            "5734 is not perfect square\n",
            "5735 is not perfect square\n",
            "5736 is not perfect square\n",
            "5737 is not perfect square\n",
            "5738 is not perfect square\n",
            "5739 is not perfect square\n",
            "5740 is not perfect square\n",
            "5741 is not perfect square\n",
            "5742 is not perfect square\n",
            "5743 is not perfect square\n",
            "5744 is not perfect square\n",
            "5745 is not perfect square\n",
            "5746 is not perfect square\n",
            "5747 is not perfect square\n",
            "5748 is not perfect square\n",
            "5749 is not perfect square\n",
            "5750 is not perfect square\n",
            "5751 is not perfect square\n",
            "5752 is not perfect square\n",
            "5753 is not perfect square\n",
            "5754 is not perfect square\n",
            "5755 is not perfect square\n",
            "5756 is not perfect square\n",
            "5757 is not perfect square\n",
            "5758 is not perfect square\n",
            "5759 is not perfect square\n",
            "5760 is not perfect square\n",
            "5761 is not perfect square\n",
            "5762 is not perfect square\n",
            "5763 is not perfect square\n",
            "5764 is not perfect square\n",
            "5765 is not perfect square\n",
            "5766 is not perfect square\n",
            "5767 is not perfect square\n",
            "5768 is not perfect square\n",
            "5769 is not perfect square\n",
            "5770 is not perfect square\n",
            "5771 is not perfect square\n",
            "5772 is not perfect square\n",
            "5773 is not perfect square\n",
            "5774 is not perfect square\n",
            "5775 is not perfect square\n",
            "5776 is perfect square\n",
            "5777 is not perfect square\n",
            "5778 is not perfect square\n",
            "5779 is not perfect square\n",
            "5780 is not perfect square\n",
            "5781 is not perfect square\n",
            "5782 is not perfect square\n",
            "5783 is not perfect square\n",
            "5784 is not perfect square\n",
            "5785 is not perfect square\n",
            "5786 is not perfect square\n",
            "5787 is not perfect square\n",
            "5788 is not perfect square\n",
            "5789 is not perfect square\n",
            "5790 is not perfect square\n",
            "5791 is not perfect square\n",
            "5792 is not perfect square\n",
            "5793 is not perfect square\n",
            "5794 is not perfect square\n",
            "5795 is not perfect square\n",
            "5796 is not perfect square\n",
            "5797 is not perfect square\n",
            "5798 is not perfect square\n",
            "5799 is not perfect square\n",
            "5800 is not perfect square\n",
            "5801 is not perfect square\n",
            "5802 is not perfect square\n",
            "5803 is not perfect square\n",
            "5804 is not perfect square\n",
            "5805 is not perfect square\n",
            "5806 is not perfect square\n",
            "5807 is not perfect square\n",
            "5808 is not perfect square\n",
            "5809 is not perfect square\n",
            "5810 is not perfect square\n",
            "5811 is not perfect square\n",
            "5812 is not perfect square\n",
            "5813 is not perfect square\n",
            "5814 is not perfect square\n",
            "5815 is not perfect square\n",
            "5816 is not perfect square\n",
            "5817 is not perfect square\n",
            "5818 is not perfect square\n",
            "5819 is not perfect square\n",
            "5820 is not perfect square\n",
            "5821 is not perfect square\n",
            "5822 is not perfect square\n",
            "5823 is not perfect square\n",
            "5824 is not perfect square\n",
            "5825 is not perfect square\n",
            "5826 is not perfect square\n",
            "5827 is not perfect square\n",
            "5828 is not perfect square\n",
            "5829 is not perfect square\n",
            "5830 is not perfect square\n",
            "5831 is not perfect square\n",
            "5832 is not perfect square\n",
            "5833 is not perfect square\n",
            "5834 is not perfect square\n",
            "5835 is not perfect square\n",
            "5836 is not perfect square\n",
            "5837 is not perfect square\n",
            "5838 is not perfect square\n",
            "5839 is not perfect square\n",
            "5840 is not perfect square\n",
            "5841 is not perfect square\n",
            "5842 is not perfect square\n",
            "5843 is not perfect square\n",
            "5844 is not perfect square\n",
            "5845 is not perfect square\n",
            "5846 is not perfect square\n",
            "5847 is not perfect square\n",
            "5848 is not perfect square\n",
            "5849 is not perfect square\n",
            "5850 is not perfect square\n",
            "5851 is not perfect square\n",
            "5852 is not perfect square\n",
            "5853 is not perfect square\n",
            "5854 is not perfect square\n",
            "5855 is not perfect square\n",
            "5856 is not perfect square\n",
            "5857 is not perfect square\n",
            "5858 is not perfect square\n",
            "5859 is not perfect square\n",
            "5860 is not perfect square\n",
            "5861 is not perfect square\n",
            "5862 is not perfect square\n",
            "5863 is not perfect square\n",
            "5864 is not perfect square\n",
            "5865 is not perfect square\n",
            "5866 is not perfect square\n",
            "5867 is not perfect square\n",
            "5868 is not perfect square\n",
            "5869 is not perfect square\n",
            "5870 is not perfect square\n",
            "5871 is not perfect square\n",
            "5872 is not perfect square\n",
            "5873 is not perfect square\n",
            "5874 is not perfect square\n",
            "5875 is not perfect square\n",
            "5876 is not perfect square\n",
            "5877 is not perfect square\n",
            "5878 is not perfect square\n",
            "5879 is not perfect square\n",
            "5880 is not perfect square\n",
            "5881 is not perfect square\n",
            "5882 is not perfect square\n",
            "5883 is not perfect square\n",
            "5884 is not perfect square\n",
            "5885 is not perfect square\n",
            "5886 is not perfect square\n",
            "5887 is not perfect square\n",
            "5888 is not perfect square\n",
            "5889 is not perfect square\n",
            "5890 is not perfect square\n",
            "5891 is not perfect square\n",
            "5892 is not perfect square\n",
            "5893 is not perfect square\n",
            "5894 is not perfect square\n",
            "5895 is not perfect square\n",
            "5896 is not perfect square\n",
            "5897 is not perfect square\n",
            "5898 is not perfect square\n",
            "5899 is not perfect square\n",
            "5900 is not perfect square\n",
            "5901 is not perfect square\n",
            "5902 is not perfect square\n",
            "5903 is not perfect square\n",
            "5904 is not perfect square\n",
            "5905 is not perfect square\n",
            "5906 is not perfect square\n",
            "5907 is not perfect square\n",
            "5908 is not perfect square\n",
            "5909 is not perfect square\n",
            "5910 is not perfect square\n",
            "5911 is not perfect square\n",
            "5912 is not perfect square\n",
            "5913 is not perfect square\n",
            "5914 is not perfect square\n",
            "5915 is not perfect square\n",
            "5916 is not perfect square\n",
            "5917 is not perfect square\n",
            "5918 is not perfect square\n",
            "5919 is not perfect square\n",
            "5920 is not perfect square\n",
            "5921 is not perfect square\n",
            "5922 is not perfect square\n",
            "5923 is not perfect square\n",
            "5924 is not perfect square\n",
            "5925 is not perfect square\n",
            "5926 is not perfect square\n",
            "5927 is not perfect square\n",
            "5928 is not perfect square\n",
            "5929 is perfect square\n",
            "5930 is not perfect square\n",
            "5931 is not perfect square\n",
            "5932 is not perfect square\n",
            "5933 is not perfect square\n",
            "5934 is not perfect square\n",
            "5935 is not perfect square\n",
            "5936 is not perfect square\n",
            "5937 is not perfect square\n",
            "5938 is not perfect square\n",
            "5939 is not perfect square\n",
            "5940 is not perfect square\n",
            "5941 is not perfect square\n",
            "5942 is not perfect square\n",
            "5943 is not perfect square\n",
            "5944 is not perfect square\n",
            "5945 is not perfect square\n",
            "5946 is not perfect square\n",
            "5947 is not perfect square\n",
            "5948 is not perfect square\n",
            "5949 is not perfect square\n",
            "5950 is not perfect square\n",
            "5951 is not perfect square\n",
            "5952 is not perfect square\n",
            "5953 is not perfect square\n",
            "5954 is not perfect square\n",
            "5955 is not perfect square\n",
            "5956 is not perfect square\n",
            "5957 is not perfect square\n",
            "5958 is not perfect square\n",
            "5959 is not perfect square\n",
            "5960 is not perfect square\n",
            "5961 is not perfect square\n",
            "5962 is not perfect square\n",
            "5963 is not perfect square\n",
            "5964 is not perfect square\n",
            "5965 is not perfect square\n",
            "5966 is not perfect square\n",
            "5967 is not perfect square\n",
            "5968 is not perfect square\n",
            "5969 is not perfect square\n",
            "5970 is not perfect square\n",
            "5971 is not perfect square\n",
            "5972 is not perfect square\n",
            "5973 is not perfect square\n",
            "5974 is not perfect square\n",
            "5975 is not perfect square\n",
            "5976 is not perfect square\n",
            "5977 is not perfect square\n",
            "5978 is not perfect square\n",
            "5979 is not perfect square\n",
            "5980 is not perfect square\n",
            "5981 is not perfect square\n",
            "5982 is not perfect square\n",
            "5983 is not perfect square\n",
            "5984 is not perfect square\n",
            "5985 is not perfect square\n",
            "5986 is not perfect square\n",
            "5987 is not perfect square\n",
            "5988 is not perfect square\n",
            "5989 is not perfect square\n",
            "5990 is not perfect square\n",
            "5991 is not perfect square\n",
            "5992 is not perfect square\n",
            "5993 is not perfect square\n",
            "5994 is not perfect square\n",
            "5995 is not perfect square\n",
            "5996 is not perfect square\n",
            "5997 is not perfect square\n",
            "5998 is not perfect square\n",
            "5999 is not perfect square\n",
            "6000 is not perfect square\n",
            "6001 is not perfect square\n",
            "6002 is not perfect square\n",
            "6003 is not perfect square\n",
            "6004 is not perfect square\n",
            "6005 is not perfect square\n",
            "6006 is not perfect square\n",
            "6007 is not perfect square\n",
            "6008 is not perfect square\n",
            "6009 is not perfect square\n",
            "6010 is not perfect square\n",
            "6011 is not perfect square\n",
            "6012 is not perfect square\n",
            "6013 is not perfect square\n",
            "6014 is not perfect square\n",
            "6015 is not perfect square\n",
            "6016 is not perfect square\n",
            "6017 is not perfect square\n",
            "6018 is not perfect square\n",
            "6019 is not perfect square\n",
            "6020 is not perfect square\n",
            "6021 is not perfect square\n",
            "6022 is not perfect square\n",
            "6023 is not perfect square\n",
            "6024 is not perfect square\n",
            "6025 is not perfect square\n",
            "6026 is not perfect square\n",
            "6027 is not perfect square\n",
            "6028 is not perfect square\n",
            "6029 is not perfect square\n",
            "6030 is not perfect square\n",
            "6031 is not perfect square\n",
            "6032 is not perfect square\n",
            "6033 is not perfect square\n",
            "6034 is not perfect square\n",
            "6035 is not perfect square\n",
            "6036 is not perfect square\n",
            "6037 is not perfect square\n",
            "6038 is not perfect square\n",
            "6039 is not perfect square\n",
            "6040 is not perfect square\n",
            "6041 is not perfect square\n",
            "6042 is not perfect square\n",
            "6043 is not perfect square\n",
            "6044 is not perfect square\n",
            "6045 is not perfect square\n",
            "6046 is not perfect square\n",
            "6047 is not perfect square\n",
            "6048 is not perfect square\n",
            "6049 is not perfect square\n",
            "6050 is not perfect square\n",
            "6051 is not perfect square\n",
            "6052 is not perfect square\n",
            "6053 is not perfect square\n",
            "6054 is not perfect square\n",
            "6055 is not perfect square\n",
            "6056 is not perfect square\n",
            "6057 is not perfect square\n",
            "6058 is not perfect square\n",
            "6059 is not perfect square\n",
            "6060 is not perfect square\n",
            "6061 is not perfect square\n",
            "6062 is not perfect square\n",
            "6063 is not perfect square\n",
            "6064 is not perfect square\n",
            "6065 is not perfect square\n",
            "6066 is not perfect square\n",
            "6067 is not perfect square\n",
            "6068 is not perfect square\n",
            "6069 is not perfect square\n",
            "6070 is not perfect square\n",
            "6071 is not perfect square\n",
            "6072 is not perfect square\n",
            "6073 is not perfect square\n",
            "6074 is not perfect square\n",
            "6075 is not perfect square\n",
            "6076 is not perfect square\n",
            "6077 is not perfect square\n",
            "6078 is not perfect square\n",
            "6079 is not perfect square\n",
            "6080 is not perfect square\n",
            "6081 is not perfect square\n",
            "6082 is not perfect square\n",
            "6083 is not perfect square\n",
            "6084 is perfect square\n",
            "6085 is not perfect square\n",
            "6086 is not perfect square\n",
            "6087 is not perfect square\n",
            "6088 is not perfect square\n",
            "6089 is not perfect square\n",
            "6090 is not perfect square\n",
            "6091 is not perfect square\n",
            "6092 is not perfect square\n",
            "6093 is not perfect square\n",
            "6094 is not perfect square\n",
            "6095 is not perfect square\n",
            "6096 is not perfect square\n",
            "6097 is not perfect square\n",
            "6098 is not perfect square\n",
            "6099 is not perfect square\n",
            "6100 is not perfect square\n",
            "6101 is not perfect square\n",
            "6102 is not perfect square\n",
            "6103 is not perfect square\n",
            "6104 is not perfect square\n",
            "6105 is not perfect square\n",
            "6106 is not perfect square\n",
            "6107 is not perfect square\n",
            "6108 is not perfect square\n",
            "6109 is not perfect square\n",
            "6110 is not perfect square\n",
            "6111 is not perfect square\n",
            "6112 is not perfect square\n",
            "6113 is not perfect square\n",
            "6114 is not perfect square\n",
            "6115 is not perfect square\n",
            "6116 is not perfect square\n",
            "6117 is not perfect square\n",
            "6118 is not perfect square\n",
            "6119 is not perfect square\n",
            "6120 is not perfect square\n",
            "6121 is not perfect square\n",
            "6122 is not perfect square\n",
            "6123 is not perfect square\n",
            "6124 is not perfect square\n",
            "6125 is not perfect square\n",
            "6126 is not perfect square\n",
            "6127 is not perfect square\n",
            "6128 is not perfect square\n",
            "6129 is not perfect square\n",
            "6130 is not perfect square\n",
            "6131 is not perfect square\n",
            "6132 is not perfect square\n",
            "6133 is not perfect square\n",
            "6134 is not perfect square\n",
            "6135 is not perfect square\n",
            "6136 is not perfect square\n",
            "6137 is not perfect square\n",
            "6138 is not perfect square\n",
            "6139 is not perfect square\n",
            "6140 is not perfect square\n",
            "6141 is not perfect square\n",
            "6142 is not perfect square\n",
            "6143 is not perfect square\n",
            "6144 is not perfect square\n",
            "6145 is not perfect square\n",
            "6146 is not perfect square\n",
            "6147 is not perfect square\n",
            "6148 is not perfect square\n",
            "6149 is not perfect square\n",
            "6150 is not perfect square\n",
            "6151 is not perfect square\n",
            "6152 is not perfect square\n",
            "6153 is not perfect square\n",
            "6154 is not perfect square\n",
            "6155 is not perfect square\n",
            "6156 is not perfect square\n",
            "6157 is not perfect square\n",
            "6158 is not perfect square\n",
            "6159 is not perfect square\n",
            "6160 is not perfect square\n",
            "6161 is not perfect square\n",
            "6162 is not perfect square\n",
            "6163 is not perfect square\n",
            "6164 is not perfect square\n",
            "6165 is not perfect square\n",
            "6166 is not perfect square\n",
            "6167 is not perfect square\n",
            "6168 is not perfect square\n",
            "6169 is not perfect square\n",
            "6170 is not perfect square\n",
            "6171 is not perfect square\n",
            "6172 is not perfect square\n",
            "6173 is not perfect square\n",
            "6174 is not perfect square\n",
            "6175 is not perfect square\n",
            "6176 is not perfect square\n",
            "6177 is not perfect square\n",
            "6178 is not perfect square\n",
            "6179 is not perfect square\n",
            "6180 is not perfect square\n",
            "6181 is not perfect square\n",
            "6182 is not perfect square\n",
            "6183 is not perfect square\n",
            "6184 is not perfect square\n",
            "6185 is not perfect square\n",
            "6186 is not perfect square\n",
            "6187 is not perfect square\n",
            "6188 is not perfect square\n",
            "6189 is not perfect square\n",
            "6190 is not perfect square\n",
            "6191 is not perfect square\n",
            "6192 is not perfect square\n",
            "6193 is not perfect square\n",
            "6194 is not perfect square\n",
            "6195 is not perfect square\n",
            "6196 is not perfect square\n",
            "6197 is not perfect square\n",
            "6198 is not perfect square\n",
            "6199 is not perfect square\n",
            "6200 is not perfect square\n",
            "6201 is not perfect square\n",
            "6202 is not perfect square\n",
            "6203 is not perfect square\n",
            "6204 is not perfect square\n",
            "6205 is not perfect square\n",
            "6206 is not perfect square\n",
            "6207 is not perfect square\n",
            "6208 is not perfect square\n",
            "6209 is not perfect square\n",
            "6210 is not perfect square\n",
            "6211 is not perfect square\n",
            "6212 is not perfect square\n",
            "6213 is not perfect square\n",
            "6214 is not perfect square\n",
            "6215 is not perfect square\n",
            "6216 is not perfect square\n",
            "6217 is not perfect square\n",
            "6218 is not perfect square\n",
            "6219 is not perfect square\n",
            "6220 is not perfect square\n",
            "6221 is not perfect square\n",
            "6222 is not perfect square\n",
            "6223 is not perfect square\n",
            "6224 is not perfect square\n",
            "6225 is not perfect square\n",
            "6226 is not perfect square\n",
            "6227 is not perfect square\n",
            "6228 is not perfect square\n",
            "6229 is not perfect square\n",
            "6230 is not perfect square\n",
            "6231 is not perfect square\n",
            "6232 is not perfect square\n",
            "6233 is not perfect square\n",
            "6234 is not perfect square\n",
            "6235 is not perfect square\n",
            "6236 is not perfect square\n",
            "6237 is not perfect square\n",
            "6238 is not perfect square\n",
            "6239 is not perfect square\n",
            "6240 is not perfect square\n",
            "6241 is perfect square\n",
            "6242 is not perfect square\n",
            "6243 is not perfect square\n",
            "6244 is not perfect square\n",
            "6245 is not perfect square\n",
            "6246 is not perfect square\n",
            "6247 is not perfect square\n",
            "6248 is not perfect square\n",
            "6249 is not perfect square\n",
            "6250 is not perfect square\n",
            "6251 is not perfect square\n",
            "6252 is not perfect square\n",
            "6253 is not perfect square\n",
            "6254 is not perfect square\n",
            "6255 is not perfect square\n",
            "6256 is not perfect square\n",
            "6257 is not perfect square\n",
            "6258 is not perfect square\n",
            "6259 is not perfect square\n",
            "6260 is not perfect square\n",
            "6261 is not perfect square\n",
            "6262 is not perfect square\n",
            "6263 is not perfect square\n",
            "6264 is not perfect square\n",
            "6265 is not perfect square\n",
            "6266 is not perfect square\n",
            "6267 is not perfect square\n",
            "6268 is not perfect square\n",
            "6269 is not perfect square\n",
            "6270 is not perfect square\n",
            "6271 is not perfect square\n",
            "6272 is not perfect square\n",
            "6273 is not perfect square\n",
            "6274 is not perfect square\n",
            "6275 is not perfect square\n",
            "6276 is not perfect square\n",
            "6277 is not perfect square\n",
            "6278 is not perfect square\n",
            "6279 is not perfect square\n",
            "6280 is not perfect square\n",
            "6281 is not perfect square\n",
            "6282 is not perfect square\n",
            "6283 is not perfect square\n",
            "6284 is not perfect square\n",
            "6285 is not perfect square\n",
            "6286 is not perfect square\n",
            "6287 is not perfect square\n",
            "6288 is not perfect square\n",
            "6289 is not perfect square\n",
            "6290 is not perfect square\n",
            "6291 is not perfect square\n",
            "6292 is not perfect square\n",
            "6293 is not perfect square\n",
            "6294 is not perfect square\n",
            "6295 is not perfect square\n",
            "6296 is not perfect square\n",
            "6297 is not perfect square\n",
            "6298 is not perfect square\n",
            "6299 is not perfect square\n",
            "6300 is not perfect square\n",
            "6301 is not perfect square\n",
            "6302 is not perfect square\n",
            "6303 is not perfect square\n",
            "6304 is not perfect square\n",
            "6305 is not perfect square\n",
            "6306 is not perfect square\n",
            "6307 is not perfect square\n",
            "6308 is not perfect square\n",
            "6309 is not perfect square\n",
            "6310 is not perfect square\n",
            "6311 is not perfect square\n",
            "6312 is not perfect square\n",
            "6313 is not perfect square\n",
            "6314 is not perfect square\n",
            "6315 is not perfect square\n",
            "6316 is not perfect square\n",
            "6317 is not perfect square\n",
            "6318 is not perfect square\n",
            "6319 is not perfect square\n",
            "6320 is not perfect square\n",
            "6321 is not perfect square\n",
            "6322 is not perfect square\n",
            "6323 is not perfect square\n",
            "6324 is not perfect square\n",
            "6325 is not perfect square\n",
            "6326 is not perfect square\n",
            "6327 is not perfect square\n",
            "6328 is not perfect square\n",
            "6329 is not perfect square\n",
            "6330 is not perfect square\n",
            "6331 is not perfect square\n",
            "6332 is not perfect square\n",
            "6333 is not perfect square\n",
            "6334 is not perfect square\n",
            "6335 is not perfect square\n",
            "6336 is not perfect square\n",
            "6337 is not perfect square\n",
            "6338 is not perfect square\n",
            "6339 is not perfect square\n",
            "6340 is not perfect square\n",
            "6341 is not perfect square\n",
            "6342 is not perfect square\n",
            "6343 is not perfect square\n",
            "6344 is not perfect square\n",
            "6345 is not perfect square\n",
            "6346 is not perfect square\n",
            "6347 is not perfect square\n",
            "6348 is not perfect square\n",
            "6349 is not perfect square\n",
            "6350 is not perfect square\n",
            "6351 is not perfect square\n",
            "6352 is not perfect square\n",
            "6353 is not perfect square\n",
            "6354 is not perfect square\n",
            "6355 is not perfect square\n",
            "6356 is not perfect square\n",
            "6357 is not perfect square\n",
            "6358 is not perfect square\n",
            "6359 is not perfect square\n",
            "6360 is not perfect square\n",
            "6361 is not perfect square\n",
            "6362 is not perfect square\n",
            "6363 is not perfect square\n",
            "6364 is not perfect square\n",
            "6365 is not perfect square\n",
            "6366 is not perfect square\n",
            "6367 is not perfect square\n",
            "6368 is not perfect square\n",
            "6369 is not perfect square\n",
            "6370 is not perfect square\n",
            "6371 is not perfect square\n",
            "6372 is not perfect square\n",
            "6373 is not perfect square\n",
            "6374 is not perfect square\n",
            "6375 is not perfect square\n",
            "6376 is not perfect square\n",
            "6377 is not perfect square\n",
            "6378 is not perfect square\n",
            "6379 is not perfect square\n",
            "6380 is not perfect square\n",
            "6381 is not perfect square\n",
            "6382 is not perfect square\n",
            "6383 is not perfect square\n",
            "6384 is not perfect square\n",
            "6385 is not perfect square\n",
            "6386 is not perfect square\n",
            "6387 is not perfect square\n",
            "6388 is not perfect square\n",
            "6389 is not perfect square\n",
            "6390 is not perfect square\n",
            "6391 is not perfect square\n",
            "6392 is not perfect square\n",
            "6393 is not perfect square\n",
            "6394 is not perfect square\n",
            "6395 is not perfect square\n",
            "6396 is not perfect square\n",
            "6397 is not perfect square\n",
            "6398 is not perfect square\n",
            "6399 is not perfect square\n",
            "6400 is perfect square\n",
            "6401 is not perfect square\n",
            "6402 is not perfect square\n",
            "6403 is not perfect square\n",
            "6404 is not perfect square\n",
            "6405 is not perfect square\n",
            "6406 is not perfect square\n",
            "6407 is not perfect square\n",
            "6408 is not perfect square\n",
            "6409 is not perfect square\n",
            "6410 is not perfect square\n",
            "6411 is not perfect square\n",
            "6412 is not perfect square\n",
            "6413 is not perfect square\n",
            "6414 is not perfect square\n",
            "6415 is not perfect square\n",
            "6416 is not perfect square\n",
            "6417 is not perfect square\n",
            "6418 is not perfect square\n",
            "6419 is not perfect square\n",
            "6420 is not perfect square\n",
            "6421 is not perfect square\n",
            "6422 is not perfect square\n",
            "6423 is not perfect square\n",
            "6424 is not perfect square\n",
            "6425 is not perfect square\n",
            "6426 is not perfect square\n",
            "6427 is not perfect square\n",
            "6428 is not perfect square\n",
            "6429 is not perfect square\n",
            "6430 is not perfect square\n",
            "6431 is not perfect square\n",
            "6432 is not perfect square\n",
            "6433 is not perfect square\n",
            "6434 is not perfect square\n",
            "6435 is not perfect square\n",
            "6436 is not perfect square\n",
            "6437 is not perfect square\n",
            "6438 is not perfect square\n",
            "6439 is not perfect square\n",
            "6440 is not perfect square\n",
            "6441 is not perfect square\n",
            "6442 is not perfect square\n",
            "6443 is not perfect square\n",
            "6444 is not perfect square\n",
            "6445 is not perfect square\n",
            "6446 is not perfect square\n",
            "6447 is not perfect square\n",
            "6448 is not perfect square\n",
            "6449 is not perfect square\n",
            "6450 is not perfect square\n",
            "6451 is not perfect square\n",
            "6452 is not perfect square\n",
            "6453 is not perfect square\n",
            "6454 is not perfect square\n",
            "6455 is not perfect square\n",
            "6456 is not perfect square\n",
            "6457 is not perfect square\n",
            "6458 is not perfect square\n",
            "6459 is not perfect square\n",
            "6460 is not perfect square\n",
            "6461 is not perfect square\n",
            "6462 is not perfect square\n",
            "6463 is not perfect square\n",
            "6464 is not perfect square\n",
            "6465 is not perfect square\n",
            "6466 is not perfect square\n",
            "6467 is not perfect square\n",
            "6468 is not perfect square\n",
            "6469 is not perfect square\n",
            "6470 is not perfect square\n",
            "6471 is not perfect square\n",
            "6472 is not perfect square\n",
            "6473 is not perfect square\n",
            "6474 is not perfect square\n",
            "6475 is not perfect square\n",
            "6476 is not perfect square\n",
            "6477 is not perfect square\n",
            "6478 is not perfect square\n",
            "6479 is not perfect square\n",
            "6480 is not perfect square\n",
            "6481 is not perfect square\n",
            "6482 is not perfect square\n",
            "6483 is not perfect square\n",
            "6484 is not perfect square\n",
            "6485 is not perfect square\n",
            "6486 is not perfect square\n",
            "6487 is not perfect square\n",
            "6488 is not perfect square\n",
            "6489 is not perfect square\n",
            "6490 is not perfect square\n",
            "6491 is not perfect square\n",
            "6492 is not perfect square\n",
            "6493 is not perfect square\n",
            "6494 is not perfect square\n",
            "6495 is not perfect square\n",
            "6496 is not perfect square\n",
            "6497 is not perfect square\n",
            "6498 is not perfect square\n",
            "6499 is not perfect square\n",
            "6500 is not perfect square\n",
            "6501 is not perfect square\n",
            "6502 is not perfect square\n",
            "6503 is not perfect square\n",
            "6504 is not perfect square\n",
            "6505 is not perfect square\n",
            "6506 is not perfect square\n",
            "6507 is not perfect square\n",
            "6508 is not perfect square\n",
            "6509 is not perfect square\n",
            "6510 is not perfect square\n",
            "6511 is not perfect square\n",
            "6512 is not perfect square\n",
            "6513 is not perfect square\n",
            "6514 is not perfect square\n",
            "6515 is not perfect square\n",
            "6516 is not perfect square\n",
            "6517 is not perfect square\n",
            "6518 is not perfect square\n",
            "6519 is not perfect square\n",
            "6520 is not perfect square\n",
            "6521 is not perfect square\n",
            "6522 is not perfect square\n",
            "6523 is not perfect square\n",
            "6524 is not perfect square\n",
            "6525 is not perfect square\n",
            "6526 is not perfect square\n",
            "6527 is not perfect square\n",
            "6528 is not perfect square\n",
            "6529 is not perfect square\n",
            "6530 is not perfect square\n",
            "6531 is not perfect square\n",
            "6532 is not perfect square\n",
            "6533 is not perfect square\n",
            "6534 is not perfect square\n",
            "6535 is not perfect square\n",
            "6536 is not perfect square\n",
            "6537 is not perfect square\n",
            "6538 is not perfect square\n",
            "6539 is not perfect square\n",
            "6540 is not perfect square\n",
            "6541 is not perfect square\n",
            "6542 is not perfect square\n",
            "6543 is not perfect square\n",
            "6544 is not perfect square\n",
            "6545 is not perfect square\n",
            "6546 is not perfect square\n",
            "6547 is not perfect square\n",
            "6548 is not perfect square\n",
            "6549 is not perfect square\n",
            "6550 is not perfect square\n",
            "6551 is not perfect square\n",
            "6552 is not perfect square\n",
            "6553 is not perfect square\n",
            "6554 is not perfect square\n",
            "6555 is not perfect square\n",
            "6556 is not perfect square\n",
            "6557 is not perfect square\n",
            "6558 is not perfect square\n",
            "6559 is not perfect square\n",
            "6560 is not perfect square\n",
            "6561 is perfect square\n",
            "6562 is not perfect square\n",
            "6563 is not perfect square\n",
            "6564 is not perfect square\n",
            "6565 is not perfect square\n",
            "6566 is not perfect square\n",
            "6567 is not perfect square\n",
            "6568 is not perfect square\n",
            "6569 is not perfect square\n",
            "6570 is not perfect square\n",
            "6571 is not perfect square\n",
            "6572 is not perfect square\n",
            "6573 is not perfect square\n",
            "6574 is not perfect square\n",
            "6575 is not perfect square\n",
            "6576 is not perfect square\n",
            "6577 is not perfect square\n",
            "6578 is not perfect square\n",
            "6579 is not perfect square\n",
            "6580 is not perfect square\n",
            "6581 is not perfect square\n",
            "6582 is not perfect square\n",
            "6583 is not perfect square\n",
            "6584 is not perfect square\n",
            "6585 is not perfect square\n",
            "6586 is not perfect square\n",
            "6587 is not perfect square\n",
            "6588 is not perfect square\n",
            "6589 is not perfect square\n",
            "6590 is not perfect square\n",
            "6591 is not perfect square\n",
            "6592 is not perfect square\n",
            "6593 is not perfect square\n",
            "6594 is not perfect square\n",
            "6595 is not perfect square\n",
            "6596 is not perfect square\n",
            "6597 is not perfect square\n",
            "6598 is not perfect square\n",
            "6599 is not perfect square\n",
            "6600 is not perfect square\n",
            "6601 is not perfect square\n",
            "6602 is not perfect square\n",
            "6603 is not perfect square\n",
            "6604 is not perfect square\n",
            "6605 is not perfect square\n",
            "6606 is not perfect square\n",
            "6607 is not perfect square\n",
            "6608 is not perfect square\n",
            "6609 is not perfect square\n",
            "6610 is not perfect square\n",
            "6611 is not perfect square\n",
            "6612 is not perfect square\n",
            "6613 is not perfect square\n",
            "6614 is not perfect square\n",
            "6615 is not perfect square\n",
            "6616 is not perfect square\n",
            "6617 is not perfect square\n",
            "6618 is not perfect square\n",
            "6619 is not perfect square\n",
            "6620 is not perfect square\n",
            "6621 is not perfect square\n",
            "6622 is not perfect square\n",
            "6623 is not perfect square\n",
            "6624 is not perfect square\n",
            "6625 is not perfect square\n",
            "6626 is not perfect square\n",
            "6627 is not perfect square\n",
            "6628 is not perfect square\n",
            "6629 is not perfect square\n",
            "6630 is not perfect square\n",
            "6631 is not perfect square\n",
            "6632 is not perfect square\n",
            "6633 is not perfect square\n",
            "6634 is not perfect square\n",
            "6635 is not perfect square\n",
            "6636 is not perfect square\n",
            "6637 is not perfect square\n",
            "6638 is not perfect square\n",
            "6639 is not perfect square\n",
            "6640 is not perfect square\n",
            "6641 is not perfect square\n",
            "6642 is not perfect square\n",
            "6643 is not perfect square\n",
            "6644 is not perfect square\n",
            "6645 is not perfect square\n",
            "6646 is not perfect square\n",
            "6647 is not perfect square\n",
            "6648 is not perfect square\n",
            "6649 is not perfect square\n",
            "6650 is not perfect square\n",
            "6651 is not perfect square\n",
            "6652 is not perfect square\n",
            "6653 is not perfect square\n",
            "6654 is not perfect square\n",
            "6655 is not perfect square\n",
            "6656 is not perfect square\n",
            "6657 is not perfect square\n",
            "6658 is not perfect square\n",
            "6659 is not perfect square\n",
            "6660 is not perfect square\n",
            "6661 is not perfect square\n",
            "6662 is not perfect square\n",
            "6663 is not perfect square\n",
            "6664 is not perfect square\n",
            "6665 is not perfect square\n",
            "6666 is not perfect square\n",
            "6667 is not perfect square\n",
            "6668 is not perfect square\n",
            "6669 is not perfect square\n",
            "6670 is not perfect square\n",
            "6671 is not perfect square\n",
            "6672 is not perfect square\n",
            "6673 is not perfect square\n",
            "6674 is not perfect square\n",
            "6675 is not perfect square\n",
            "6676 is not perfect square\n",
            "6677 is not perfect square\n",
            "6678 is not perfect square\n",
            "6679 is not perfect square\n",
            "6680 is not perfect square\n",
            "6681 is not perfect square\n",
            "6682 is not perfect square\n",
            "6683 is not perfect square\n",
            "6684 is not perfect square\n",
            "6685 is not perfect square\n",
            "6686 is not perfect square\n",
            "6687 is not perfect square\n",
            "6688 is not perfect square\n",
            "6689 is not perfect square\n",
            "6690 is not perfect square\n",
            "6691 is not perfect square\n",
            "6692 is not perfect square\n",
            "6693 is not perfect square\n",
            "6694 is not perfect square\n",
            "6695 is not perfect square\n",
            "6696 is not perfect square\n",
            "6697 is not perfect square\n",
            "6698 is not perfect square\n",
            "6699 is not perfect square\n",
            "6700 is not perfect square\n",
            "6701 is not perfect square\n",
            "6702 is not perfect square\n",
            "6703 is not perfect square\n",
            "6704 is not perfect square\n",
            "6705 is not perfect square\n",
            "6706 is not perfect square\n",
            "6707 is not perfect square\n",
            "6708 is not perfect square\n",
            "6709 is not perfect square\n",
            "6710 is not perfect square\n",
            "6711 is not perfect square\n",
            "6712 is not perfect square\n",
            "6713 is not perfect square\n",
            "6714 is not perfect square\n",
            "6715 is not perfect square\n",
            "6716 is not perfect square\n",
            "6717 is not perfect square\n",
            "6718 is not perfect square\n",
            "6719 is not perfect square\n",
            "6720 is not perfect square\n",
            "6721 is not perfect square\n",
            "6722 is not perfect square\n",
            "6723 is not perfect square\n",
            "6724 is perfect square\n",
            "6725 is not perfect square\n",
            "6726 is not perfect square\n",
            "6727 is not perfect square\n",
            "6728 is not perfect square\n",
            "6729 is not perfect square\n",
            "6730 is not perfect square\n",
            "6731 is not perfect square\n",
            "6732 is not perfect square\n",
            "6733 is not perfect square\n",
            "6734 is not perfect square\n",
            "6735 is not perfect square\n",
            "6736 is not perfect square\n",
            "6737 is not perfect square\n",
            "6738 is not perfect square\n",
            "6739 is not perfect square\n",
            "6740 is not perfect square\n",
            "6741 is not perfect square\n",
            "6742 is not perfect square\n",
            "6743 is not perfect square\n",
            "6744 is not perfect square\n",
            "6745 is not perfect square\n",
            "6746 is not perfect square\n",
            "6747 is not perfect square\n",
            "6748 is not perfect square\n",
            "6749 is not perfect square\n",
            "6750 is not perfect square\n",
            "6751 is not perfect square\n",
            "6752 is not perfect square\n",
            "6753 is not perfect square\n",
            "6754 is not perfect square\n",
            "6755 is not perfect square\n",
            "6756 is not perfect square\n",
            "6757 is not perfect square\n",
            "6758 is not perfect square\n",
            "6759 is not perfect square\n",
            "6760 is not perfect square\n",
            "6761 is not perfect square\n",
            "6762 is not perfect square\n",
            "6763 is not perfect square\n",
            "6764 is not perfect square\n",
            "6765 is not perfect square\n",
            "6766 is not perfect square\n",
            "6767 is not perfect square\n",
            "6768 is not perfect square\n",
            "6769 is not perfect square\n",
            "6770 is not perfect square\n",
            "6771 is not perfect square\n",
            "6772 is not perfect square\n",
            "6773 is not perfect square\n",
            "6774 is not perfect square\n",
            "6775 is not perfect square\n",
            "6776 is not perfect square\n",
            "6777 is not perfect square\n",
            "6778 is not perfect square\n",
            "6779 is not perfect square\n",
            "6780 is not perfect square\n",
            "6781 is not perfect square\n",
            "6782 is not perfect square\n",
            "6783 is not perfect square\n",
            "6784 is not perfect square\n",
            "6785 is not perfect square\n",
            "6786 is not perfect square\n",
            "6787 is not perfect square\n",
            "6788 is not perfect square\n",
            "6789 is not perfect square\n",
            "6790 is not perfect square\n",
            "6791 is not perfect square\n",
            "6792 is not perfect square\n",
            "6793 is not perfect square\n",
            "6794 is not perfect square\n",
            "6795 is not perfect square\n",
            "6796 is not perfect square\n",
            "6797 is not perfect square\n",
            "6798 is not perfect square\n",
            "6799 is not perfect square\n",
            "6800 is not perfect square\n",
            "6801 is not perfect square\n",
            "6802 is not perfect square\n",
            "6803 is not perfect square\n",
            "6804 is not perfect square\n",
            "6805 is not perfect square\n",
            "6806 is not perfect square\n",
            "6807 is not perfect square\n",
            "6808 is not perfect square\n",
            "6809 is not perfect square\n",
            "6810 is not perfect square\n",
            "6811 is not perfect square\n",
            "6812 is not perfect square\n",
            "6813 is not perfect square\n",
            "6814 is not perfect square\n",
            "6815 is not perfect square\n",
            "6816 is not perfect square\n",
            "6817 is not perfect square\n",
            "6818 is not perfect square\n",
            "6819 is not perfect square\n",
            "6820 is not perfect square\n",
            "6821 is not perfect square\n",
            "6822 is not perfect square\n",
            "6823 is not perfect square\n",
            "6824 is not perfect square\n",
            "6825 is not perfect square\n",
            "6826 is not perfect square\n",
            "6827 is not perfect square\n",
            "6828 is not perfect square\n",
            "6829 is not perfect square\n",
            "6830 is not perfect square\n",
            "6831 is not perfect square\n",
            "6832 is not perfect square\n",
            "6833 is not perfect square\n",
            "6834 is not perfect square\n",
            "6835 is not perfect square\n",
            "6836 is not perfect square\n",
            "6837 is not perfect square\n",
            "6838 is not perfect square\n",
            "6839 is not perfect square\n",
            "6840 is not perfect square\n",
            "6841 is not perfect square\n",
            "6842 is not perfect square\n",
            "6843 is not perfect square\n",
            "6844 is not perfect square\n",
            "6845 is not perfect square\n",
            "6846 is not perfect square\n",
            "6847 is not perfect square\n",
            "6848 is not perfect square\n",
            "6849 is not perfect square\n",
            "6850 is not perfect square\n",
            "6851 is not perfect square\n",
            "6852 is not perfect square\n",
            "6853 is not perfect square\n",
            "6854 is not perfect square\n",
            "6855 is not perfect square\n",
            "6856 is not perfect square\n",
            "6857 is not perfect square\n",
            "6858 is not perfect square\n",
            "6859 is not perfect square\n",
            "6860 is not perfect square\n",
            "6861 is not perfect square\n",
            "6862 is not perfect square\n",
            "6863 is not perfect square\n",
            "6864 is not perfect square\n",
            "6865 is not perfect square\n",
            "6866 is not perfect square\n",
            "6867 is not perfect square\n",
            "6868 is not perfect square\n",
            "6869 is not perfect square\n",
            "6870 is not perfect square\n",
            "6871 is not perfect square\n",
            "6872 is not perfect square\n",
            "6873 is not perfect square\n",
            "6874 is not perfect square\n",
            "6875 is not perfect square\n",
            "6876 is not perfect square\n",
            "6877 is not perfect square\n",
            "6878 is not perfect square\n",
            "6879 is not perfect square\n",
            "6880 is not perfect square\n",
            "6881 is not perfect square\n",
            "6882 is not perfect square\n",
            "6883 is not perfect square\n",
            "6884 is not perfect square\n",
            "6885 is not perfect square\n",
            "6886 is not perfect square\n",
            "6887 is not perfect square\n",
            "6888 is not perfect square\n",
            "6889 is perfect square\n",
            "6890 is not perfect square\n",
            "6891 is not perfect square\n",
            "6892 is not perfect square\n",
            "6893 is not perfect square\n",
            "6894 is not perfect square\n",
            "6895 is not perfect square\n",
            "6896 is not perfect square\n",
            "6897 is not perfect square\n",
            "6898 is not perfect square\n",
            "6899 is not perfect square\n",
            "6900 is not perfect square\n",
            "6901 is not perfect square\n",
            "6902 is not perfect square\n",
            "6903 is not perfect square\n",
            "6904 is not perfect square\n",
            "6905 is not perfect square\n",
            "6906 is not perfect square\n",
            "6907 is not perfect square\n",
            "6908 is not perfect square\n",
            "6909 is not perfect square\n",
            "6910 is not perfect square\n",
            "6911 is not perfect square\n",
            "6912 is not perfect square\n",
            "6913 is not perfect square\n",
            "6914 is not perfect square\n",
            "6915 is not perfect square\n",
            "6916 is not perfect square\n",
            "6917 is not perfect square\n",
            "6918 is not perfect square\n",
            "6919 is not perfect square\n",
            "6920 is not perfect square\n",
            "6921 is not perfect square\n",
            "6922 is not perfect square\n",
            "6923 is not perfect square\n",
            "6924 is not perfect square\n",
            "6925 is not perfect square\n",
            "6926 is not perfect square\n",
            "6927 is not perfect square\n",
            "6928 is not perfect square\n",
            "6929 is not perfect square\n",
            "6930 is not perfect square\n",
            "6931 is not perfect square\n",
            "6932 is not perfect square\n",
            "6933 is not perfect square\n",
            "6934 is not perfect square\n",
            "6935 is not perfect square\n",
            "6936 is not perfect square\n",
            "6937 is not perfect square\n",
            "6938 is not perfect square\n",
            "6939 is not perfect square\n",
            "6940 is not perfect square\n",
            "6941 is not perfect square\n",
            "6942 is not perfect square\n",
            "6943 is not perfect square\n",
            "6944 is not perfect square\n",
            "6945 is not perfect square\n",
            "6946 is not perfect square\n",
            "6947 is not perfect square\n",
            "6948 is not perfect square\n",
            "6949 is not perfect square\n",
            "6950 is not perfect square\n",
            "6951 is not perfect square\n",
            "6952 is not perfect square\n",
            "6953 is not perfect square\n",
            "6954 is not perfect square\n",
            "6955 is not perfect square\n",
            "6956 is not perfect square\n",
            "6957 is not perfect square\n",
            "6958 is not perfect square\n",
            "6959 is not perfect square\n",
            "6960 is not perfect square\n",
            "6961 is not perfect square\n",
            "6962 is not perfect square\n",
            "6963 is not perfect square\n",
            "6964 is not perfect square\n",
            "6965 is not perfect square\n",
            "6966 is not perfect square\n",
            "6967 is not perfect square\n",
            "6968 is not perfect square\n",
            "6969 is not perfect square\n",
            "6970 is not perfect square\n",
            "6971 is not perfect square\n",
            "6972 is not perfect square\n",
            "6973 is not perfect square\n",
            "6974 is not perfect square\n",
            "6975 is not perfect square\n",
            "6976 is not perfect square\n",
            "6977 is not perfect square\n",
            "6978 is not perfect square\n",
            "6979 is not perfect square\n",
            "6980 is not perfect square\n",
            "6981 is not perfect square\n",
            "6982 is not perfect square\n",
            "6983 is not perfect square\n",
            "6984 is not perfect square\n",
            "6985 is not perfect square\n",
            "6986 is not perfect square\n",
            "6987 is not perfect square\n",
            "6988 is not perfect square\n",
            "6989 is not perfect square\n",
            "6990 is not perfect square\n",
            "6991 is not perfect square\n",
            "6992 is not perfect square\n",
            "6993 is not perfect square\n",
            "6994 is not perfect square\n",
            "6995 is not perfect square\n",
            "6996 is not perfect square\n",
            "6997 is not perfect square\n",
            "6998 is not perfect square\n",
            "6999 is not perfect square\n",
            "7000 is not perfect square\n",
            "7001 is not perfect square\n",
            "7002 is not perfect square\n",
            "7003 is not perfect square\n",
            "7004 is not perfect square\n",
            "7005 is not perfect square\n",
            "7006 is not perfect square\n",
            "7007 is not perfect square\n",
            "7008 is not perfect square\n",
            "7009 is not perfect square\n",
            "7010 is not perfect square\n",
            "7011 is not perfect square\n",
            "7012 is not perfect square\n",
            "7013 is not perfect square\n",
            "7014 is not perfect square\n",
            "7015 is not perfect square\n",
            "7016 is not perfect square\n",
            "7017 is not perfect square\n",
            "7018 is not perfect square\n",
            "7019 is not perfect square\n",
            "7020 is not perfect square\n",
            "7021 is not perfect square\n",
            "7022 is not perfect square\n",
            "7023 is not perfect square\n",
            "7024 is not perfect square\n",
            "7025 is not perfect square\n",
            "7026 is not perfect square\n",
            "7027 is not perfect square\n",
            "7028 is not perfect square\n",
            "7029 is not perfect square\n",
            "7030 is not perfect square\n",
            "7031 is not perfect square\n",
            "7032 is not perfect square\n",
            "7033 is not perfect square\n",
            "7034 is not perfect square\n",
            "7035 is not perfect square\n",
            "7036 is not perfect square\n",
            "7037 is not perfect square\n",
            "7038 is not perfect square\n",
            "7039 is not perfect square\n",
            "7040 is not perfect square\n",
            "7041 is not perfect square\n",
            "7042 is not perfect square\n",
            "7043 is not perfect square\n",
            "7044 is not perfect square\n",
            "7045 is not perfect square\n",
            "7046 is not perfect square\n",
            "7047 is not perfect square\n",
            "7048 is not perfect square\n",
            "7049 is not perfect square\n",
            "7050 is not perfect square\n",
            "7051 is not perfect square\n",
            "7052 is not perfect square\n",
            "7053 is not perfect square\n",
            "7054 is not perfect square\n",
            "7055 is not perfect square\n",
            "7056 is perfect square\n",
            "7057 is not perfect square\n",
            "7058 is not perfect square\n",
            "7059 is not perfect square\n",
            "7060 is not perfect square\n",
            "7061 is not perfect square\n",
            "7062 is not perfect square\n",
            "7063 is not perfect square\n",
            "7064 is not perfect square\n",
            "7065 is not perfect square\n",
            "7066 is not perfect square\n",
            "7067 is not perfect square\n",
            "7068 is not perfect square\n",
            "7069 is not perfect square\n",
            "7070 is not perfect square\n",
            "7071 is not perfect square\n",
            "7072 is not perfect square\n",
            "7073 is not perfect square\n",
            "7074 is not perfect square\n",
            "7075 is not perfect square\n",
            "7076 is not perfect square\n",
            "7077 is not perfect square\n",
            "7078 is not perfect square\n",
            "7079 is not perfect square\n",
            "7080 is not perfect square\n",
            "7081 is not perfect square\n",
            "7082 is not perfect square\n",
            "7083 is not perfect square\n",
            "7084 is not perfect square\n",
            "7085 is not perfect square\n",
            "7086 is not perfect square\n",
            "7087 is not perfect square\n",
            "7088 is not perfect square\n",
            "7089 is not perfect square\n",
            "7090 is not perfect square\n",
            "7091 is not perfect square\n",
            "7092 is not perfect square\n",
            "7093 is not perfect square\n",
            "7094 is not perfect square\n",
            "7095 is not perfect square\n",
            "7096 is not perfect square\n",
            "7097 is not perfect square\n",
            "7098 is not perfect square\n",
            "7099 is not perfect square\n",
            "7100 is not perfect square\n",
            "7101 is not perfect square\n",
            "7102 is not perfect square\n",
            "7103 is not perfect square\n",
            "7104 is not perfect square\n",
            "7105 is not perfect square\n",
            "7106 is not perfect square\n",
            "7107 is not perfect square\n",
            "7108 is not perfect square\n",
            "7109 is not perfect square\n",
            "7110 is not perfect square\n",
            "7111 is not perfect square\n",
            "7112 is not perfect square\n",
            "7113 is not perfect square\n",
            "7114 is not perfect square\n",
            "7115 is not perfect square\n",
            "7116 is not perfect square\n",
            "7117 is not perfect square\n",
            "7118 is not perfect square\n",
            "7119 is not perfect square\n",
            "7120 is not perfect square\n",
            "7121 is not perfect square\n",
            "7122 is not perfect square\n",
            "7123 is not perfect square\n",
            "7124 is not perfect square\n",
            "7125 is not perfect square\n",
            "7126 is not perfect square\n",
            "7127 is not perfect square\n",
            "7128 is not perfect square\n",
            "7129 is not perfect square\n",
            "7130 is not perfect square\n",
            "7131 is not perfect square\n",
            "7132 is not perfect square\n",
            "7133 is not perfect square\n",
            "7134 is not perfect square\n",
            "7135 is not perfect square\n",
            "7136 is not perfect square\n",
            "7137 is not perfect square\n",
            "7138 is not perfect square\n",
            "7139 is not perfect square\n",
            "7140 is not perfect square\n",
            "7141 is not perfect square\n",
            "7142 is not perfect square\n",
            "7143 is not perfect square\n",
            "7144 is not perfect square\n",
            "7145 is not perfect square\n",
            "7146 is not perfect square\n",
            "7147 is not perfect square\n",
            "7148 is not perfect square\n",
            "7149 is not perfect square\n",
            "7150 is not perfect square\n",
            "7151 is not perfect square\n",
            "7152 is not perfect square\n",
            "7153 is not perfect square\n",
            "7154 is not perfect square\n",
            "7155 is not perfect square\n",
            "7156 is not perfect square\n",
            "7157 is not perfect square\n",
            "7158 is not perfect square\n",
            "7159 is not perfect square\n",
            "7160 is not perfect square\n",
            "7161 is not perfect square\n",
            "7162 is not perfect square\n",
            "7163 is not perfect square\n",
            "7164 is not perfect square\n",
            "7165 is not perfect square\n",
            "7166 is not perfect square\n",
            "7167 is not perfect square\n",
            "7168 is not perfect square\n",
            "7169 is not perfect square\n",
            "7170 is not perfect square\n",
            "7171 is not perfect square\n",
            "7172 is not perfect square\n",
            "7173 is not perfect square\n",
            "7174 is not perfect square\n",
            "7175 is not perfect square\n",
            "7176 is not perfect square\n",
            "7177 is not perfect square\n",
            "7178 is not perfect square\n",
            "7179 is not perfect square\n",
            "7180 is not perfect square\n",
            "7181 is not perfect square\n",
            "7182 is not perfect square\n",
            "7183 is not perfect square\n",
            "7184 is not perfect square\n",
            "7185 is not perfect square\n",
            "7186 is not perfect square\n",
            "7187 is not perfect square\n",
            "7188 is not perfect square\n",
            "7189 is not perfect square\n",
            "7190 is not perfect square\n",
            "7191 is not perfect square\n",
            "7192 is not perfect square\n",
            "7193 is not perfect square\n",
            "7194 is not perfect square\n",
            "7195 is not perfect square\n",
            "7196 is not perfect square\n",
            "7197 is not perfect square\n",
            "7198 is not perfect square\n",
            "7199 is not perfect square\n",
            "7200 is not perfect square\n",
            "7201 is not perfect square\n",
            "7202 is not perfect square\n",
            "7203 is not perfect square\n",
            "7204 is not perfect square\n",
            "7205 is not perfect square\n",
            "7206 is not perfect square\n",
            "7207 is not perfect square\n",
            "7208 is not perfect square\n",
            "7209 is not perfect square\n",
            "7210 is not perfect square\n",
            "7211 is not perfect square\n",
            "7212 is not perfect square\n",
            "7213 is not perfect square\n",
            "7214 is not perfect square\n",
            "7215 is not perfect square\n",
            "7216 is not perfect square\n",
            "7217 is not perfect square\n",
            "7218 is not perfect square\n",
            "7219 is not perfect square\n",
            "7220 is not perfect square\n",
            "7221 is not perfect square\n",
            "7222 is not perfect square\n",
            "7223 is not perfect square\n",
            "7224 is not perfect square\n",
            "7225 is perfect square\n",
            "7226 is not perfect square\n",
            "7227 is not perfect square\n",
            "7228 is not perfect square\n",
            "7229 is not perfect square\n",
            "7230 is not perfect square\n",
            "7231 is not perfect square\n",
            "7232 is not perfect square\n",
            "7233 is not perfect square\n",
            "7234 is not perfect square\n",
            "7235 is not perfect square\n",
            "7236 is not perfect square\n",
            "7237 is not perfect square\n",
            "7238 is not perfect square\n",
            "7239 is not perfect square\n",
            "7240 is not perfect square\n",
            "7241 is not perfect square\n",
            "7242 is not perfect square\n",
            "7243 is not perfect square\n",
            "7244 is not perfect square\n",
            "7245 is not perfect square\n",
            "7246 is not perfect square\n",
            "7247 is not perfect square\n",
            "7248 is not perfect square\n",
            "7249 is not perfect square\n",
            "7250 is not perfect square\n",
            "7251 is not perfect square\n",
            "7252 is not perfect square\n",
            "7253 is not perfect square\n",
            "7254 is not perfect square\n",
            "7255 is not perfect square\n",
            "7256 is not perfect square\n",
            "7257 is not perfect square\n",
            "7258 is not perfect square\n",
            "7259 is not perfect square\n",
            "7260 is not perfect square\n",
            "7261 is not perfect square\n",
            "7262 is not perfect square\n",
            "7263 is not perfect square\n",
            "7264 is not perfect square\n",
            "7265 is not perfect square\n",
            "7266 is not perfect square\n",
            "7267 is not perfect square\n",
            "7268 is not perfect square\n",
            "7269 is not perfect square\n",
            "7270 is not perfect square\n",
            "7271 is not perfect square\n",
            "7272 is not perfect square\n",
            "7273 is not perfect square\n",
            "7274 is not perfect square\n",
            "7275 is not perfect square\n",
            "7276 is not perfect square\n",
            "7277 is not perfect square\n",
            "7278 is not perfect square\n",
            "7279 is not perfect square\n",
            "7280 is not perfect square\n",
            "7281 is not perfect square\n",
            "7282 is not perfect square\n",
            "7283 is not perfect square\n",
            "7284 is not perfect square\n",
            "7285 is not perfect square\n",
            "7286 is not perfect square\n",
            "7287 is not perfect square\n",
            "7288 is not perfect square\n",
            "7289 is not perfect square\n",
            "7290 is not perfect square\n",
            "7291 is not perfect square\n",
            "7292 is not perfect square\n",
            "7293 is not perfect square\n",
            "7294 is not perfect square\n",
            "7295 is not perfect square\n",
            "7296 is not perfect square\n",
            "7297 is not perfect square\n",
            "7298 is not perfect square\n",
            "7299 is not perfect square\n",
            "7300 is not perfect square\n",
            "7301 is not perfect square\n",
            "7302 is not perfect square\n",
            "7303 is not perfect square\n",
            "7304 is not perfect square\n",
            "7305 is not perfect square\n",
            "7306 is not perfect square\n",
            "7307 is not perfect square\n",
            "7308 is not perfect square\n",
            "7309 is not perfect square\n",
            "7310 is not perfect square\n",
            "7311 is not perfect square\n",
            "7312 is not perfect square\n",
            "7313 is not perfect square\n",
            "7314 is not perfect square\n",
            "7315 is not perfect square\n",
            "7316 is not perfect square\n",
            "7317 is not perfect square\n",
            "7318 is not perfect square\n",
            "7319 is not perfect square\n",
            "7320 is not perfect square\n",
            "7321 is not perfect square\n",
            "7322 is not perfect square\n",
            "7323 is not perfect square\n",
            "7324 is not perfect square\n",
            "7325 is not perfect square\n",
            "7326 is not perfect square\n",
            "7327 is not perfect square\n",
            "7328 is not perfect square\n",
            "7329 is not perfect square\n",
            "7330 is not perfect square\n",
            "7331 is not perfect square\n",
            "7332 is not perfect square\n",
            "7333 is not perfect square\n",
            "7334 is not perfect square\n",
            "7335 is not perfect square\n",
            "7336 is not perfect square\n",
            "7337 is not perfect square\n",
            "7338 is not perfect square\n",
            "7339 is not perfect square\n",
            "7340 is not perfect square\n",
            "7341 is not perfect square\n",
            "7342 is not perfect square\n",
            "7343 is not perfect square\n",
            "7344 is not perfect square\n",
            "7345 is not perfect square\n",
            "7346 is not perfect square\n",
            "7347 is not perfect square\n",
            "7348 is not perfect square\n",
            "7349 is not perfect square\n",
            "7350 is not perfect square\n",
            "7351 is not perfect square\n",
            "7352 is not perfect square\n",
            "7353 is not perfect square\n",
            "7354 is not perfect square\n",
            "7355 is not perfect square\n",
            "7356 is not perfect square\n",
            "7357 is not perfect square\n",
            "7358 is not perfect square\n",
            "7359 is not perfect square\n",
            "7360 is not perfect square\n",
            "7361 is not perfect square\n",
            "7362 is not perfect square\n",
            "7363 is not perfect square\n",
            "7364 is not perfect square\n",
            "7365 is not perfect square\n",
            "7366 is not perfect square\n",
            "7367 is not perfect square\n",
            "7368 is not perfect square\n",
            "7369 is not perfect square\n",
            "7370 is not perfect square\n",
            "7371 is not perfect square\n",
            "7372 is not perfect square\n",
            "7373 is not perfect square\n",
            "7374 is not perfect square\n",
            "7375 is not perfect square\n",
            "7376 is not perfect square\n",
            "7377 is not perfect square\n",
            "7378 is not perfect square\n",
            "7379 is not perfect square\n",
            "7380 is not perfect square\n",
            "7381 is not perfect square\n",
            "7382 is not perfect square\n",
            "7383 is not perfect square\n",
            "7384 is not perfect square\n",
            "7385 is not perfect square\n",
            "7386 is not perfect square\n",
            "7387 is not perfect square\n",
            "7388 is not perfect square\n",
            "7389 is not perfect square\n",
            "7390 is not perfect square\n",
            "7391 is not perfect square\n",
            "7392 is not perfect square\n",
            "7393 is not perfect square\n",
            "7394 is not perfect square\n",
            "7395 is not perfect square\n",
            "7396 is perfect square\n",
            "7397 is not perfect square\n",
            "7398 is not perfect square\n",
            "7399 is not perfect square\n",
            "7400 is not perfect square\n",
            "7401 is not perfect square\n",
            "7402 is not perfect square\n",
            "7403 is not perfect square\n",
            "7404 is not perfect square\n",
            "7405 is not perfect square\n",
            "7406 is not perfect square\n",
            "7407 is not perfect square\n",
            "7408 is not perfect square\n",
            "7409 is not perfect square\n",
            "7410 is not perfect square\n",
            "7411 is not perfect square\n",
            "7412 is not perfect square\n",
            "7413 is not perfect square\n",
            "7414 is not perfect square\n",
            "7415 is not perfect square\n",
            "7416 is not perfect square\n",
            "7417 is not perfect square\n",
            "7418 is not perfect square\n",
            "7419 is not perfect square\n",
            "7420 is not perfect square\n",
            "7421 is not perfect square\n",
            "7422 is not perfect square\n",
            "7423 is not perfect square\n",
            "7424 is not perfect square\n",
            "7425 is not perfect square\n",
            "7426 is not perfect square\n",
            "7427 is not perfect square\n",
            "7428 is not perfect square\n",
            "7429 is not perfect square\n",
            "7430 is not perfect square\n",
            "7431 is not perfect square\n",
            "7432 is not perfect square\n",
            "7433 is not perfect square\n",
            "7434 is not perfect square\n",
            "7435 is not perfect square\n",
            "7436 is not perfect square\n",
            "7437 is not perfect square\n",
            "7438 is not perfect square\n",
            "7439 is not perfect square\n",
            "7440 is not perfect square\n",
            "7441 is not perfect square\n",
            "7442 is not perfect square\n",
            "7443 is not perfect square\n",
            "7444 is not perfect square\n",
            "7445 is not perfect square\n",
            "7446 is not perfect square\n",
            "7447 is not perfect square\n",
            "7448 is not perfect square\n",
            "7449 is not perfect square\n",
            "7450 is not perfect square\n",
            "7451 is not perfect square\n",
            "7452 is not perfect square\n",
            "7453 is not perfect square\n",
            "7454 is not perfect square\n",
            "7455 is not perfect square\n",
            "7456 is not perfect square\n",
            "7457 is not perfect square\n",
            "7458 is not perfect square\n",
            "7459 is not perfect square\n",
            "7460 is not perfect square\n",
            "7461 is not perfect square\n",
            "7462 is not perfect square\n",
            "7463 is not perfect square\n",
            "7464 is not perfect square\n",
            "7465 is not perfect square\n",
            "7466 is not perfect square\n",
            "7467 is not perfect square\n",
            "7468 is not perfect square\n",
            "7469 is not perfect square\n",
            "7470 is not perfect square\n",
            "7471 is not perfect square\n",
            "7472 is not perfect square\n",
            "7473 is not perfect square\n",
            "7474 is not perfect square\n",
            "7475 is not perfect square\n",
            "7476 is not perfect square\n",
            "7477 is not perfect square\n",
            "7478 is not perfect square\n",
            "7479 is not perfect square\n",
            "7480 is not perfect square\n",
            "7481 is not perfect square\n",
            "7482 is not perfect square\n",
            "7483 is not perfect square\n",
            "7484 is not perfect square\n",
            "7485 is not perfect square\n",
            "7486 is not perfect square\n",
            "7487 is not perfect square\n",
            "7488 is not perfect square\n",
            "7489 is not perfect square\n",
            "7490 is not perfect square\n",
            "7491 is not perfect square\n",
            "7492 is not perfect square\n",
            "7493 is not perfect square\n",
            "7494 is not perfect square\n",
            "7495 is not perfect square\n",
            "7496 is not perfect square\n",
            "7497 is not perfect square\n",
            "7498 is not perfect square\n",
            "7499 is not perfect square\n",
            "7500 is not perfect square\n",
            "7501 is not perfect square\n",
            "7502 is not perfect square\n",
            "7503 is not perfect square\n",
            "7504 is not perfect square\n",
            "7505 is not perfect square\n",
            "7506 is not perfect square\n",
            "7507 is not perfect square\n",
            "7508 is not perfect square\n",
            "7509 is not perfect square\n",
            "7510 is not perfect square\n",
            "7511 is not perfect square\n",
            "7512 is not perfect square\n",
            "7513 is not perfect square\n",
            "7514 is not perfect square\n",
            "7515 is not perfect square\n",
            "7516 is not perfect square\n",
            "7517 is not perfect square\n",
            "7518 is not perfect square\n",
            "7519 is not perfect square\n",
            "7520 is not perfect square\n",
            "7521 is not perfect square\n",
            "7522 is not perfect square\n",
            "7523 is not perfect square\n",
            "7524 is not perfect square\n",
            "7525 is not perfect square\n",
            "7526 is not perfect square\n",
            "7527 is not perfect square\n",
            "7528 is not perfect square\n",
            "7529 is not perfect square\n",
            "7530 is not perfect square\n",
            "7531 is not perfect square\n",
            "7532 is not perfect square\n",
            "7533 is not perfect square\n",
            "7534 is not perfect square\n",
            "7535 is not perfect square\n",
            "7536 is not perfect square\n",
            "7537 is not perfect square\n",
            "7538 is not perfect square\n",
            "7539 is not perfect square\n",
            "7540 is not perfect square\n",
            "7541 is not perfect square\n",
            "7542 is not perfect square\n",
            "7543 is not perfect square\n",
            "7544 is not perfect square\n",
            "7545 is not perfect square\n",
            "7546 is not perfect square\n",
            "7547 is not perfect square\n",
            "7548 is not perfect square\n",
            "7549 is not perfect square\n",
            "7550 is not perfect square\n",
            "7551 is not perfect square\n",
            "7552 is not perfect square\n",
            "7553 is not perfect square\n",
            "7554 is not perfect square\n",
            "7555 is not perfect square\n",
            "7556 is not perfect square\n",
            "7557 is not perfect square\n",
            "7558 is not perfect square\n",
            "7559 is not perfect square\n",
            "7560 is not perfect square\n",
            "7561 is not perfect square\n",
            "7562 is not perfect square\n",
            "7563 is not perfect square\n",
            "7564 is not perfect square\n",
            "7565 is not perfect square\n",
            "7566 is not perfect square\n",
            "7567 is not perfect square\n",
            "7568 is not perfect square\n",
            "7569 is perfect square\n",
            "7570 is not perfect square\n",
            "7571 is not perfect square\n",
            "7572 is not perfect square\n",
            "7573 is not perfect square\n",
            "7574 is not perfect square\n",
            "7575 is not perfect square\n",
            "7576 is not perfect square\n",
            "7577 is not perfect square\n",
            "7578 is not perfect square\n",
            "7579 is not perfect square\n",
            "7580 is not perfect square\n",
            "7581 is not perfect square\n",
            "7582 is not perfect square\n",
            "7583 is not perfect square\n",
            "7584 is not perfect square\n",
            "7585 is not perfect square\n",
            "7586 is not perfect square\n",
            "7587 is not perfect square\n",
            "7588 is not perfect square\n",
            "7589 is not perfect square\n",
            "7590 is not perfect square\n",
            "7591 is not perfect square\n",
            "7592 is not perfect square\n",
            "7593 is not perfect square\n",
            "7594 is not perfect square\n",
            "7595 is not perfect square\n",
            "7596 is not perfect square\n",
            "7597 is not perfect square\n",
            "7598 is not perfect square\n",
            "7599 is not perfect square\n",
            "7600 is not perfect square\n",
            "7601 is not perfect square\n",
            "7602 is not perfect square\n",
            "7603 is not perfect square\n",
            "7604 is not perfect square\n",
            "7605 is not perfect square\n",
            "7606 is not perfect square\n",
            "7607 is not perfect square\n",
            "7608 is not perfect square\n",
            "7609 is not perfect square\n",
            "7610 is not perfect square\n",
            "7611 is not perfect square\n",
            "7612 is not perfect square\n",
            "7613 is not perfect square\n",
            "7614 is not perfect square\n",
            "7615 is not perfect square\n",
            "7616 is not perfect square\n",
            "7617 is not perfect square\n",
            "7618 is not perfect square\n",
            "7619 is not perfect square\n",
            "7620 is not perfect square\n",
            "7621 is not perfect square\n",
            "7622 is not perfect square\n",
            "7623 is not perfect square\n",
            "7624 is not perfect square\n",
            "7625 is not perfect square\n",
            "7626 is not perfect square\n",
            "7627 is not perfect square\n",
            "7628 is not perfect square\n",
            "7629 is not perfect square\n",
            "7630 is not perfect square\n",
            "7631 is not perfect square\n",
            "7632 is not perfect square\n",
            "7633 is not perfect square\n",
            "7634 is not perfect square\n",
            "7635 is not perfect square\n",
            "7636 is not perfect square\n",
            "7637 is not perfect square\n",
            "7638 is not perfect square\n",
            "7639 is not perfect square\n",
            "7640 is not perfect square\n",
            "7641 is not perfect square\n",
            "7642 is not perfect square\n",
            "7643 is not perfect square\n",
            "7644 is not perfect square\n",
            "7645 is not perfect square\n",
            "7646 is not perfect square\n",
            "7647 is not perfect square\n",
            "7648 is not perfect square\n",
            "7649 is not perfect square\n",
            "7650 is not perfect square\n",
            "7651 is not perfect square\n",
            "7652 is not perfect square\n",
            "7653 is not perfect square\n",
            "7654 is not perfect square\n",
            "7655 is not perfect square\n",
            "7656 is not perfect square\n",
            "7657 is not perfect square\n",
            "7658 is not perfect square\n",
            "7659 is not perfect square\n",
            "7660 is not perfect square\n",
            "7661 is not perfect square\n",
            "7662 is not perfect square\n",
            "7663 is not perfect square\n",
            "7664 is not perfect square\n",
            "7665 is not perfect square\n",
            "7666 is not perfect square\n",
            "7667 is not perfect square\n",
            "7668 is not perfect square\n",
            "7669 is not perfect square\n",
            "7670 is not perfect square\n",
            "7671 is not perfect square\n",
            "7672 is not perfect square\n",
            "7673 is not perfect square\n",
            "7674 is not perfect square\n",
            "7675 is not perfect square\n",
            "7676 is not perfect square\n",
            "7677 is not perfect square\n",
            "7678 is not perfect square\n",
            "7679 is not perfect square\n",
            "7680 is not perfect square\n",
            "7681 is not perfect square\n",
            "7682 is not perfect square\n",
            "7683 is not perfect square\n",
            "7684 is not perfect square\n",
            "7685 is not perfect square\n",
            "7686 is not perfect square\n",
            "7687 is not perfect square\n",
            "7688 is not perfect square\n",
            "7689 is not perfect square\n",
            "7690 is not perfect square\n",
            "7691 is not perfect square\n",
            "7692 is not perfect square\n",
            "7693 is not perfect square\n",
            "7694 is not perfect square\n",
            "7695 is not perfect square\n",
            "7696 is not perfect square\n",
            "7697 is not perfect square\n",
            "7698 is not perfect square\n",
            "7699 is not perfect square\n",
            "7700 is not perfect square\n",
            "7701 is not perfect square\n",
            "7702 is not perfect square\n",
            "7703 is not perfect square\n",
            "7704 is not perfect square\n",
            "7705 is not perfect square\n",
            "7706 is not perfect square\n",
            "7707 is not perfect square\n",
            "7708 is not perfect square\n",
            "7709 is not perfect square\n",
            "7710 is not perfect square\n",
            "7711 is not perfect square\n",
            "7712 is not perfect square\n",
            "7713 is not perfect square\n",
            "7714 is not perfect square\n",
            "7715 is not perfect square\n",
            "7716 is not perfect square\n",
            "7717 is not perfect square\n",
            "7718 is not perfect square\n",
            "7719 is not perfect square\n",
            "7720 is not perfect square\n",
            "7721 is not perfect square\n",
            "7722 is not perfect square\n",
            "7723 is not perfect square\n",
            "7724 is not perfect square\n",
            "7725 is not perfect square\n",
            "7726 is not perfect square\n",
            "7727 is not perfect square\n",
            "7728 is not perfect square\n",
            "7729 is not perfect square\n",
            "7730 is not perfect square\n",
            "7731 is not perfect square\n",
            "7732 is not perfect square\n",
            "7733 is not perfect square\n",
            "7734 is not perfect square\n",
            "7735 is not perfect square\n",
            "7736 is not perfect square\n",
            "7737 is not perfect square\n",
            "7738 is not perfect square\n",
            "7739 is not perfect square\n",
            "7740 is not perfect square\n",
            "7741 is not perfect square\n",
            "7742 is not perfect square\n",
            "7743 is not perfect square\n",
            "7744 is perfect square\n",
            "7745 is not perfect square\n",
            "7746 is not perfect square\n",
            "7747 is not perfect square\n",
            "7748 is not perfect square\n",
            "7749 is not perfect square\n",
            "7750 is not perfect square\n",
            "7751 is not perfect square\n",
            "7752 is not perfect square\n",
            "7753 is not perfect square\n",
            "7754 is not perfect square\n",
            "7755 is not perfect square\n",
            "7756 is not perfect square\n",
            "7757 is not perfect square\n",
            "7758 is not perfect square\n",
            "7759 is not perfect square\n",
            "7760 is not perfect square\n",
            "7761 is not perfect square\n",
            "7762 is not perfect square\n",
            "7763 is not perfect square\n",
            "7764 is not perfect square\n",
            "7765 is not perfect square\n",
            "7766 is not perfect square\n",
            "7767 is not perfect square\n",
            "7768 is not perfect square\n",
            "7769 is not perfect square\n",
            "7770 is not perfect square\n",
            "7771 is not perfect square\n",
            "7772 is not perfect square\n",
            "7773 is not perfect square\n",
            "7774 is not perfect square\n",
            "7775 is not perfect square\n",
            "7776 is not perfect square\n",
            "7777 is not perfect square\n",
            "7778 is not perfect square\n",
            "7779 is not perfect square\n",
            "7780 is not perfect square\n",
            "7781 is not perfect square\n",
            "7782 is not perfect square\n",
            "7783 is not perfect square\n",
            "7784 is not perfect square\n",
            "7785 is not perfect square\n",
            "7786 is not perfect square\n",
            "7787 is not perfect square\n",
            "7788 is not perfect square\n",
            "7789 is not perfect square\n",
            "7790 is not perfect square\n",
            "7791 is not perfect square\n",
            "7792 is not perfect square\n",
            "7793 is not perfect square\n",
            "7794 is not perfect square\n",
            "7795 is not perfect square\n",
            "7796 is not perfect square\n",
            "7797 is not perfect square\n",
            "7798 is not perfect square\n",
            "7799 is not perfect square\n",
            "7800 is not perfect square\n",
            "7801 is not perfect square\n",
            "7802 is not perfect square\n",
            "7803 is not perfect square\n",
            "7804 is not perfect square\n",
            "7805 is not perfect square\n",
            "7806 is not perfect square\n",
            "7807 is not perfect square\n",
            "7808 is not perfect square\n",
            "7809 is not perfect square\n",
            "7810 is not perfect square\n",
            "7811 is not perfect square\n",
            "7812 is not perfect square\n",
            "7813 is not perfect square\n",
            "7814 is not perfect square\n",
            "7815 is not perfect square\n",
            "7816 is not perfect square\n",
            "7817 is not perfect square\n",
            "7818 is not perfect square\n",
            "7819 is not perfect square\n",
            "7820 is not perfect square\n",
            "7821 is not perfect square\n",
            "7822 is not perfect square\n",
            "7823 is not perfect square\n",
            "7824 is not perfect square\n",
            "7825 is not perfect square\n",
            "7826 is not perfect square\n",
            "7827 is not perfect square\n",
            "7828 is not perfect square\n",
            "7829 is not perfect square\n",
            "7830 is not perfect square\n",
            "7831 is not perfect square\n",
            "7832 is not perfect square\n",
            "7833 is not perfect square\n",
            "7834 is not perfect square\n",
            "7835 is not perfect square\n",
            "7836 is not perfect square\n",
            "7837 is not perfect square\n",
            "7838 is not perfect square\n",
            "7839 is not perfect square\n",
            "7840 is not perfect square\n",
            "7841 is not perfect square\n",
            "7842 is not perfect square\n",
            "7843 is not perfect square\n",
            "7844 is not perfect square\n",
            "7845 is not perfect square\n",
            "7846 is not perfect square\n",
            "7847 is not perfect square\n",
            "7848 is not perfect square\n",
            "7849 is not perfect square\n",
            "7850 is not perfect square\n",
            "7851 is not perfect square\n",
            "7852 is not perfect square\n",
            "7853 is not perfect square\n",
            "7854 is not perfect square\n",
            "7855 is not perfect square\n",
            "7856 is not perfect square\n",
            "7857 is not perfect square\n",
            "7858 is not perfect square\n",
            "7859 is not perfect square\n",
            "7860 is not perfect square\n",
            "7861 is not perfect square\n",
            "7862 is not perfect square\n",
            "7863 is not perfect square\n",
            "7864 is not perfect square\n",
            "7865 is not perfect square\n",
            "7866 is not perfect square\n",
            "7867 is not perfect square\n",
            "7868 is not perfect square\n",
            "7869 is not perfect square\n",
            "7870 is not perfect square\n",
            "7871 is not perfect square\n",
            "7872 is not perfect square\n",
            "7873 is not perfect square\n",
            "7874 is not perfect square\n",
            "7875 is not perfect square\n",
            "7876 is not perfect square\n",
            "7877 is not perfect square\n",
            "7878 is not perfect square\n",
            "7879 is not perfect square\n",
            "7880 is not perfect square\n",
            "7881 is not perfect square\n",
            "7882 is not perfect square\n",
            "7883 is not perfect square\n",
            "7884 is not perfect square\n",
            "7885 is not perfect square\n",
            "7886 is not perfect square\n",
            "7887 is not perfect square\n",
            "7888 is not perfect square\n",
            "7889 is not perfect square\n",
            "7890 is not perfect square\n",
            "7891 is not perfect square\n",
            "7892 is not perfect square\n",
            "7893 is not perfect square\n",
            "7894 is not perfect square\n",
            "7895 is not perfect square\n",
            "7896 is not perfect square\n",
            "7897 is not perfect square\n",
            "7898 is not perfect square\n",
            "7899 is not perfect square\n",
            "7900 is not perfect square\n",
            "7901 is not perfect square\n",
            "7902 is not perfect square\n",
            "7903 is not perfect square\n",
            "7904 is not perfect square\n",
            "7905 is not perfect square\n",
            "7906 is not perfect square\n",
            "7907 is not perfect square\n",
            "7908 is not perfect square\n",
            "7909 is not perfect square\n",
            "7910 is not perfect square\n",
            "7911 is not perfect square\n",
            "7912 is not perfect square\n",
            "7913 is not perfect square\n",
            "7914 is not perfect square\n",
            "7915 is not perfect square\n",
            "7916 is not perfect square\n",
            "7917 is not perfect square\n",
            "7918 is not perfect square\n",
            "7919 is not perfect square\n",
            "7920 is not perfect square\n",
            "7921 is perfect square\n",
            "7922 is not perfect square\n",
            "7923 is not perfect square\n",
            "7924 is not perfect square\n",
            "7925 is not perfect square\n",
            "7926 is not perfect square\n",
            "7927 is not perfect square\n",
            "7928 is not perfect square\n",
            "7929 is not perfect square\n",
            "7930 is not perfect square\n",
            "7931 is not perfect square\n",
            "7932 is not perfect square\n",
            "7933 is not perfect square\n",
            "7934 is not perfect square\n",
            "7935 is not perfect square\n",
            "7936 is not perfect square\n",
            "7937 is not perfect square\n",
            "7938 is not perfect square\n",
            "7939 is not perfect square\n",
            "7940 is not perfect square\n",
            "7941 is not perfect square\n",
            "7942 is not perfect square\n",
            "7943 is not perfect square\n",
            "7944 is not perfect square\n",
            "7945 is not perfect square\n",
            "7946 is not perfect square\n",
            "7947 is not perfect square\n",
            "7948 is not perfect square\n",
            "7949 is not perfect square\n",
            "7950 is not perfect square\n",
            "7951 is not perfect square\n",
            "7952 is not perfect square\n",
            "7953 is not perfect square\n",
            "7954 is not perfect square\n",
            "7955 is not perfect square\n",
            "7956 is not perfect square\n",
            "7957 is not perfect square\n",
            "7958 is not perfect square\n",
            "7959 is not perfect square\n",
            "7960 is not perfect square\n",
            "7961 is not perfect square\n",
            "7962 is not perfect square\n",
            "7963 is not perfect square\n",
            "7964 is not perfect square\n",
            "7965 is not perfect square\n",
            "7966 is not perfect square\n",
            "7967 is not perfect square\n",
            "7968 is not perfect square\n",
            "7969 is not perfect square\n",
            "7970 is not perfect square\n",
            "7971 is not perfect square\n",
            "7972 is not perfect square\n",
            "7973 is not perfect square\n",
            "7974 is not perfect square\n",
            "7975 is not perfect square\n",
            "7976 is not perfect square\n",
            "7977 is not perfect square\n",
            "7978 is not perfect square\n",
            "7979 is not perfect square\n",
            "7980 is not perfect square\n",
            "7981 is not perfect square\n",
            "7982 is not perfect square\n",
            "7983 is not perfect square\n",
            "7984 is not perfect square\n",
            "7985 is not perfect square\n",
            "7986 is not perfect square\n",
            "7987 is not perfect square\n",
            "7988 is not perfect square\n",
            "7989 is not perfect square\n",
            "7990 is not perfect square\n",
            "7991 is not perfect square\n",
            "7992 is not perfect square\n",
            "7993 is not perfect square\n",
            "7994 is not perfect square\n",
            "7995 is not perfect square\n",
            "7996 is not perfect square\n",
            "7997 is not perfect square\n",
            "7998 is not perfect square\n",
            "7999 is not perfect square\n",
            "8000 is not perfect square\n",
            "8001 is not perfect square\n",
            "8002 is not perfect square\n",
            "8003 is not perfect square\n",
            "8004 is not perfect square\n",
            "8005 is not perfect square\n",
            "8006 is not perfect square\n",
            "8007 is not perfect square\n",
            "8008 is not perfect square\n",
            "8009 is not perfect square\n",
            "8010 is not perfect square\n",
            "8011 is not perfect square\n",
            "8012 is not perfect square\n",
            "8013 is not perfect square\n",
            "8014 is not perfect square\n",
            "8015 is not perfect square\n",
            "8016 is not perfect square\n",
            "8017 is not perfect square\n",
            "8018 is not perfect square\n",
            "8019 is not perfect square\n",
            "8020 is not perfect square\n",
            "8021 is not perfect square\n",
            "8022 is not perfect square\n",
            "8023 is not perfect square\n",
            "8024 is not perfect square\n",
            "8025 is not perfect square\n",
            "8026 is not perfect square\n",
            "8027 is not perfect square\n",
            "8028 is not perfect square\n",
            "8029 is not perfect square\n",
            "8030 is not perfect square\n",
            "8031 is not perfect square\n",
            "8032 is not perfect square\n",
            "8033 is not perfect square\n",
            "8034 is not perfect square\n",
            "8035 is not perfect square\n",
            "8036 is not perfect square\n",
            "8037 is not perfect square\n",
            "8038 is not perfect square\n",
            "8039 is not perfect square\n",
            "8040 is not perfect square\n",
            "8041 is not perfect square\n",
            "8042 is not perfect square\n",
            "8043 is not perfect square\n",
            "8044 is not perfect square\n",
            "8045 is not perfect square\n",
            "8046 is not perfect square\n",
            "8047 is not perfect square\n",
            "8048 is not perfect square\n",
            "8049 is not perfect square\n",
            "8050 is not perfect square\n",
            "8051 is not perfect square\n",
            "8052 is not perfect square\n",
            "8053 is not perfect square\n",
            "8054 is not perfect square\n",
            "8055 is not perfect square\n",
            "8056 is not perfect square\n",
            "8057 is not perfect square\n",
            "8058 is not perfect square\n",
            "8059 is not perfect square\n",
            "8060 is not perfect square\n",
            "8061 is not perfect square\n",
            "8062 is not perfect square\n",
            "8063 is not perfect square\n",
            "8064 is not perfect square\n",
            "8065 is not perfect square\n",
            "8066 is not perfect square\n",
            "8067 is not perfect square\n",
            "8068 is not perfect square\n",
            "8069 is not perfect square\n",
            "8070 is not perfect square\n",
            "8071 is not perfect square\n",
            "8072 is not perfect square\n",
            "8073 is not perfect square\n",
            "8074 is not perfect square\n",
            "8075 is not perfect square\n",
            "8076 is not perfect square\n",
            "8077 is not perfect square\n",
            "8078 is not perfect square\n",
            "8079 is not perfect square\n",
            "8080 is not perfect square\n",
            "8081 is not perfect square\n",
            "8082 is not perfect square\n",
            "8083 is not perfect square\n",
            "8084 is not perfect square\n",
            "8085 is not perfect square\n",
            "8086 is not perfect square\n",
            "8087 is not perfect square\n",
            "8088 is not perfect square\n",
            "8089 is not perfect square\n",
            "8090 is not perfect square\n",
            "8091 is not perfect square\n",
            "8092 is not perfect square\n",
            "8093 is not perfect square\n",
            "8094 is not perfect square\n",
            "8095 is not perfect square\n",
            "8096 is not perfect square\n",
            "8097 is not perfect square\n",
            "8098 is not perfect square\n",
            "8099 is not perfect square\n",
            "8100 is perfect square\n",
            "8101 is not perfect square\n",
            "8102 is not perfect square\n",
            "8103 is not perfect square\n",
            "8104 is not perfect square\n",
            "8105 is not perfect square\n",
            "8106 is not perfect square\n",
            "8107 is not perfect square\n",
            "8108 is not perfect square\n",
            "8109 is not perfect square\n",
            "8110 is not perfect square\n",
            "8111 is not perfect square\n",
            "8112 is not perfect square\n",
            "8113 is not perfect square\n",
            "8114 is not perfect square\n",
            "8115 is not perfect square\n",
            "8116 is not perfect square\n",
            "8117 is not perfect square\n",
            "8118 is not perfect square\n",
            "8119 is not perfect square\n",
            "8120 is not perfect square\n",
            "8121 is not perfect square\n",
            "8122 is not perfect square\n",
            "8123 is not perfect square\n",
            "8124 is not perfect square\n",
            "8125 is not perfect square\n",
            "8126 is not perfect square\n",
            "8127 is not perfect square\n",
            "8128 is not perfect square\n",
            "8129 is not perfect square\n",
            "8130 is not perfect square\n",
            "8131 is not perfect square\n",
            "8132 is not perfect square\n",
            "8133 is not perfect square\n",
            "8134 is not perfect square\n",
            "8135 is not perfect square\n",
            "8136 is not perfect square\n",
            "8137 is not perfect square\n",
            "8138 is not perfect square\n",
            "8139 is not perfect square\n",
            "8140 is not perfect square\n",
            "8141 is not perfect square\n",
            "8142 is not perfect square\n",
            "8143 is not perfect square\n",
            "8144 is not perfect square\n",
            "8145 is not perfect square\n",
            "8146 is not perfect square\n",
            "8147 is not perfect square\n",
            "8148 is not perfect square\n",
            "8149 is not perfect square\n",
            "8150 is not perfect square\n",
            "8151 is not perfect square\n",
            "8152 is not perfect square\n",
            "8153 is not perfect square\n",
            "8154 is not perfect square\n",
            "8155 is not perfect square\n",
            "8156 is not perfect square\n",
            "8157 is not perfect square\n",
            "8158 is not perfect square\n",
            "8159 is not perfect square\n",
            "8160 is not perfect square\n",
            "8161 is not perfect square\n",
            "8162 is not perfect square\n",
            "8163 is not perfect square\n",
            "8164 is not perfect square\n",
            "8165 is not perfect square\n",
            "8166 is not perfect square\n",
            "8167 is not perfect square\n",
            "8168 is not perfect square\n",
            "8169 is not perfect square\n",
            "8170 is not perfect square\n",
            "8171 is not perfect square\n",
            "8172 is not perfect square\n",
            "8173 is not perfect square\n",
            "8174 is not perfect square\n",
            "8175 is not perfect square\n",
            "8176 is not perfect square\n",
            "8177 is not perfect square\n",
            "8178 is not perfect square\n",
            "8179 is not perfect square\n",
            "8180 is not perfect square\n",
            "8181 is not perfect square\n",
            "8182 is not perfect square\n",
            "8183 is not perfect square\n",
            "8184 is not perfect square\n",
            "8185 is not perfect square\n",
            "8186 is not perfect square\n",
            "8187 is not perfect square\n",
            "8188 is not perfect square\n",
            "8189 is not perfect square\n",
            "8190 is not perfect square\n",
            "8191 is not perfect square\n",
            "8192 is not perfect square\n",
            "8193 is not perfect square\n",
            "8194 is not perfect square\n",
            "8195 is not perfect square\n",
            "8196 is not perfect square\n",
            "8197 is not perfect square\n",
            "8198 is not perfect square\n",
            "8199 is not perfect square\n",
            "8200 is not perfect square\n",
            "8201 is not perfect square\n",
            "8202 is not perfect square\n",
            "8203 is not perfect square\n",
            "8204 is not perfect square\n",
            "8205 is not perfect square\n",
            "8206 is not perfect square\n",
            "8207 is not perfect square\n",
            "8208 is not perfect square\n",
            "8209 is not perfect square\n",
            "8210 is not perfect square\n",
            "8211 is not perfect square\n",
            "8212 is not perfect square\n",
            "8213 is not perfect square\n",
            "8214 is not perfect square\n",
            "8215 is not perfect square\n",
            "8216 is not perfect square\n",
            "8217 is not perfect square\n",
            "8218 is not perfect square\n",
            "8219 is not perfect square\n",
            "8220 is not perfect square\n",
            "8221 is not perfect square\n",
            "8222 is not perfect square\n",
            "8223 is not perfect square\n",
            "8224 is not perfect square\n",
            "8225 is not perfect square\n",
            "8226 is not perfect square\n",
            "8227 is not perfect square\n",
            "8228 is not perfect square\n",
            "8229 is not perfect square\n",
            "8230 is not perfect square\n",
            "8231 is not perfect square\n",
            "8232 is not perfect square\n",
            "8233 is not perfect square\n",
            "8234 is not perfect square\n",
            "8235 is not perfect square\n",
            "8236 is not perfect square\n",
            "8237 is not perfect square\n",
            "8238 is not perfect square\n",
            "8239 is not perfect square\n",
            "8240 is not perfect square\n",
            "8241 is not perfect square\n",
            "8242 is not perfect square\n",
            "8243 is not perfect square\n",
            "8244 is not perfect square\n",
            "8245 is not perfect square\n",
            "8246 is not perfect square\n",
            "8247 is not perfect square\n",
            "8248 is not perfect square\n",
            "8249 is not perfect square\n",
            "8250 is not perfect square\n",
            "8251 is not perfect square\n",
            "8252 is not perfect square\n",
            "8253 is not perfect square\n",
            "8254 is not perfect square\n",
            "8255 is not perfect square\n",
            "8256 is not perfect square\n",
            "8257 is not perfect square\n",
            "8258 is not perfect square\n",
            "8259 is not perfect square\n",
            "8260 is not perfect square\n",
            "8261 is not perfect square\n",
            "8262 is not perfect square\n",
            "8263 is not perfect square\n",
            "8264 is not perfect square\n",
            "8265 is not perfect square\n",
            "8266 is not perfect square\n",
            "8267 is not perfect square\n",
            "8268 is not perfect square\n",
            "8269 is not perfect square\n",
            "8270 is not perfect square\n",
            "8271 is not perfect square\n",
            "8272 is not perfect square\n",
            "8273 is not perfect square\n",
            "8274 is not perfect square\n",
            "8275 is not perfect square\n",
            "8276 is not perfect square\n",
            "8277 is not perfect square\n",
            "8278 is not perfect square\n",
            "8279 is not perfect square\n",
            "8280 is not perfect square\n",
            "8281 is perfect square\n",
            "8282 is not perfect square\n",
            "8283 is not perfect square\n",
            "8284 is not perfect square\n",
            "8285 is not perfect square\n",
            "8286 is not perfect square\n",
            "8287 is not perfect square\n",
            "8288 is not perfect square\n",
            "8289 is not perfect square\n",
            "8290 is not perfect square\n",
            "8291 is not perfect square\n",
            "8292 is not perfect square\n",
            "8293 is not perfect square\n",
            "8294 is not perfect square\n",
            "8295 is not perfect square\n",
            "8296 is not perfect square\n",
            "8297 is not perfect square\n",
            "8298 is not perfect square\n",
            "8299 is not perfect square\n",
            "8300 is not perfect square\n",
            "8301 is not perfect square\n",
            "8302 is not perfect square\n",
            "8303 is not perfect square\n",
            "8304 is not perfect square\n",
            "8305 is not perfect square\n",
            "8306 is not perfect square\n",
            "8307 is not perfect square\n",
            "8308 is not perfect square\n",
            "8309 is not perfect square\n",
            "8310 is not perfect square\n",
            "8311 is not perfect square\n",
            "8312 is not perfect square\n",
            "8313 is not perfect square\n",
            "8314 is not perfect square\n",
            "8315 is not perfect square\n",
            "8316 is not perfect square\n",
            "8317 is not perfect square\n",
            "8318 is not perfect square\n",
            "8319 is not perfect square\n",
            "8320 is not perfect square\n",
            "8321 is not perfect square\n",
            "8322 is not perfect square\n",
            "8323 is not perfect square\n",
            "8324 is not perfect square\n",
            "8325 is not perfect square\n",
            "8326 is not perfect square\n",
            "8327 is not perfect square\n",
            "8328 is not perfect square\n",
            "8329 is not perfect square\n",
            "8330 is not perfect square\n",
            "8331 is not perfect square\n",
            "8332 is not perfect square\n",
            "8333 is not perfect square\n",
            "8334 is not perfect square\n",
            "8335 is not perfect square\n",
            "8336 is not perfect square\n",
            "8337 is not perfect square\n",
            "8338 is not perfect square\n",
            "8339 is not perfect square\n",
            "8340 is not perfect square\n",
            "8341 is not perfect square\n",
            "8342 is not perfect square\n",
            "8343 is not perfect square\n",
            "8344 is not perfect square\n",
            "8345 is not perfect square\n",
            "8346 is not perfect square\n",
            "8347 is not perfect square\n",
            "8348 is not perfect square\n",
            "8349 is not perfect square\n",
            "8350 is not perfect square\n",
            "8351 is not perfect square\n",
            "8352 is not perfect square\n",
            "8353 is not perfect square\n",
            "8354 is not perfect square\n",
            "8355 is not perfect square\n",
            "8356 is not perfect square\n",
            "8357 is not perfect square\n",
            "8358 is not perfect square\n",
            "8359 is not perfect square\n",
            "8360 is not perfect square\n",
            "8361 is not perfect square\n",
            "8362 is not perfect square\n",
            "8363 is not perfect square\n",
            "8364 is not perfect square\n",
            "8365 is not perfect square\n",
            "8366 is not perfect square\n",
            "8367 is not perfect square\n",
            "8368 is not perfect square\n",
            "8369 is not perfect square\n",
            "8370 is not perfect square\n",
            "8371 is not perfect square\n",
            "8372 is not perfect square\n",
            "8373 is not perfect square\n",
            "8374 is not perfect square\n",
            "8375 is not perfect square\n",
            "8376 is not perfect square\n",
            "8377 is not perfect square\n",
            "8378 is not perfect square\n",
            "8379 is not perfect square\n",
            "8380 is not perfect square\n",
            "8381 is not perfect square\n",
            "8382 is not perfect square\n",
            "8383 is not perfect square\n",
            "8384 is not perfect square\n",
            "8385 is not perfect square\n",
            "8386 is not perfect square\n",
            "8387 is not perfect square\n",
            "8388 is not perfect square\n",
            "8389 is not perfect square\n",
            "8390 is not perfect square\n",
            "8391 is not perfect square\n",
            "8392 is not perfect square\n",
            "8393 is not perfect square\n",
            "8394 is not perfect square\n",
            "8395 is not perfect square\n",
            "8396 is not perfect square\n",
            "8397 is not perfect square\n",
            "8398 is not perfect square\n",
            "8399 is not perfect square\n",
            "8400 is not perfect square\n",
            "8401 is not perfect square\n",
            "8402 is not perfect square\n",
            "8403 is not perfect square\n",
            "8404 is not perfect square\n",
            "8405 is not perfect square\n",
            "8406 is not perfect square\n",
            "8407 is not perfect square\n",
            "8408 is not perfect square\n",
            "8409 is not perfect square\n",
            "8410 is not perfect square\n",
            "8411 is not perfect square\n",
            "8412 is not perfect square\n",
            "8413 is not perfect square\n",
            "8414 is not perfect square\n",
            "8415 is not perfect square\n",
            "8416 is not perfect square\n",
            "8417 is not perfect square\n",
            "8418 is not perfect square\n",
            "8419 is not perfect square\n",
            "8420 is not perfect square\n",
            "8421 is not perfect square\n",
            "8422 is not perfect square\n",
            "8423 is not perfect square\n",
            "8424 is not perfect square\n",
            "8425 is not perfect square\n",
            "8426 is not perfect square\n",
            "8427 is not perfect square\n",
            "8428 is not perfect square\n",
            "8429 is not perfect square\n",
            "8430 is not perfect square\n",
            "8431 is not perfect square\n",
            "8432 is not perfect square\n",
            "8433 is not perfect square\n",
            "8434 is not perfect square\n",
            "8435 is not perfect square\n",
            "8436 is not perfect square\n",
            "8437 is not perfect square\n",
            "8438 is not perfect square\n",
            "8439 is not perfect square\n",
            "8440 is not perfect square\n",
            "8441 is not perfect square\n",
            "8442 is not perfect square\n",
            "8443 is not perfect square\n",
            "8444 is not perfect square\n",
            "8445 is not perfect square\n",
            "8446 is not perfect square\n",
            "8447 is not perfect square\n",
            "8448 is not perfect square\n",
            "8449 is not perfect square\n",
            "8450 is not perfect square\n",
            "8451 is not perfect square\n",
            "8452 is not perfect square\n",
            "8453 is not perfect square\n",
            "8454 is not perfect square\n",
            "8455 is not perfect square\n",
            "8456 is not perfect square\n",
            "8457 is not perfect square\n",
            "8458 is not perfect square\n",
            "8459 is not perfect square\n",
            "8460 is not perfect square\n",
            "8461 is not perfect square\n",
            "8462 is not perfect square\n",
            "8463 is not perfect square\n",
            "8464 is perfect square\n",
            "8465 is not perfect square\n",
            "8466 is not perfect square\n",
            "8467 is not perfect square\n",
            "8468 is not perfect square\n",
            "8469 is not perfect square\n",
            "8470 is not perfect square\n",
            "8471 is not perfect square\n",
            "8472 is not perfect square\n",
            "8473 is not perfect square\n",
            "8474 is not perfect square\n",
            "8475 is not perfect square\n",
            "8476 is not perfect square\n",
            "8477 is not perfect square\n",
            "8478 is not perfect square\n",
            "8479 is not perfect square\n",
            "8480 is not perfect square\n",
            "8481 is not perfect square\n",
            "8482 is not perfect square\n",
            "8483 is not perfect square\n",
            "8484 is not perfect square\n",
            "8485 is not perfect square\n",
            "8486 is not perfect square\n",
            "8487 is not perfect square\n",
            "8488 is not perfect square\n",
            "8489 is not perfect square\n",
            "8490 is not perfect square\n",
            "8491 is not perfect square\n",
            "8492 is not perfect square\n",
            "8493 is not perfect square\n",
            "8494 is not perfect square\n",
            "8495 is not perfect square\n",
            "8496 is not perfect square\n",
            "8497 is not perfect square\n",
            "8498 is not perfect square\n",
            "8499 is not perfect square\n",
            "8500 is not perfect square\n",
            "8501 is not perfect square\n",
            "8502 is not perfect square\n",
            "8503 is not perfect square\n",
            "8504 is not perfect square\n",
            "8505 is not perfect square\n",
            "8506 is not perfect square\n",
            "8507 is not perfect square\n",
            "8508 is not perfect square\n",
            "8509 is not perfect square\n",
            "8510 is not perfect square\n",
            "8511 is not perfect square\n",
            "8512 is not perfect square\n",
            "8513 is not perfect square\n",
            "8514 is not perfect square\n",
            "8515 is not perfect square\n",
            "8516 is not perfect square\n",
            "8517 is not perfect square\n",
            "8518 is not perfect square\n",
            "8519 is not perfect square\n",
            "8520 is not perfect square\n",
            "8521 is not perfect square\n",
            "8522 is not perfect square\n",
            "8523 is not perfect square\n",
            "8524 is not perfect square\n",
            "8525 is not perfect square\n",
            "8526 is not perfect square\n",
            "8527 is not perfect square\n",
            "8528 is not perfect square\n",
            "8529 is not perfect square\n",
            "8530 is not perfect square\n",
            "8531 is not perfect square\n",
            "8532 is not perfect square\n",
            "8533 is not perfect square\n",
            "8534 is not perfect square\n",
            "8535 is not perfect square\n",
            "8536 is not perfect square\n",
            "8537 is not perfect square\n",
            "8538 is not perfect square\n",
            "8539 is not perfect square\n",
            "8540 is not perfect square\n",
            "8541 is not perfect square\n",
            "8542 is not perfect square\n",
            "8543 is not perfect square\n",
            "8544 is not perfect square\n",
            "8545 is not perfect square\n",
            "8546 is not perfect square\n",
            "8547 is not perfect square\n",
            "8548 is not perfect square\n",
            "8549 is not perfect square\n",
            "8550 is not perfect square\n",
            "8551 is not perfect square\n",
            "8552 is not perfect square\n",
            "8553 is not perfect square\n",
            "8554 is not perfect square\n",
            "8555 is not perfect square\n",
            "8556 is not perfect square\n",
            "8557 is not perfect square\n",
            "8558 is not perfect square\n",
            "8559 is not perfect square\n",
            "8560 is not perfect square\n",
            "8561 is not perfect square\n",
            "8562 is not perfect square\n",
            "8563 is not perfect square\n",
            "8564 is not perfect square\n",
            "8565 is not perfect square\n",
            "8566 is not perfect square\n",
            "8567 is not perfect square\n",
            "8568 is not perfect square\n",
            "8569 is not perfect square\n",
            "8570 is not perfect square\n",
            "8571 is not perfect square\n",
            "8572 is not perfect square\n",
            "8573 is not perfect square\n",
            "8574 is not perfect square\n",
            "8575 is not perfect square\n",
            "8576 is not perfect square\n",
            "8577 is not perfect square\n",
            "8578 is not perfect square\n",
            "8579 is not perfect square\n",
            "8580 is not perfect square\n",
            "8581 is not perfect square\n",
            "8582 is not perfect square\n",
            "8583 is not perfect square\n",
            "8584 is not perfect square\n",
            "8585 is not perfect square\n",
            "8586 is not perfect square\n",
            "8587 is not perfect square\n",
            "8588 is not perfect square\n",
            "8589 is not perfect square\n",
            "8590 is not perfect square\n",
            "8591 is not perfect square\n",
            "8592 is not perfect square\n",
            "8593 is not perfect square\n",
            "8594 is not perfect square\n",
            "8595 is not perfect square\n",
            "8596 is not perfect square\n",
            "8597 is not perfect square\n",
            "8598 is not perfect square\n",
            "8599 is not perfect square\n",
            "8600 is not perfect square\n",
            "8601 is not perfect square\n",
            "8602 is not perfect square\n",
            "8603 is not perfect square\n",
            "8604 is not perfect square\n",
            "8605 is not perfect square\n",
            "8606 is not perfect square\n",
            "8607 is not perfect square\n",
            "8608 is not perfect square\n",
            "8609 is not perfect square\n",
            "8610 is not perfect square\n",
            "8611 is not perfect square\n",
            "8612 is not perfect square\n",
            "8613 is not perfect square\n",
            "8614 is not perfect square\n",
            "8615 is not perfect square\n",
            "8616 is not perfect square\n",
            "8617 is not perfect square\n",
            "8618 is not perfect square\n",
            "8619 is not perfect square\n",
            "8620 is not perfect square\n",
            "8621 is not perfect square\n",
            "8622 is not perfect square\n",
            "8623 is not perfect square\n",
            "8624 is not perfect square\n",
            "8625 is not perfect square\n",
            "8626 is not perfect square\n",
            "8627 is not perfect square\n",
            "8628 is not perfect square\n",
            "8629 is not perfect square\n",
            "8630 is not perfect square\n",
            "8631 is not perfect square\n",
            "8632 is not perfect square\n",
            "8633 is not perfect square\n",
            "8634 is not perfect square\n",
            "8635 is not perfect square\n",
            "8636 is not perfect square\n",
            "8637 is not perfect square\n",
            "8638 is not perfect square\n",
            "8639 is not perfect square\n",
            "8640 is not perfect square\n",
            "8641 is not perfect square\n",
            "8642 is not perfect square\n",
            "8643 is not perfect square\n",
            "8644 is not perfect square\n",
            "8645 is not perfect square\n",
            "8646 is not perfect square\n",
            "8647 is not perfect square\n",
            "8648 is not perfect square\n",
            "8649 is perfect square\n",
            "8650 is not perfect square\n",
            "8651 is not perfect square\n",
            "8652 is not perfect square\n",
            "8653 is not perfect square\n",
            "8654 is not perfect square\n",
            "8655 is not perfect square\n",
            "8656 is not perfect square\n",
            "8657 is not perfect square\n",
            "8658 is not perfect square\n",
            "8659 is not perfect square\n",
            "8660 is not perfect square\n",
            "8661 is not perfect square\n",
            "8662 is not perfect square\n",
            "8663 is not perfect square\n",
            "8664 is not perfect square\n",
            "8665 is not perfect square\n",
            "8666 is not perfect square\n",
            "8667 is not perfect square\n",
            "8668 is not perfect square\n",
            "8669 is not perfect square\n",
            "8670 is not perfect square\n",
            "8671 is not perfect square\n",
            "8672 is not perfect square\n",
            "8673 is not perfect square\n",
            "8674 is not perfect square\n",
            "8675 is not perfect square\n",
            "8676 is not perfect square\n",
            "8677 is not perfect square\n",
            "8678 is not perfect square\n",
            "8679 is not perfect square\n",
            "8680 is not perfect square\n",
            "8681 is not perfect square\n",
            "8682 is not perfect square\n",
            "8683 is not perfect square\n",
            "8684 is not perfect square\n",
            "8685 is not perfect square\n",
            "8686 is not perfect square\n",
            "8687 is not perfect square\n",
            "8688 is not perfect square\n",
            "8689 is not perfect square\n",
            "8690 is not perfect square\n",
            "8691 is not perfect square\n",
            "8692 is not perfect square\n",
            "8693 is not perfect square\n",
            "8694 is not perfect square\n",
            "8695 is not perfect square\n",
            "8696 is not perfect square\n",
            "8697 is not perfect square\n",
            "8698 is not perfect square\n",
            "8699 is not perfect square\n",
            "8700 is not perfect square\n",
            "8701 is not perfect square\n",
            "8702 is not perfect square\n",
            "8703 is not perfect square\n",
            "8704 is not perfect square\n",
            "8705 is not perfect square\n",
            "8706 is not perfect square\n",
            "8707 is not perfect square\n",
            "8708 is not perfect square\n",
            "8709 is not perfect square\n",
            "8710 is not perfect square\n",
            "8711 is not perfect square\n",
            "8712 is not perfect square\n",
            "8713 is not perfect square\n",
            "8714 is not perfect square\n",
            "8715 is not perfect square\n",
            "8716 is not perfect square\n",
            "8717 is not perfect square\n",
            "8718 is not perfect square\n",
            "8719 is not perfect square\n",
            "8720 is not perfect square\n",
            "8721 is not perfect square\n",
            "8722 is not perfect square\n",
            "8723 is not perfect square\n",
            "8724 is not perfect square\n",
            "8725 is not perfect square\n",
            "8726 is not perfect square\n",
            "8727 is not perfect square\n",
            "8728 is not perfect square\n",
            "8729 is not perfect square\n",
            "8730 is not perfect square\n",
            "8731 is not perfect square\n",
            "8732 is not perfect square\n",
            "8733 is not perfect square\n",
            "8734 is not perfect square\n",
            "8735 is not perfect square\n",
            "8736 is not perfect square\n",
            "8737 is not perfect square\n",
            "8738 is not perfect square\n",
            "8739 is not perfect square\n",
            "8740 is not perfect square\n",
            "8741 is not perfect square\n",
            "8742 is not perfect square\n",
            "8743 is not perfect square\n",
            "8744 is not perfect square\n",
            "8745 is not perfect square\n",
            "8746 is not perfect square\n",
            "8747 is not perfect square\n",
            "8748 is not perfect square\n",
            "8749 is not perfect square\n",
            "8750 is not perfect square\n",
            "8751 is not perfect square\n",
            "8752 is not perfect square\n",
            "8753 is not perfect square\n",
            "8754 is not perfect square\n",
            "8755 is not perfect square\n",
            "8756 is not perfect square\n",
            "8757 is not perfect square\n",
            "8758 is not perfect square\n",
            "8759 is not perfect square\n",
            "8760 is not perfect square\n",
            "8761 is not perfect square\n",
            "8762 is not perfect square\n",
            "8763 is not perfect square\n",
            "8764 is not perfect square\n",
            "8765 is not perfect square\n",
            "8766 is not perfect square\n",
            "8767 is not perfect square\n",
            "8768 is not perfect square\n",
            "8769 is not perfect square\n",
            "8770 is not perfect square\n",
            "8771 is not perfect square\n",
            "8772 is not perfect square\n",
            "8773 is not perfect square\n",
            "8774 is not perfect square\n",
            "8775 is not perfect square\n",
            "8776 is not perfect square\n",
            "8777 is not perfect square\n",
            "8778 is not perfect square\n",
            "8779 is not perfect square\n",
            "8780 is not perfect square\n",
            "8781 is not perfect square\n",
            "8782 is not perfect square\n",
            "8783 is not perfect square\n",
            "8784 is not perfect square\n",
            "8785 is not perfect square\n",
            "8786 is not perfect square\n",
            "8787 is not perfect square\n",
            "8788 is not perfect square\n",
            "8789 is not perfect square\n",
            "8790 is not perfect square\n",
            "8791 is not perfect square\n",
            "8792 is not perfect square\n",
            "8793 is not perfect square\n",
            "8794 is not perfect square\n",
            "8795 is not perfect square\n",
            "8796 is not perfect square\n",
            "8797 is not perfect square\n",
            "8798 is not perfect square\n",
            "8799 is not perfect square\n",
            "8800 is not perfect square\n",
            "8801 is not perfect square\n",
            "8802 is not perfect square\n",
            "8803 is not perfect square\n",
            "8804 is not perfect square\n",
            "8805 is not perfect square\n",
            "8806 is not perfect square\n",
            "8807 is not perfect square\n",
            "8808 is not perfect square\n",
            "8809 is not perfect square\n",
            "8810 is not perfect square\n",
            "8811 is not perfect square\n",
            "8812 is not perfect square\n",
            "8813 is not perfect square\n",
            "8814 is not perfect square\n",
            "8815 is not perfect square\n",
            "8816 is not perfect square\n",
            "8817 is not perfect square\n",
            "8818 is not perfect square\n",
            "8819 is not perfect square\n",
            "8820 is not perfect square\n",
            "8821 is not perfect square\n",
            "8822 is not perfect square\n",
            "8823 is not perfect square\n",
            "8824 is not perfect square\n",
            "8825 is not perfect square\n",
            "8826 is not perfect square\n",
            "8827 is not perfect square\n",
            "8828 is not perfect square\n",
            "8829 is not perfect square\n",
            "8830 is not perfect square\n",
            "8831 is not perfect square\n",
            "8832 is not perfect square\n",
            "8833 is not perfect square\n",
            "8834 is not perfect square\n",
            "8835 is not perfect square\n",
            "8836 is perfect square\n",
            "8837 is not perfect square\n",
            "8838 is not perfect square\n",
            "8839 is not perfect square\n",
            "8840 is not perfect square\n",
            "8841 is not perfect square\n",
            "8842 is not perfect square\n",
            "8843 is not perfect square\n",
            "8844 is not perfect square\n",
            "8845 is not perfect square\n",
            "8846 is not perfect square\n",
            "8847 is not perfect square\n",
            "8848 is not perfect square\n",
            "8849 is not perfect square\n",
            "8850 is not perfect square\n",
            "8851 is not perfect square\n",
            "8852 is not perfect square\n",
            "8853 is not perfect square\n",
            "8854 is not perfect square\n",
            "8855 is not perfect square\n",
            "8856 is not perfect square\n",
            "8857 is not perfect square\n",
            "8858 is not perfect square\n",
            "8859 is not perfect square\n",
            "8860 is not perfect square\n",
            "8861 is not perfect square\n",
            "8862 is not perfect square\n",
            "8863 is not perfect square\n",
            "8864 is not perfect square\n",
            "8865 is not perfect square\n",
            "8866 is not perfect square\n",
            "8867 is not perfect square\n",
            "8868 is not perfect square\n",
            "8869 is not perfect square\n",
            "8870 is not perfect square\n",
            "8871 is not perfect square\n",
            "8872 is not perfect square\n",
            "8873 is not perfect square\n",
            "8874 is not perfect square\n",
            "8875 is not perfect square\n",
            "8876 is not perfect square\n",
            "8877 is not perfect square\n",
            "8878 is not perfect square\n",
            "8879 is not perfect square\n",
            "8880 is not perfect square\n",
            "8881 is not perfect square\n",
            "8882 is not perfect square\n",
            "8883 is not perfect square\n",
            "8884 is not perfect square\n",
            "8885 is not perfect square\n",
            "8886 is not perfect square\n",
            "8887 is not perfect square\n",
            "8888 is not perfect square\n",
            "8889 is not perfect square\n",
            "8890 is not perfect square\n",
            "8891 is not perfect square\n",
            "8892 is not perfect square\n",
            "8893 is not perfect square\n",
            "8894 is not perfect square\n",
            "8895 is not perfect square\n",
            "8896 is not perfect square\n",
            "8897 is not perfect square\n",
            "8898 is not perfect square\n",
            "8899 is not perfect square\n",
            "8900 is not perfect square\n",
            "8901 is not perfect square\n",
            "8902 is not perfect square\n",
            "8903 is not perfect square\n",
            "8904 is not perfect square\n",
            "8905 is not perfect square\n",
            "8906 is not perfect square\n",
            "8907 is not perfect square\n",
            "8908 is not perfect square\n",
            "8909 is not perfect square\n",
            "8910 is not perfect square\n",
            "8911 is not perfect square\n",
            "8912 is not perfect square\n",
            "8913 is not perfect square\n",
            "8914 is not perfect square\n",
            "8915 is not perfect square\n",
            "8916 is not perfect square\n",
            "8917 is not perfect square\n",
            "8918 is not perfect square\n",
            "8919 is not perfect square\n",
            "8920 is not perfect square\n",
            "8921 is not perfect square\n",
            "8922 is not perfect square\n",
            "8923 is not perfect square\n",
            "8924 is not perfect square\n",
            "8925 is not perfect square\n",
            "8926 is not perfect square\n",
            "8927 is not perfect square\n",
            "8928 is not perfect square\n",
            "8929 is not perfect square\n",
            "8930 is not perfect square\n",
            "8931 is not perfect square\n",
            "8932 is not perfect square\n",
            "8933 is not perfect square\n",
            "8934 is not perfect square\n",
            "8935 is not perfect square\n",
            "8936 is not perfect square\n",
            "8937 is not perfect square\n",
            "8938 is not perfect square\n",
            "8939 is not perfect square\n",
            "8940 is not perfect square\n",
            "8941 is not perfect square\n",
            "8942 is not perfect square\n",
            "8943 is not perfect square\n",
            "8944 is not perfect square\n",
            "8945 is not perfect square\n",
            "8946 is not perfect square\n",
            "8947 is not perfect square\n",
            "8948 is not perfect square\n",
            "8949 is not perfect square\n",
            "8950 is not perfect square\n",
            "8951 is not perfect square\n",
            "8952 is not perfect square\n",
            "8953 is not perfect square\n",
            "8954 is not perfect square\n",
            "8955 is not perfect square\n",
            "8956 is not perfect square\n",
            "8957 is not perfect square\n",
            "8958 is not perfect square\n",
            "8959 is not perfect square\n",
            "8960 is not perfect square\n",
            "8961 is not perfect square\n",
            "8962 is not perfect square\n",
            "8963 is not perfect square\n",
            "8964 is not perfect square\n",
            "8965 is not perfect square\n",
            "8966 is not perfect square\n",
            "8967 is not perfect square\n",
            "8968 is not perfect square\n",
            "8969 is not perfect square\n",
            "8970 is not perfect square\n",
            "8971 is not perfect square\n",
            "8972 is not perfect square\n",
            "8973 is not perfect square\n",
            "8974 is not perfect square\n",
            "8975 is not perfect square\n",
            "8976 is not perfect square\n",
            "8977 is not perfect square\n",
            "8978 is not perfect square\n",
            "8979 is not perfect square\n",
            "8980 is not perfect square\n",
            "8981 is not perfect square\n",
            "8982 is not perfect square\n",
            "8983 is not perfect square\n",
            "8984 is not perfect square\n",
            "8985 is not perfect square\n",
            "8986 is not perfect square\n",
            "8987 is not perfect square\n",
            "8988 is not perfect square\n",
            "8989 is not perfect square\n",
            "8990 is not perfect square\n",
            "8991 is not perfect square\n",
            "8992 is not perfect square\n",
            "8993 is not perfect square\n",
            "8994 is not perfect square\n",
            "8995 is not perfect square\n",
            "8996 is not perfect square\n",
            "8997 is not perfect square\n",
            "8998 is not perfect square\n",
            "8999 is not perfect square\n",
            "9000 is not perfect square\n",
            "9001 is not perfect square\n",
            "9002 is not perfect square\n",
            "9003 is not perfect square\n",
            "9004 is not perfect square\n",
            "9005 is not perfect square\n",
            "9006 is not perfect square\n",
            "9007 is not perfect square\n",
            "9008 is not perfect square\n",
            "9009 is not perfect square\n",
            "9010 is not perfect square\n",
            "9011 is not perfect square\n",
            "9012 is not perfect square\n",
            "9013 is not perfect square\n",
            "9014 is not perfect square\n",
            "9015 is not perfect square\n",
            "9016 is not perfect square\n",
            "9017 is not perfect square\n",
            "9018 is not perfect square\n",
            "9019 is not perfect square\n",
            "9020 is not perfect square\n",
            "9021 is not perfect square\n",
            "9022 is not perfect square\n",
            "9023 is not perfect square\n",
            "9024 is not perfect square\n",
            "9025 is perfect square\n",
            "9026 is not perfect square\n",
            "9027 is not perfect square\n",
            "9028 is not perfect square\n",
            "9029 is not perfect square\n",
            "9030 is not perfect square\n",
            "9031 is not perfect square\n",
            "9032 is not perfect square\n",
            "9033 is not perfect square\n",
            "9034 is not perfect square\n",
            "9035 is not perfect square\n",
            "9036 is not perfect square\n",
            "9037 is not perfect square\n",
            "9038 is not perfect square\n",
            "9039 is not perfect square\n",
            "9040 is not perfect square\n",
            "9041 is not perfect square\n",
            "9042 is not perfect square\n",
            "9043 is not perfect square\n",
            "9044 is not perfect square\n",
            "9045 is not perfect square\n",
            "9046 is not perfect square\n",
            "9047 is not perfect square\n",
            "9048 is not perfect square\n",
            "9049 is not perfect square\n",
            "9050 is not perfect square\n",
            "9051 is not perfect square\n",
            "9052 is not perfect square\n",
            "9053 is not perfect square\n",
            "9054 is not perfect square\n",
            "9055 is not perfect square\n",
            "9056 is not perfect square\n",
            "9057 is not perfect square\n",
            "9058 is not perfect square\n",
            "9059 is not perfect square\n",
            "9060 is not perfect square\n",
            "9061 is not perfect square\n",
            "9062 is not perfect square\n",
            "9063 is not perfect square\n",
            "9064 is not perfect square\n",
            "9065 is not perfect square\n",
            "9066 is not perfect square\n",
            "9067 is not perfect square\n",
            "9068 is not perfect square\n",
            "9069 is not perfect square\n",
            "9070 is not perfect square\n",
            "9071 is not perfect square\n",
            "9072 is not perfect square\n",
            "9073 is not perfect square\n",
            "9074 is not perfect square\n",
            "9075 is not perfect square\n",
            "9076 is not perfect square\n",
            "9077 is not perfect square\n",
            "9078 is not perfect square\n",
            "9079 is not perfect square\n",
            "9080 is not perfect square\n",
            "9081 is not perfect square\n",
            "9082 is not perfect square\n",
            "9083 is not perfect square\n",
            "9084 is not perfect square\n",
            "9085 is not perfect square\n",
            "9086 is not perfect square\n",
            "9087 is not perfect square\n",
            "9088 is not perfect square\n",
            "9089 is not perfect square\n",
            "9090 is not perfect square\n",
            "9091 is not perfect square\n",
            "9092 is not perfect square\n",
            "9093 is not perfect square\n",
            "9094 is not perfect square\n",
            "9095 is not perfect square\n",
            "9096 is not perfect square\n",
            "9097 is not perfect square\n",
            "9098 is not perfect square\n",
            "9099 is not perfect square\n",
            "9100 is not perfect square\n",
            "9101 is not perfect square\n",
            "9102 is not perfect square\n",
            "9103 is not perfect square\n",
            "9104 is not perfect square\n",
            "9105 is not perfect square\n",
            "9106 is not perfect square\n",
            "9107 is not perfect square\n",
            "9108 is not perfect square\n",
            "9109 is not perfect square\n",
            "9110 is not perfect square\n",
            "9111 is not perfect square\n",
            "9112 is not perfect square\n",
            "9113 is not perfect square\n",
            "9114 is not perfect square\n",
            "9115 is not perfect square\n",
            "9116 is not perfect square\n",
            "9117 is not perfect square\n",
            "9118 is not perfect square\n",
            "9119 is not perfect square\n",
            "9120 is not perfect square\n",
            "9121 is not perfect square\n",
            "9122 is not perfect square\n",
            "9123 is not perfect square\n",
            "9124 is not perfect square\n",
            "9125 is not perfect square\n",
            "9126 is not perfect square\n",
            "9127 is not perfect square\n",
            "9128 is not perfect square\n",
            "9129 is not perfect square\n",
            "9130 is not perfect square\n",
            "9131 is not perfect square\n",
            "9132 is not perfect square\n",
            "9133 is not perfect square\n",
            "9134 is not perfect square\n",
            "9135 is not perfect square\n",
            "9136 is not perfect square\n",
            "9137 is not perfect square\n",
            "9138 is not perfect square\n",
            "9139 is not perfect square\n",
            "9140 is not perfect square\n",
            "9141 is not perfect square\n",
            "9142 is not perfect square\n",
            "9143 is not perfect square\n",
            "9144 is not perfect square\n",
            "9145 is not perfect square\n",
            "9146 is not perfect square\n",
            "9147 is not perfect square\n",
            "9148 is not perfect square\n",
            "9149 is not perfect square\n",
            "9150 is not perfect square\n",
            "9151 is not perfect square\n",
            "9152 is not perfect square\n",
            "9153 is not perfect square\n",
            "9154 is not perfect square\n",
            "9155 is not perfect square\n",
            "9156 is not perfect square\n",
            "9157 is not perfect square\n",
            "9158 is not perfect square\n",
            "9159 is not perfect square\n",
            "9160 is not perfect square\n",
            "9161 is not perfect square\n",
            "9162 is not perfect square\n",
            "9163 is not perfect square\n",
            "9164 is not perfect square\n",
            "9165 is not perfect square\n",
            "9166 is not perfect square\n",
            "9167 is not perfect square\n",
            "9168 is not perfect square\n",
            "9169 is not perfect square\n",
            "9170 is not perfect square\n",
            "9171 is not perfect square\n",
            "9172 is not perfect square\n",
            "9173 is not perfect square\n",
            "9174 is not perfect square\n",
            "9175 is not perfect square\n",
            "9176 is not perfect square\n",
            "9177 is not perfect square\n",
            "9178 is not perfect square\n",
            "9179 is not perfect square\n",
            "9180 is not perfect square\n",
            "9181 is not perfect square\n",
            "9182 is not perfect square\n",
            "9183 is not perfect square\n",
            "9184 is not perfect square\n",
            "9185 is not perfect square\n",
            "9186 is not perfect square\n",
            "9187 is not perfect square\n",
            "9188 is not perfect square\n",
            "9189 is not perfect square\n",
            "9190 is not perfect square\n",
            "9191 is not perfect square\n",
            "9192 is not perfect square\n",
            "9193 is not perfect square\n",
            "9194 is not perfect square\n",
            "9195 is not perfect square\n",
            "9196 is not perfect square\n",
            "9197 is not perfect square\n",
            "9198 is not perfect square\n",
            "9199 is not perfect square\n",
            "9200 is not perfect square\n",
            "9201 is not perfect square\n",
            "9202 is not perfect square\n",
            "9203 is not perfect square\n",
            "9204 is not perfect square\n",
            "9205 is not perfect square\n",
            "9206 is not perfect square\n",
            "9207 is not perfect square\n",
            "9208 is not perfect square\n",
            "9209 is not perfect square\n",
            "9210 is not perfect square\n",
            "9211 is not perfect square\n",
            "9212 is not perfect square\n",
            "9213 is not perfect square\n",
            "9214 is not perfect square\n",
            "9215 is not perfect square\n",
            "9216 is perfect square\n",
            "9217 is not perfect square\n",
            "9218 is not perfect square\n",
            "9219 is not perfect square\n",
            "9220 is not perfect square\n",
            "9221 is not perfect square\n",
            "9222 is not perfect square\n",
            "9223 is not perfect square\n",
            "9224 is not perfect square\n",
            "9225 is not perfect square\n",
            "9226 is not perfect square\n",
            "9227 is not perfect square\n",
            "9228 is not perfect square\n",
            "9229 is not perfect square\n",
            "9230 is not perfect square\n",
            "9231 is not perfect square\n",
            "9232 is not perfect square\n",
            "9233 is not perfect square\n",
            "9234 is not perfect square\n",
            "9235 is not perfect square\n",
            "9236 is not perfect square\n",
            "9237 is not perfect square\n",
            "9238 is not perfect square\n",
            "9239 is not perfect square\n",
            "9240 is not perfect square\n",
            "9241 is not perfect square\n",
            "9242 is not perfect square\n",
            "9243 is not perfect square\n",
            "9244 is not perfect square\n",
            "9245 is not perfect square\n",
            "9246 is not perfect square\n",
            "9247 is not perfect square\n",
            "9248 is not perfect square\n",
            "9249 is not perfect square\n",
            "9250 is not perfect square\n",
            "9251 is not perfect square\n",
            "9252 is not perfect square\n",
            "9253 is not perfect square\n",
            "9254 is not perfect square\n",
            "9255 is not perfect square\n",
            "9256 is not perfect square\n",
            "9257 is not perfect square\n",
            "9258 is not perfect square\n",
            "9259 is not perfect square\n",
            "9260 is not perfect square\n",
            "9261 is not perfect square\n",
            "9262 is not perfect square\n",
            "9263 is not perfect square\n",
            "9264 is not perfect square\n",
            "9265 is not perfect square\n",
            "9266 is not perfect square\n",
            "9267 is not perfect square\n",
            "9268 is not perfect square\n",
            "9269 is not perfect square\n",
            "9270 is not perfect square\n",
            "9271 is not perfect square\n",
            "9272 is not perfect square\n",
            "9273 is not perfect square\n",
            "9274 is not perfect square\n",
            "9275 is not perfect square\n",
            "9276 is not perfect square\n",
            "9277 is not perfect square\n",
            "9278 is not perfect square\n",
            "9279 is not perfect square\n",
            "9280 is not perfect square\n",
            "9281 is not perfect square\n",
            "9282 is not perfect square\n",
            "9283 is not perfect square\n",
            "9284 is not perfect square\n",
            "9285 is not perfect square\n",
            "9286 is not perfect square\n",
            "9287 is not perfect square\n",
            "9288 is not perfect square\n",
            "9289 is not perfect square\n",
            "9290 is not perfect square\n",
            "9291 is not perfect square\n",
            "9292 is not perfect square\n",
            "9293 is not perfect square\n",
            "9294 is not perfect square\n",
            "9295 is not perfect square\n",
            "9296 is not perfect square\n",
            "9297 is not perfect square\n",
            "9298 is not perfect square\n",
            "9299 is not perfect square\n",
            "9300 is not perfect square\n",
            "9301 is not perfect square\n",
            "9302 is not perfect square\n",
            "9303 is not perfect square\n",
            "9304 is not perfect square\n",
            "9305 is not perfect square\n",
            "9306 is not perfect square\n",
            "9307 is not perfect square\n",
            "9308 is not perfect square\n",
            "9309 is not perfect square\n",
            "9310 is not perfect square\n",
            "9311 is not perfect square\n",
            "9312 is not perfect square\n",
            "9313 is not perfect square\n",
            "9314 is not perfect square\n",
            "9315 is not perfect square\n",
            "9316 is not perfect square\n",
            "9317 is not perfect square\n",
            "9318 is not perfect square\n",
            "9319 is not perfect square\n",
            "9320 is not perfect square\n",
            "9321 is not perfect square\n",
            "9322 is not perfect square\n",
            "9323 is not perfect square\n",
            "9324 is not perfect square\n",
            "9325 is not perfect square\n",
            "9326 is not perfect square\n",
            "9327 is not perfect square\n",
            "9328 is not perfect square\n",
            "9329 is not perfect square\n",
            "9330 is not perfect square\n",
            "9331 is not perfect square\n",
            "9332 is not perfect square\n",
            "9333 is not perfect square\n",
            "9334 is not perfect square\n",
            "9335 is not perfect square\n",
            "9336 is not perfect square\n",
            "9337 is not perfect square\n",
            "9338 is not perfect square\n",
            "9339 is not perfect square\n",
            "9340 is not perfect square\n",
            "9341 is not perfect square\n",
            "9342 is not perfect square\n",
            "9343 is not perfect square\n",
            "9344 is not perfect square\n",
            "9345 is not perfect square\n",
            "9346 is not perfect square\n",
            "9347 is not perfect square\n",
            "9348 is not perfect square\n",
            "9349 is not perfect square\n",
            "9350 is not perfect square\n",
            "9351 is not perfect square\n",
            "9352 is not perfect square\n",
            "9353 is not perfect square\n",
            "9354 is not perfect square\n",
            "9355 is not perfect square\n",
            "9356 is not perfect square\n",
            "9357 is not perfect square\n",
            "9358 is not perfect square\n",
            "9359 is not perfect square\n",
            "9360 is not perfect square\n",
            "9361 is not perfect square\n",
            "9362 is not perfect square\n",
            "9363 is not perfect square\n",
            "9364 is not perfect square\n",
            "9365 is not perfect square\n",
            "9366 is not perfect square\n",
            "9367 is not perfect square\n",
            "9368 is not perfect square\n",
            "9369 is not perfect square\n",
            "9370 is not perfect square\n",
            "9371 is not perfect square\n",
            "9372 is not perfect square\n",
            "9373 is not perfect square\n",
            "9374 is not perfect square\n",
            "9375 is not perfect square\n",
            "9376 is not perfect square\n",
            "9377 is not perfect square\n",
            "9378 is not perfect square\n",
            "9379 is not perfect square\n",
            "9380 is not perfect square\n",
            "9381 is not perfect square\n",
            "9382 is not perfect square\n",
            "9383 is not perfect square\n",
            "9384 is not perfect square\n",
            "9385 is not perfect square\n",
            "9386 is not perfect square\n",
            "9387 is not perfect square\n",
            "9388 is not perfect square\n",
            "9389 is not perfect square\n",
            "9390 is not perfect square\n",
            "9391 is not perfect square\n",
            "9392 is not perfect square\n",
            "9393 is not perfect square\n",
            "9394 is not perfect square\n",
            "9395 is not perfect square\n",
            "9396 is not perfect square\n",
            "9397 is not perfect square\n",
            "9398 is not perfect square\n",
            "9399 is not perfect square\n",
            "9400 is not perfect square\n",
            "9401 is not perfect square\n",
            "9402 is not perfect square\n",
            "9403 is not perfect square\n",
            "9404 is not perfect square\n",
            "9405 is not perfect square\n",
            "9406 is not perfect square\n",
            "9407 is not perfect square\n",
            "9408 is not perfect square\n",
            "9409 is perfect square\n",
            "9410 is not perfect square\n",
            "9411 is not perfect square\n",
            "9412 is not perfect square\n",
            "9413 is not perfect square\n",
            "9414 is not perfect square\n",
            "9415 is not perfect square\n",
            "9416 is not perfect square\n",
            "9417 is not perfect square\n",
            "9418 is not perfect square\n",
            "9419 is not perfect square\n",
            "9420 is not perfect square\n",
            "9421 is not perfect square\n",
            "9422 is not perfect square\n",
            "9423 is not perfect square\n",
            "9424 is not perfect square\n",
            "9425 is not perfect square\n",
            "9426 is not perfect square\n",
            "9427 is not perfect square\n",
            "9428 is not perfect square\n",
            "9429 is not perfect square\n",
            "9430 is not perfect square\n",
            "9431 is not perfect square\n",
            "9432 is not perfect square\n",
            "9433 is not perfect square\n",
            "9434 is not perfect square\n",
            "9435 is not perfect square\n",
            "9436 is not perfect square\n",
            "9437 is not perfect square\n",
            "9438 is not perfect square\n",
            "9439 is not perfect square\n",
            "9440 is not perfect square\n",
            "9441 is not perfect square\n",
            "9442 is not perfect square\n",
            "9443 is not perfect square\n",
            "9444 is not perfect square\n",
            "9445 is not perfect square\n",
            "9446 is not perfect square\n",
            "9447 is not perfect square\n",
            "9448 is not perfect square\n",
            "9449 is not perfect square\n",
            "9450 is not perfect square\n",
            "9451 is not perfect square\n",
            "9452 is not perfect square\n",
            "9453 is not perfect square\n",
            "9454 is not perfect square\n",
            "9455 is not perfect square\n",
            "9456 is not perfect square\n",
            "9457 is not perfect square\n",
            "9458 is not perfect square\n",
            "9459 is not perfect square\n",
            "9460 is not perfect square\n",
            "9461 is not perfect square\n",
            "9462 is not perfect square\n",
            "9463 is not perfect square\n",
            "9464 is not perfect square\n",
            "9465 is not perfect square\n",
            "9466 is not perfect square\n",
            "9467 is not perfect square\n",
            "9468 is not perfect square\n",
            "9469 is not perfect square\n",
            "9470 is not perfect square\n",
            "9471 is not perfect square\n",
            "9472 is not perfect square\n",
            "9473 is not perfect square\n",
            "9474 is not perfect square\n",
            "9475 is not perfect square\n",
            "9476 is not perfect square\n",
            "9477 is not perfect square\n",
            "9478 is not perfect square\n",
            "9479 is not perfect square\n",
            "9480 is not perfect square\n",
            "9481 is not perfect square\n",
            "9482 is not perfect square\n",
            "9483 is not perfect square\n",
            "9484 is not perfect square\n",
            "9485 is not perfect square\n",
            "9486 is not perfect square\n",
            "9487 is not perfect square\n",
            "9488 is not perfect square\n",
            "9489 is not perfect square\n",
            "9490 is not perfect square\n",
            "9491 is not perfect square\n",
            "9492 is not perfect square\n",
            "9493 is not perfect square\n",
            "9494 is not perfect square\n",
            "9495 is not perfect square\n",
            "9496 is not perfect square\n",
            "9497 is not perfect square\n",
            "9498 is not perfect square\n",
            "9499 is not perfect square\n",
            "9500 is not perfect square\n",
            "9501 is not perfect square\n",
            "9502 is not perfect square\n",
            "9503 is not perfect square\n",
            "9504 is not perfect square\n",
            "9505 is not perfect square\n",
            "9506 is not perfect square\n",
            "9507 is not perfect square\n",
            "9508 is not perfect square\n",
            "9509 is not perfect square\n",
            "9510 is not perfect square\n",
            "9511 is not perfect square\n",
            "9512 is not perfect square\n",
            "9513 is not perfect square\n",
            "9514 is not perfect square\n",
            "9515 is not perfect square\n",
            "9516 is not perfect square\n",
            "9517 is not perfect square\n",
            "9518 is not perfect square\n",
            "9519 is not perfect square\n",
            "9520 is not perfect square\n",
            "9521 is not perfect square\n",
            "9522 is not perfect square\n",
            "9523 is not perfect square\n",
            "9524 is not perfect square\n",
            "9525 is not perfect square\n",
            "9526 is not perfect square\n",
            "9527 is not perfect square\n",
            "9528 is not perfect square\n",
            "9529 is not perfect square\n",
            "9530 is not perfect square\n",
            "9531 is not perfect square\n",
            "9532 is not perfect square\n",
            "9533 is not perfect square\n",
            "9534 is not perfect square\n",
            "9535 is not perfect square\n",
            "9536 is not perfect square\n",
            "9537 is not perfect square\n",
            "9538 is not perfect square\n",
            "9539 is not perfect square\n",
            "9540 is not perfect square\n",
            "9541 is not perfect square\n",
            "9542 is not perfect square\n",
            "9543 is not perfect square\n",
            "9544 is not perfect square\n",
            "9545 is not perfect square\n",
            "9546 is not perfect square\n",
            "9547 is not perfect square\n",
            "9548 is not perfect square\n",
            "9549 is not perfect square\n",
            "9550 is not perfect square\n",
            "9551 is not perfect square\n",
            "9552 is not perfect square\n",
            "9553 is not perfect square\n",
            "9554 is not perfect square\n",
            "9555 is not perfect square\n",
            "9556 is not perfect square\n",
            "9557 is not perfect square\n",
            "9558 is not perfect square\n",
            "9559 is not perfect square\n",
            "9560 is not perfect square\n",
            "9561 is not perfect square\n",
            "9562 is not perfect square\n",
            "9563 is not perfect square\n",
            "9564 is not perfect square\n",
            "9565 is not perfect square\n",
            "9566 is not perfect square\n",
            "9567 is not perfect square\n",
            "9568 is not perfect square\n",
            "9569 is not perfect square\n",
            "9570 is not perfect square\n",
            "9571 is not perfect square\n",
            "9572 is not perfect square\n",
            "9573 is not perfect square\n",
            "9574 is not perfect square\n",
            "9575 is not perfect square\n",
            "9576 is not perfect square\n",
            "9577 is not perfect square\n",
            "9578 is not perfect square\n",
            "9579 is not perfect square\n",
            "9580 is not perfect square\n",
            "9581 is not perfect square\n",
            "9582 is not perfect square\n",
            "9583 is not perfect square\n",
            "9584 is not perfect square\n",
            "9585 is not perfect square\n",
            "9586 is not perfect square\n",
            "9587 is not perfect square\n",
            "9588 is not perfect square\n",
            "9589 is not perfect square\n",
            "9590 is not perfect square\n",
            "9591 is not perfect square\n",
            "9592 is not perfect square\n",
            "9593 is not perfect square\n",
            "9594 is not perfect square\n",
            "9595 is not perfect square\n",
            "9596 is not perfect square\n",
            "9597 is not perfect square\n",
            "9598 is not perfect square\n",
            "9599 is not perfect square\n",
            "9600 is not perfect square\n",
            "9601 is not perfect square\n",
            "9602 is not perfect square\n",
            "9603 is not perfect square\n",
            "9604 is perfect square\n",
            "9605 is not perfect square\n",
            "9606 is not perfect square\n",
            "9607 is not perfect square\n",
            "9608 is not perfect square\n",
            "9609 is not perfect square\n",
            "9610 is not perfect square\n",
            "9611 is not perfect square\n",
            "9612 is not perfect square\n",
            "9613 is not perfect square\n",
            "9614 is not perfect square\n",
            "9615 is not perfect square\n",
            "9616 is not perfect square\n",
            "9617 is not perfect square\n",
            "9618 is not perfect square\n",
            "9619 is not perfect square\n",
            "9620 is not perfect square\n",
            "9621 is not perfect square\n",
            "9622 is not perfect square\n",
            "9623 is not perfect square\n",
            "9624 is not perfect square\n",
            "9625 is not perfect square\n",
            "9626 is not perfect square\n",
            "9627 is not perfect square\n",
            "9628 is not perfect square\n",
            "9629 is not perfect square\n",
            "9630 is not perfect square\n",
            "9631 is not perfect square\n",
            "9632 is not perfect square\n",
            "9633 is not perfect square\n",
            "9634 is not perfect square\n",
            "9635 is not perfect square\n",
            "9636 is not perfect square\n",
            "9637 is not perfect square\n",
            "9638 is not perfect square\n",
            "9639 is not perfect square\n",
            "9640 is not perfect square\n",
            "9641 is not perfect square\n",
            "9642 is not perfect square\n",
            "9643 is not perfect square\n",
            "9644 is not perfect square\n",
            "9645 is not perfect square\n",
            "9646 is not perfect square\n",
            "9647 is not perfect square\n",
            "9648 is not perfect square\n",
            "9649 is not perfect square\n",
            "9650 is not perfect square\n",
            "9651 is not perfect square\n",
            "9652 is not perfect square\n",
            "9653 is not perfect square\n",
            "9654 is not perfect square\n",
            "9655 is not perfect square\n",
            "9656 is not perfect square\n",
            "9657 is not perfect square\n",
            "9658 is not perfect square\n",
            "9659 is not perfect square\n",
            "9660 is not perfect square\n",
            "9661 is not perfect square\n",
            "9662 is not perfect square\n",
            "9663 is not perfect square\n",
            "9664 is not perfect square\n",
            "9665 is not perfect square\n",
            "9666 is not perfect square\n",
            "9667 is not perfect square\n",
            "9668 is not perfect square\n",
            "9669 is not perfect square\n",
            "9670 is not perfect square\n",
            "9671 is not perfect square\n",
            "9672 is not perfect square\n",
            "9673 is not perfect square\n",
            "9674 is not perfect square\n",
            "9675 is not perfect square\n",
            "9676 is not perfect square\n",
            "9677 is not perfect square\n",
            "9678 is not perfect square\n",
            "9679 is not perfect square\n",
            "9680 is not perfect square\n",
            "9681 is not perfect square\n",
            "9682 is not perfect square\n",
            "9683 is not perfect square\n",
            "9684 is not perfect square\n",
            "9685 is not perfect square\n",
            "9686 is not perfect square\n",
            "9687 is not perfect square\n",
            "9688 is not perfect square\n",
            "9689 is not perfect square\n",
            "9690 is not perfect square\n",
            "9691 is not perfect square\n",
            "9692 is not perfect square\n",
            "9693 is not perfect square\n",
            "9694 is not perfect square\n",
            "9695 is not perfect square\n",
            "9696 is not perfect square\n",
            "9697 is not perfect square\n",
            "9698 is not perfect square\n",
            "9699 is not perfect square\n",
            "9700 is not perfect square\n",
            "9701 is not perfect square\n",
            "9702 is not perfect square\n",
            "9703 is not perfect square\n",
            "9704 is not perfect square\n",
            "9705 is not perfect square\n",
            "9706 is not perfect square\n",
            "9707 is not perfect square\n",
            "9708 is not perfect square\n",
            "9709 is not perfect square\n",
            "9710 is not perfect square\n",
            "9711 is not perfect square\n",
            "9712 is not perfect square\n",
            "9713 is not perfect square\n",
            "9714 is not perfect square\n",
            "9715 is not perfect square\n",
            "9716 is not perfect square\n",
            "9717 is not perfect square\n",
            "9718 is not perfect square\n",
            "9719 is not perfect square\n",
            "9720 is not perfect square\n",
            "9721 is not perfect square\n",
            "9722 is not perfect square\n",
            "9723 is not perfect square\n",
            "9724 is not perfect square\n",
            "9725 is not perfect square\n",
            "9726 is not perfect square\n",
            "9727 is not perfect square\n",
            "9728 is not perfect square\n",
            "9729 is not perfect square\n",
            "9730 is not perfect square\n",
            "9731 is not perfect square\n",
            "9732 is not perfect square\n",
            "9733 is not perfect square\n",
            "9734 is not perfect square\n",
            "9735 is not perfect square\n",
            "9736 is not perfect square\n",
            "9737 is not perfect square\n",
            "9738 is not perfect square\n",
            "9739 is not perfect square\n",
            "9740 is not perfect square\n",
            "9741 is not perfect square\n",
            "9742 is not perfect square\n",
            "9743 is not perfect square\n",
            "9744 is not perfect square\n",
            "9745 is not perfect square\n",
            "9746 is not perfect square\n",
            "9747 is not perfect square\n",
            "9748 is not perfect square\n",
            "9749 is not perfect square\n",
            "9750 is not perfect square\n",
            "9751 is not perfect square\n",
            "9752 is not perfect square\n",
            "9753 is not perfect square\n",
            "9754 is not perfect square\n",
            "9755 is not perfect square\n",
            "9756 is not perfect square\n",
            "9757 is not perfect square\n",
            "9758 is not perfect square\n",
            "9759 is not perfect square\n",
            "9760 is not perfect square\n",
            "9761 is not perfect square\n",
            "9762 is not perfect square\n",
            "9763 is not perfect square\n",
            "9764 is not perfect square\n",
            "9765 is not perfect square\n",
            "9766 is not perfect square\n",
            "9767 is not perfect square\n",
            "9768 is not perfect square\n",
            "9769 is not perfect square\n",
            "9770 is not perfect square\n",
            "9771 is not perfect square\n",
            "9772 is not perfect square\n",
            "9773 is not perfect square\n",
            "9774 is not perfect square\n",
            "9775 is not perfect square\n",
            "9776 is not perfect square\n",
            "9777 is not perfect square\n",
            "9778 is not perfect square\n",
            "9779 is not perfect square\n",
            "9780 is not perfect square\n",
            "9781 is not perfect square\n",
            "9782 is not perfect square\n",
            "9783 is not perfect square\n",
            "9784 is not perfect square\n",
            "9785 is not perfect square\n",
            "9786 is not perfect square\n",
            "9787 is not perfect square\n",
            "9788 is not perfect square\n",
            "9789 is not perfect square\n",
            "9790 is not perfect square\n",
            "9791 is not perfect square\n",
            "9792 is not perfect square\n",
            "9793 is not perfect square\n",
            "9794 is not perfect square\n",
            "9795 is not perfect square\n",
            "9796 is not perfect square\n",
            "9797 is not perfect square\n",
            "9798 is not perfect square\n",
            "9799 is not perfect square\n",
            "9800 is not perfect square\n",
            "9801 is perfect square\n",
            "9802 is not perfect square\n",
            "9803 is not perfect square\n",
            "9804 is not perfect square\n",
            "9805 is not perfect square\n",
            "9806 is not perfect square\n",
            "9807 is not perfect square\n",
            "9808 is not perfect square\n",
            "9809 is not perfect square\n",
            "9810 is not perfect square\n",
            "9811 is not perfect square\n",
            "9812 is not perfect square\n",
            "9813 is not perfect square\n",
            "9814 is not perfect square\n",
            "9815 is not perfect square\n",
            "9816 is not perfect square\n",
            "9817 is not perfect square\n",
            "9818 is not perfect square\n",
            "9819 is not perfect square\n",
            "9820 is not perfect square\n",
            "9821 is not perfect square\n",
            "9822 is not perfect square\n",
            "9823 is not perfect square\n",
            "9824 is not perfect square\n",
            "9825 is not perfect square\n",
            "9826 is not perfect square\n",
            "9827 is not perfect square\n",
            "9828 is not perfect square\n",
            "9829 is not perfect square\n",
            "9830 is not perfect square\n",
            "9831 is not perfect square\n",
            "9832 is not perfect square\n",
            "9833 is not perfect square\n",
            "9834 is not perfect square\n",
            "9835 is not perfect square\n",
            "9836 is not perfect square\n",
            "9837 is not perfect square\n",
            "9838 is not perfect square\n",
            "9839 is not perfect square\n",
            "9840 is not perfect square\n",
            "9841 is not perfect square\n",
            "9842 is not perfect square\n",
            "9843 is not perfect square\n",
            "9844 is not perfect square\n",
            "9845 is not perfect square\n",
            "9846 is not perfect square\n",
            "9847 is not perfect square\n",
            "9848 is not perfect square\n",
            "9849 is not perfect square\n",
            "9850 is not perfect square\n",
            "9851 is not perfect square\n",
            "9852 is not perfect square\n",
            "9853 is not perfect square\n",
            "9854 is not perfect square\n",
            "9855 is not perfect square\n",
            "9856 is not perfect square\n",
            "9857 is not perfect square\n",
            "9858 is not perfect square\n",
            "9859 is not perfect square\n",
            "9860 is not perfect square\n",
            "9861 is not perfect square\n",
            "9862 is not perfect square\n",
            "9863 is not perfect square\n",
            "9864 is not perfect square\n",
            "9865 is not perfect square\n",
            "9866 is not perfect square\n",
            "9867 is not perfect square\n",
            "9868 is not perfect square\n",
            "9869 is not perfect square\n",
            "9870 is not perfect square\n",
            "9871 is not perfect square\n",
            "9872 is not perfect square\n",
            "9873 is not perfect square\n",
            "9874 is not perfect square\n",
            "9875 is not perfect square\n",
            "9876 is not perfect square\n",
            "9877 is not perfect square\n",
            "9878 is not perfect square\n",
            "9879 is not perfect square\n",
            "9880 is not perfect square\n",
            "9881 is not perfect square\n",
            "9882 is not perfect square\n",
            "9883 is not perfect square\n",
            "9884 is not perfect square\n",
            "9885 is not perfect square\n",
            "9886 is not perfect square\n",
            "9887 is not perfect square\n",
            "9888 is not perfect square\n",
            "9889 is not perfect square\n",
            "9890 is not perfect square\n",
            "9891 is not perfect square\n",
            "9892 is not perfect square\n",
            "9893 is not perfect square\n",
            "9894 is not perfect square\n",
            "9895 is not perfect square\n",
            "9896 is not perfect square\n",
            "9897 is not perfect square\n",
            "9898 is not perfect square\n",
            "9899 is not perfect square\n",
            "9900 is not perfect square\n",
            "9901 is not perfect square\n",
            "9902 is not perfect square\n",
            "9903 is not perfect square\n",
            "9904 is not perfect square\n",
            "9905 is not perfect square\n",
            "9906 is not perfect square\n",
            "9907 is not perfect square\n",
            "9908 is not perfect square\n",
            "9909 is not perfect square\n",
            "9910 is not perfect square\n",
            "9911 is not perfect square\n",
            "9912 is not perfect square\n",
            "9913 is not perfect square\n",
            "9914 is not perfect square\n",
            "9915 is not perfect square\n",
            "9916 is not perfect square\n",
            "9917 is not perfect square\n",
            "9918 is not perfect square\n",
            "9919 is not perfect square\n",
            "9920 is not perfect square\n",
            "9921 is not perfect square\n",
            "9922 is not perfect square\n",
            "9923 is not perfect square\n",
            "9924 is not perfect square\n",
            "9925 is not perfect square\n",
            "9926 is not perfect square\n",
            "9927 is not perfect square\n",
            "9928 is not perfect square\n",
            "9929 is not perfect square\n",
            "9930 is not perfect square\n",
            "9931 is not perfect square\n",
            "9932 is not perfect square\n",
            "9933 is not perfect square\n",
            "9934 is not perfect square\n",
            "9935 is not perfect square\n",
            "9936 is not perfect square\n",
            "9937 is not perfect square\n",
            "9938 is not perfect square\n",
            "9939 is not perfect square\n",
            "9940 is not perfect square\n",
            "9941 is not perfect square\n",
            "9942 is not perfect square\n",
            "9943 is not perfect square\n",
            "9944 is not perfect square\n",
            "9945 is not perfect square\n",
            "9946 is not perfect square\n",
            "9947 is not perfect square\n",
            "9948 is not perfect square\n",
            "9949 is not perfect square\n",
            "9950 is not perfect square\n",
            "9951 is not perfect square\n",
            "9952 is not perfect square\n",
            "9953 is not perfect square\n",
            "9954 is not perfect square\n",
            "9955 is not perfect square\n",
            "9956 is not perfect square\n",
            "9957 is not perfect square\n",
            "9958 is not perfect square\n",
            "9959 is not perfect square\n",
            "9960 is not perfect square\n",
            "9961 is not perfect square\n",
            "9962 is not perfect square\n",
            "9963 is not perfect square\n",
            "9964 is not perfect square\n",
            "9965 is not perfect square\n",
            "9966 is not perfect square\n",
            "9967 is not perfect square\n",
            "9968 is not perfect square\n",
            "9969 is not perfect square\n",
            "9970 is not perfect square\n",
            "9971 is not perfect square\n",
            "9972 is not perfect square\n",
            "9973 is not perfect square\n",
            "9974 is not perfect square\n",
            "9975 is not perfect square\n",
            "9976 is not perfect square\n",
            "9977 is not perfect square\n",
            "9978 is not perfect square\n",
            "9979 is not perfect square\n",
            "9980 is not perfect square\n",
            "9981 is not perfect square\n",
            "9982 is not perfect square\n",
            "9983 is not perfect square\n",
            "9984 is not perfect square\n",
            "9985 is not perfect square\n",
            "9986 is not perfect square\n",
            "9987 is not perfect square\n",
            "9988 is not perfect square\n",
            "9989 is not perfect square\n",
            "9990 is not perfect square\n",
            "9991 is not perfect square\n",
            "9992 is not perfect square\n",
            "9993 is not perfect square\n",
            "9994 is not perfect square\n",
            "9995 is not perfect square\n",
            "9996 is not perfect square\n",
            "9997 is not perfect square\n",
            "9998 is not perfect square\n",
            "9999 is not perfect square\n",
            "10000 is perfect square\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " write two Python programs to demonstrate that the two expressions are\n",
        "equivalent (that is, provided with same inputs the two programs must return same\n",
        "outputs)"
      ],
      "metadata": {
        "id": "juJ0KJhUAW8s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = \"I love you\"\n",
        "s2=\"I love you too\"\n",
        "if s1 in s2 :\n",
        "  print(\"equal\")\n",
        "else:\n",
        "  print(\"not equal\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N69JMM5uyOPX",
        "outputId": "62b7325b-5d98-4baa-cf2a-ca5fad4e931b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "equal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a program to print the index of all chars \"e\"in the string \"The Forth Lonely Bridge\".\n",
        "the program can only use the function find (no other library functions are allowed)"
      ],
      "metadata": {
        "id": "S_LKPKZADHT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_all_occurrences(string,char):\n",
        "  index=-1\n",
        "  while True:\n",
        "    index=string.find(char,index+1)\n",
        "    if index==-1:\n",
        "      break\n",
        "    print(f\"Index of {char} found at: {index}\")\n",
        "string = \"The Forth Lonely Bridge\"\n",
        "char = \"e\"\n",
        "find_all_occurrences(string,char)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMDfA7c7At1l",
        "outputId": "8c62d3a3-1484-4767-9230-c0a17fe40116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index of e found at: 2\n",
            "Index of e found at: 13\n",
            "Index of e found at: 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def find_all_occurrences(string, char):\n",
        "    index = -1\n",
        "    while True:\n",
        "        index = string.find(char, index + 1)\n",
        "        if index == -1:\n",
        "            break\n",
        "        print(\"Index of '{}' found at: {}\".format(char, index))\n",
        "\n",
        "# Test the function\n",
        "string = \"The Forth Lonely Bridge\"\n",
        "char = \"e\"\n",
        "find_all_occurrences(string, char)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TylpRJbTE1Pu",
        "outputId": "31b94bd4-56f5-4d2e-e0a7-2cc9b39d3bdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index of 'e' found at: 2\n",
            "Index of 'e' found at: 13\n",
            "Index of 'e' found at: 22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a Python program to count the number of vowels in the string \"aurora\""
      ],
      "metadata": {
        "id": "ySC_bHBDeJAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "string = 'aurora'\n",
        "count = 0\n",
        "vowels = ['a','e','i','o','u']\n",
        "for char in string:\n",
        "  if char in vowels:\n",
        "    count+=1\n",
        "print(count)"
      ],
      "metadata": {
        "id": "JULTt-7ZGdAn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ff24daa-6bf5-4a05-944f-278f22c4e897"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a Python program that prints out True if a string s1 contains another string s2,\n",
        "False otherwise"
      ],
      "metadata": {
        "id": "Lv9nYNnsjsE_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1=\"I will\"\n",
        "s2=\"I will kill you\"\n",
        "if s1 in s2:\n",
        "  print(True)\n",
        "else:\n",
        "  print(False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlNYWV5mivdX",
        "outputId": "0c60f103-b8c1-456c-dff2-a4d95254ab2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " write a Python program to uppercase all words in a string (e.g., if given in input \"hello\n",
        "everybody\" it should print \"HELLO EVERYBODY\" in output)"
      ],
      "metadata": {
        "id": "dRBsaU1SkPko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "string = \"hello everybody\"\n",
        "upper = \"\"\n",
        "for char in string:\n",
        "  if char == \" \":\n",
        "    upper+=char\n",
        "  else:\n",
        "    upper+=char.upper()\n",
        "print(upper)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3NRVuxpkC_u",
        "outputId": "4790aece-7733-4018-9f9b-6029eb39c959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HELLO EVERYBODY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a Python program that counts letters, digits and special symbols in a given string"
      ],
      "metadata": {
        "id": "NiFtfm6_lF4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "letters = 0\n",
        "digits = 0\n",
        "symbols = 0\n",
        "for char in string:\n",
        "  if char.isalpha():\n",
        "    letters+=1\n",
        "  elif char.isdigit():\n",
        "    digits+=1\n",
        "  else:\n",
        "    symbols +=1\n",
        "print(letters)\n",
        "print(digits)\n",
        "print(symbols)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMUHOBI-kxtL",
        "outputId": "1bdac917-d112-42ad-b0c9-5263e927b38b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n",
            "0\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a Python program that (mistakenly) tries to alter a given string, e.g., by\n",
        "substituting a given character, and another program that correctly replaces that char by\n",
        "re-assigning the string"
      ],
      "metadata": {
        "id": "_5RQIIPZmTan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def correct_replace_string(input_string, old_char, new_char):\n",
        "    # Replace the character correctly by re-assigning the string\n",
        "    input_string = input_string.replace(old_char, new_char)\n",
        "    return input_string\n",
        "\n",
        "# Test the function\n",
        "input_string = \"hello world\"\n",
        "old_char = \"o\"\n",
        "new_char = \"x\"\n",
        "result = correct_replace_string(input_string, old_char, new_char)\n",
        "print(\"Correctly altered string:\", result)  # Output: \"hellx wxrld\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wX08voJl6K1",
        "outputId": "1ab0d332-ae59-4a32-c7d1-c3632b7548cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correctly altered string: hellx wxrld\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a Python program that removes punctuation from a given string"
      ],
      "metadata": {
        "id": "8IX-NtjNmmgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuation(input_string):\n",
        "    # Create translation table with None for each punctuation character\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    # Translate the input string using the translation table\n",
        "    return input_string.translate(translator)\n",
        "\n",
        "# Test the function\n",
        "input_string = \"Hello! How are you?\"\n",
        "result = remove_punctuation(input_string)\n",
        "print(\"String without punctuation:\", result)  # Output: \"Hello How are you\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAygB5zYmSsa",
        "outputId": "8328bfb3-896c-456d-8023-84a780c2dda2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "String without punctuation: Hello How are you\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a Python program that reverses a given string"
      ],
      "metadata": {
        "id": "h8stUfQunHjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "string = \"hello world\"\n",
        "nem_string = string[::-1]\n",
        "print(nem_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_TjwzMCnAnL",
        "outputId": "ffd41544-e53a-4d79-afe5-c17c2f7f7ab3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dlrow olleh\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a Python program that prints whether a given string is palindrome or not"
      ],
      "metadata": {
        "id": "-KktXxq3oW4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_palindrome(input_string):\n",
        "    # Remove spaces and convert to lowercase for case-insensitive comparison\n",
        "    input_string = input_string.replace(\" \", \"\").lower()\n",
        "    # Check if the string is equal to its reverse\n",
        "    return input_string == input_string[::-1]\n",
        "\n",
        "# Test the function\n",
        "input_string = \"A man a plan a canal Panama\"\n",
        "result = is_palindrome(input_string)\n",
        "if result:\n",
        "    print(\"The string is a palindrome.\")\n",
        "else:\n",
        "    print(\"The string is not a palindrome.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ5qfTqBoRO9",
        "outputId": "d893dc0b-9899-4200-b02f-df7c19eb85e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The string is a palindrome.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a Python program to remove the n-th index character from the string"
      ],
      "metadata": {
        "id": "gTqfYmY5oxxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_nth_char(input_string, n):\n",
        "    # Check if the index is valid\n",
        "    if n < 0 or n >= len(input_string):\n",
        "        return \"Invalid index\"\n",
        "    # Remove the n-th character by slicing the string\n",
        "    return input_string[:n] + input_string[n+1:]\n",
        "\n",
        "# Test the function\n",
        "input_string = \"hello world\"\n",
        "n = 3\n",
        "result = remove_nth_char(input_string, n)\n",
        "print(\"After removing the\", n, \"th character:\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBVAf_uloZfE",
        "outputId": "2f31867c-bdce-49cb-e998-27a37154bd67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After removing the 3 th character: helo world\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a Python program to count the number of occurrences of vowels in the string\n",
        "\"The Forth Bridge (is it where engineering's banners blaze?), Its mighty 'span': source\n",
        "of boundless pride.\""
      ],
      "metadata": {
        "id": "dxUBFKgNo0l7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_vowels(input_string):\n",
        "    vowels = \"aeiouAEIOU\"\n",
        "    vowel_count = 0\n",
        "    for char in input_string:\n",
        "        if char in vowels:\n",
        "            vowel_count += 1\n",
        "    return vowel_count\n",
        "\n",
        "# Test the function\n",
        "input_string = \"The Forth Bridge (is it where engineering's banners blaze?), Its mighty 'span': source of boundless pride.\"\n",
        "print(\"Number of vowels:\", count_vowels(input_string))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H7O6iqDowxb",
        "outputId": "4c9c56a4-0bfb-4700-edc0-603792d6b468"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of vowels: 29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_double_spaces(input_string):\n",
        "    while \"  \" in input_string:\n",
        "        input_string = input_string.replace(\"  \", \" \")\n",
        "    return input_string\n",
        "\n",
        "# Test the function\n",
        "input_string = \"This  is  a   test  string  with  double   spaces.\"\n",
        "output_string = replace_double_spaces(input_string)\n",
        "print(\"Original string:\", input_string)\n",
        "print(\"String with double spaces replaced:\", output_string)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Usm6BSujpNKj",
        "outputId": "c152fcec-93b3-46bb-b179-f482a7e99cde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original string: This  is  a   test  string  with  double   spaces.\n",
            "String with double spaces replaced: This is a test string with double spaces.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a Python function that takes in input a string and return the same string\n",
        "uppercased"
      ],
      "metadata": {
        "id": "ukTTEbkHLhUR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upper_case(string):\n",
        "  return string.upper()\n",
        "print(upper_case(\"hello world\"))"
      ],
      "metadata": {
        "id": "8bxItp1BpfOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d10e6a41-5601-41c8-b4f5-75db8572b639"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HELLO WORLD\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a Python function that takes in input a string returns True if it is palindrome, and\n",
        "False otherwise"
      ],
      "metadata": {
        "id": "X6YL3bYnL8uK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_palindrome(string):\n",
        "  string = string.lower()\n",
        "  string = ''.join(char for char in string if char.isalnum())\n",
        "  return string==string[::-1]\n",
        "print(is_palindrome('1232'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEd2ZWv0LwZG",
        "outputId": "d3961aa7-a655-4fa7-e4f9-f07ed38e7c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function to compute the Fibonacci number corresponding to a given (positive\n",
        "integer) value; recall that a Fibonacci number is the sum of the two preceding ones;"
      ],
      "metadata": {
        "id": "SJM744e_NCUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fibo(n):\n",
        "  if n<0:\n",
        "    return 'input must be positive'\n",
        "  elif n==1:\n",
        "    return 0\n",
        "  elif n==2:\n",
        "    return 1\n",
        "  else:\n",
        "    return fibo(n-1)+fibo(n-2)\n",
        "n=10\n",
        "print(fibo(n))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_Zr8UGTMKEm",
        "outputId": "c31273df-3043-49b2-dd6f-ba71c18e522d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function to generate the Fibonacci sequence for numbers in [1,100]; starting\n",
        "from 0 and 1, the Fibonacci sequence begins with 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89,\n",
        "144"
      ],
      "metadata": {
        "id": "zbHXv9eYPV3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fibonacci_sequence(n):\n",
        "    fib_sequence = [0, 1]\n",
        "    while fib_sequence[-1] + fib_sequence[-2] <= n:\n",
        "        fib_sequence.append(fib_sequence[-1] + fib_sequence[-2])\n",
        "    return fib_sequence\n",
        "\n",
        "# Test the function\n",
        "fib_seq = fibonacci_sequence(100)\n",
        "print(\"Fibonacci sequence up to 100:\", fib_seq)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sfve-WrkNEp-",
        "outputId": "c1fd6cda-8a34-4faf-ef9a-2fc5080e9fd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fibonacci sequence up to 100: [0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fibonacci(n):\n",
        "  if n<=1:\n",
        "    return n\n",
        "  else:\n",
        "    return (fibonacci(n-1)+fibonacci(n-2))\n",
        "nth = 10\n",
        "for i in range(nth):\n",
        "  print(fibonacci(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxZzFWPoQVy3",
        "outputId": "4422d8ce-8520-4305-981e-6524cd282c1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "3\n",
            "5\n",
            "8\n",
            "13\n",
            "21\n",
            "34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " write a Python function that takes in input two numbers, calls four more functions (to\n",
        "be devised) to compute sum, subtraction, product and quotient between the given\n",
        "numbers, and returns sum, subtraction, product and quotient"
      ],
      "metadata": {
        "id": "FeP4ITnJTJe_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def four(n1,n2):\n",
        "  return (f\"{sum(n1,n2)},{sub(n1,n2)},{prod(n1,n2)},{quotient(n1,n2)}\")\n",
        "def sum(n1,n2):\n",
        "  return n1+n2\n",
        "def sub(n1,n2):\n",
        "  return n1-n2\n",
        "def prod(n1,n2):\n",
        "  return n1*n2\n",
        "def quotient(n1,n2):\n",
        "  return n1//n2\n",
        "print(four(6,2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tmWpuybS70Y",
        "outputId": "2b390400-171d-4d17-8c24-09696a038b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8,4,12,3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a Python function that takes in input an integer and prints out its factors (e.g., if\n",
        "such program took in input , it should print ."
      ],
      "metadata": {
        "id": "y6DjW4Ujq-s9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def factor(num):\n",
        "  sum=0 #5 = 5*4*3*2*1\n",
        "  factors = 1\n",
        "  for i in range(1,num+1):\n",
        "    print(i)\n",
        "    factors = factors*i\n",
        "  return factors\n",
        "factor(5)\n",
        "\n"
      ],
      "metadata": {
        "id": "7Ru2EZwGURpI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae485bf1-6751-4446-9d9e-e09b4c27e662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_factors(n):\n",
        "    factors = []\n",
        "    for i in range(1, n + 1):\n",
        "        if n % i == 0:\n",
        "            factors.append(i)\n",
        "    print(\"Factors of\", n, \"are:\", factors)\n",
        "\n",
        "# Test the function\n",
        "print_factors(12)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBcxQyp0sQDw",
        "outputId": "b264151b-6e61-48c1-ea89-14919816e123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Factors of 12 are: [1, 2, 3, 4, 6, 12]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function to find the minimum of two integers read from user input (use of the\n",
        "library max() function is not allowed)"
      ],
      "metadata": {
        "id": "dw9huaBdufHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def minimum(int1,int2):\n",
        "  if int1>int2:\n",
        "    return int1\n",
        "  elif int1<int2:\n",
        "    return int2\n",
        "  else:\n",
        "    return 'equal'\n",
        "int1= int(input(\"Enter the first integer>>> \"))\n",
        "int2 = int(input(\"Enter the second integer>>> \"))\n",
        "minimum(int1,int2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cppYTzaiuSR4",
        "outputId": "1d1bdf5f-a5fa-4515-b5d5-3d6ba69d6e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the first integer>>> 3\n",
            "Enter the second integer>>> 5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function to find the largest of three given integers (same as above: avoid using\n",
        "max() function)"
      ],
      "metadata": {
        "id": "0iQdJ_OmvJ9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def maximum(int1,int2,int3):\n",
        "\n",
        "  if int1>int2 and int1>int3:\n",
        "    return int1\n",
        "  elif int1==int2 and int2==int3:\n",
        "    return 'equal'\n",
        "  elif int2>int1 and int2>int3:\n",
        "    return int2\n",
        "  else:\n",
        "    return int3\n",
        "int1 = int(input(\"Enter the first integer: \"))\n",
        "int2 = int(input(\"Enter the secon integer: \"))\n",
        "int3 =int(input(\"Enter the third integer: \"))\n",
        "print(maximum(int1,int2,int3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8TNvJykvB_w",
        "outputId": "0ed087d5-d225-47d4-90e3-1965e521f381"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the first integer: 1\n",
            "Enter the secon integer: 2\n",
            "Enter the third integer: 3\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function to determine whether a given number is even or odd"
      ],
      "metadata": {
        "id": "0iG2HUfmwzC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def even_or_odd(number):\n",
        "  if number%2==0:\n",
        "    return 'even'\n",
        "  else:\n",
        "    return 'odd'\n",
        "number = int(input(\"Enter the number: \"))\n",
        "even_or_odd(number)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "YUbzye9Av_Lm",
        "outputId": "08e6b7ef-6c46-4868-f80f-d98a95508050"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the number: 14\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'even'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a Python function that takes in input an integer and returns the factorial of that\n",
        "number. recall that the factorial of a non-negative integer , denoted by , is the\n",
        "product of all positive integers less than or equal to n"
      ],
      "metadata": {
        "id": "ho3Hpsudxb3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def factor(num):\n",
        "  factor = 1\n",
        "  for i in range(1,num+1):\n",
        "    factor = factor*i\n",
        "  return factor\n",
        "num = int(input(\"Enter an integer number>>> \"))\n",
        "print(factor(num))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dqu0uFAFxVc0",
        "outputId": "d7e24bda-a4fc-4d27-d827-7dd8d7e243bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter an integer number>>> 6\n",
            "720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write both encoder and decoder functions for the Caesar's cipher, such that the\n",
        "functions take in input both a string (either the plain text or the ciphered text, and the n\n",
        "indicating how many positions the plain text must be moved in the encrypted text)"
      ],
      "metadata": {
        "id": "y4IBrPYQyaqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def caesar_cipher_encoder(plain_text, n):\n",
        "    encrypted_text = \"\"\n",
        "    for char in plain_text:\n",
        "        if char.isalpha():\n",
        "            if char.islower():\n",
        "                encrypted_text += chr((ord(char) - ord('a') + n) % 26 + ord('a'))\n",
        "            else:\n",
        "                encrypted_text += chr((ord(char) - ord('A') + n) % 26 + ord('A'))\n",
        "        else:\n",
        "            encrypted_text += char\n",
        "    return encrypted_text\n",
        "\n",
        "def caesar_cipher_decoder(cipher_text, n):\n",
        "    decrypted_text = \"\"\n",
        "    for char in cipher_text:\n",
        "        if char.isalpha():\n",
        "            if char.islower():\n",
        "                decrypted_text += chr((ord(char) - ord('a') - n) % 26 + ord('a'))\n",
        "            else:\n",
        "                decrypted_text += chr((ord(char) - ord('A') - n) % 26 + ord('A'))\n",
        "        else:\n",
        "            decrypted_text += char\n",
        "    return decrypted_text\n",
        "\n",
        "# Test the functions\n",
        "plain_text = \"Hello, World!\"\n",
        "n = 3\n",
        "cipher_text = caesar_cipher_encoder(plain_text, n)\n",
        "print(\"Ciphered Text:\", cipher_text)\n",
        "\n",
        "decoded_text = caesar_cipher_decoder(cipher_text, n)\n",
        "print(\"Deciphered Text:\", decoded_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8jfAW16ySHF",
        "outputId": "299c4769-baed-4e20-c03b-8d6264b1f39f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ciphered Text: Khoor, Zruog!\n",
            "Deciphered Text: Hello, World!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function to compute the Fibonacci number corresponding to a given (positive\n",
        "integer) value; recall that a Fibonacci number is the sum of the two preceding ones;"
      ],
      "metadata": {
        "id": "ez3Lxzfd0PG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fibonacci(number):\n",
        "    if number <= 1:\n",
        "      return number\n",
        "    else:\n",
        "      return (fibonacci(number-1)+fibonacci(number-2))\n",
        "number = int(input(\"Nth number>>> \"))\n",
        "for i in range(number):\n",
        "  print(fibonacci(i))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LEnLmD7y5Yk",
        "outputId": "a1676266-8ee8-41d3-8554-e92a92d2f15e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nth number>>> 5\n",
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fibonacci(n):\n",
        "  if n<=1:\n",
        "    return n\n",
        "  else:\n",
        "    return (fibonacci(n-1)+fibonacci(n-2))\n",
        "nth = int(input('enter'))\n",
        "for i in range(nth):\n",
        "  print(fibonacci(i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8_tSzcA1Xkl",
        "outputId": "8765be12-c283-4473-cf79-0bca50a4d8ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter5\n",
            "0\n",
            "1\n",
            "1\n",
            "2\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_list =[1,2,'end']\n",
        "for el in my_list:\n",
        "  print(el)"
      ],
      "metadata": {
        "id": "NSzuwwMy38Yx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8ec3539-fe4a-4cd2-ddd4-ebf2b30c578a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "2\n",
            "end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_list =[1,2,'end']\n",
        "for idx in range(len(my_list)):\n",
        "  print(idx)\n",
        "print(len(my_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95IVPsKX7K8c",
        "outputId": "7dd77fd6-e6f0-4a7d-ddac-248c0bdf7d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blist = ['h','e','l','l','o']\n",
        "bstring = \" \".join(blist)\n",
        "print(bstring)\n",
        "cstring = '-'.join(blist)\n",
        "print(cstring)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c7QtYSG7VHr",
        "outputId": "a24b5f44-091c-4dc4-c581-017138020ed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h e l l o\n",
            "h-e-l-l-o\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list = [1,2,3,4,5]\n",
        "print(len(list))\n",
        "print(max(list))\n",
        "print(min(list))\n",
        "list.append(4)\n",
        "print(list)\n",
        "print(list.count(4))\n",
        "print(list.index(4))\n",
        "print(list.remove(4))\n",
        "print(list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EChD-4If8j4z",
        "outputId": "6fab3493-32a4-418d-836d-8e6e5253f5d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "5\n",
            "1\n",
            "[1, 2, 3, 4, 5, 4]\n",
            "2\n",
            "3\n",
            "None\n",
            "[1, 2, 3, 5, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "listA=[1,2,3]\n",
        "listC=listA[:]\n",
        "print(listC)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Lrt2Mc782iK",
        "outputId": "707b1985-b805-4d5a-d180-35fd32c7f9bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#list comprehension\n",
        "#new_list=[expression(element) for element in oldList if condition]\n",
        "list_a=[1,2,3]\n",
        "squared = [x**2 for x in list_a]\n",
        "print(squared)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWaPV6xv_K50",
        "outputId": "ec596bd4-911e-45e9-9142-58c800450847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "take the elements in the range [1,10]\n",
        "2. check whether these are even\n",
        "(i%2==0); if so,\n",
        "3. take even integers and add them to\n",
        "list_a"
      ],
      "metadata": {
        "id": "soyV5DqmAJDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_list = [x for x in range(11) if x%2==0]\n",
        "print(new_list)\n",
        "for x in range(11):\n",
        "  print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gk8ZW_p_-qE",
        "outputId": "9142bf4e-a9f3-469e-93b0-aae4f6622bce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 2, 4, 6, 8, 10]\n",
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_a=[]\n",
        "for char in 'hi all!':\n",
        "  list_a.append(char)\n",
        "print(list_a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdrmGzO9AUvt",
        "outputId": "f2cadd7e-4925-4506-eaeb-cd9063b08793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['h', 'i', ' ', 'a', 'l', 'l', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "assignment:\n",
        "1. write a program equivalent to the above by using the for loop\n",
        "2. given the code below, write the equivalent by employing list comprehension"
      ],
      "metadata": {
        "id": "mCDif14DA2YP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "squared_nums = [n**2 for n in range(1,11)]\n",
        "print(squared_nums)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82T3QxgjAmrF",
        "outputId": "48664249-d72d-4c88-8479-2e18891585f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list=[]\n",
        "for i in range(1,11):\n",
        "  list.append(i**2)\n",
        "print(list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGYzGsJeCPGV",
        "outputId": "fafe1148-bfe3-441d-de34-444e2d3f57fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=[1,2,3,4,5,6,7,8]\n",
        "b=[]\n",
        "for el in a:\n",
        "  if el%2==0:\n",
        "    b.append(el)\n",
        "print(b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QNyxkGpCc41",
        "outputId": "750cc3f6-dc24-4032-d051-2779a0c02455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 4, 6, 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a=[1,2,3,4,5,6,7,8]\n",
        "new_list=[x for x in a if x%2==0]\n",
        "print(new_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2WCDA-KCpHE",
        "outputId": "6df7594c-5fdb-4961-b303-400d2ad83458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 4, 6, 8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "medals = [[0,3,0],\n",
        "          [0,0,1],\n",
        "          [0,0,1],\n",
        "          [1,0,0],\n",
        "          [1,0,1]]\n",
        "print(f\"ita_gold: {medals[0][0]}\")\n",
        "print(f\"fra_bron: {medals[1][2]}\")\n",
        "print(f\"jap_silv: {medals[4][1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMV6nHAJDJlN",
        "outputId": "2be6d01a-70b3-4feb-8b86-c5acb4b8d7b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ita_gold: 0\n",
            "fra_bron: 1\n",
            "jap_silv: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "medals = [[0,3,0],\n",
        "          [0,0,1],\n",
        "          [0,0,1],\n",
        "          [1,0,0],\n",
        "          [1,0,1]]\n",
        "i = 4\n",
        "all_medals = 0\n",
        "for j in range(3):\n",
        "  all_medals+=medals[i][j]\n",
        "print(all_medals)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJMLZwaoD9OV",
        "outputId": "dd2dc8e2-9c31-467f-c28b-ba8104ca8f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "medals = [\n",
        "[0,3,0], # ita\n",
        "[0,0,1], # fra\n",
        "[0,0,1], # usa\n",
        "[1,0,0], # nor\n",
        "[1,0,1] # jap\n",
        "]\n",
        "gold_mdls = 0\n",
        "silv_mdls = 0\n",
        "bron_mdls = 0\n",
        "gold_mdls_idx = 0\n",
        "silv_mdls_idx = 1\n",
        "bron_mdls_idx = 2\n",
        "for i in range(len(medals)):\n",
        "  gold_mdls += medals[i][gold_mdls_idx]\n",
        "  silv_mdls += medals[i][silv_mdls_idx]\n",
        "  bron_mdls += medals[i][bron_mdls_idx]\n",
        "print(f'gold medals: {gold_mdls}; ',\n",
        "f'silver: {silv_mdls}; ',\n",
        "f'bronze: {bron_mdls}')\n",
        "print(len(medals))\n",
        "print(len(medals[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoqooAZ2Efjm",
        "outputId": "b87216a4-5502-47ff-93d8-3875f3bd6848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gold medals: 2;  silver: 3;  bronze: 3\n",
            "5\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "medals = [\n",
        "[0,3,0], # ita\n",
        "[0,0,1], # fra\n",
        "[0,0,1], # usa\n",
        "[1,0,0], # nor\n",
        "[1,0,1] # jap\n",
        "]\n",
        "total = 0\n",
        "for row in range(len(medals)):\n",
        "  print(row)\n",
        "  for col in range(len(medals[0])):\n",
        "    total += medals[row][col]\n",
        "print(total)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWwDCCS7E_5l",
        "outputId": "850cc8e2-098c-4e25-dac4-05df9cd4f990"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a program that computes all medals won by each Country (consider the\n",
        "above data), and plots a table such as\n",
        "Ita: 3\n",
        "Fra: 1\n",
        "Usa: 1\n",
        "Nor: 1\n",
        "Jap: 2"
      ],
      "metadata": {
        "id": "RZA0AQJPKQhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "medals = [\n",
        "    [\"Ita\", 0, 3, 0],  # ita\n",
        "    [\"Fra\", 0, 0, 1],  # fra\n",
        "    [\"Usa\", 0, 0, 1],  # usa\n",
        "    [\"Nor\", 1, 0, 0],  # nor\n",
        "    [\"Jap\", 1, 0, 1]   # jap\n",
        "]\n",
        "\n",
        "def compute_medals(medals_list):\n",
        "    country_medals = {}\n",
        "    for entry in medals_list:\n",
        "        country = entry[0]\n",
        "        gold, silver, bronze = entry[1:]\n",
        "        total_medals = gold + silver + bronze\n",
        "        country_medals[country] = total_medals\n",
        "    return country_medals\n",
        "\n",
        "def plot_medals(country_medals):\n",
        "    for country, total_medals in country_medals.items():\n",
        "        print(f\"{country}: {total_medals}\")\n",
        "\n",
        "# Compute and print medals won by each country\n",
        "country_medals = compute_medals(medals)\n",
        "plot_medals(country_medals)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_47C6w4lFelP",
        "outputId": "597a5fc5-7d29-43b4-83ed-ad0dd8d12e56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ita: 3\n",
            "Fra: 1\n",
            "Usa: 1\n",
            "Nor: 1\n",
            "Jap: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a program assigning 4 scores to gold medals, 2 to silver medals and 1 score\n",
        "to bronze medals; plot the resulting table with a score associated to each involved\n",
        "Country"
      ],
      "metadata": {
        "id": "qkYQp9SCKU-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "medals = [\n",
        "    [\"Ita\", 0, 3, 0],  # ita\n",
        "    [\"Fra\", 0, 0, 1],  # fra\n",
        "    [\"Usa\", 0, 0, 1],  # usa\n",
        "    [\"Nor\", 1, 0, 0],  # nor\n",
        "    [\"Jap\", 1, 0, 1]   # jap\n",
        "]\n",
        "\n",
        "def compute_scores(medals_list):\n",
        "    country_scores = {}\n",
        "    for entry in medals_list:\n",
        "        country = entry[0]\n",
        "        gold, silver, bronze = entry[1:]\n",
        "        total_score = gold * 4 + silver * 2 + bronze\n",
        "        country_scores[country] = total_score\n",
        "    return country_scores\n",
        "\n",
        "def plot_scores(country_scores):\n",
        "    for country, total_score in country_scores.items():\n",
        "        print(f\"{country}: {total_score}\")\n",
        "\n",
        "# Compute and plot scores for each country\n",
        "country_scores = compute_scores(medals)\n",
        "plot_scores(country_scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVGwVMTjG10W",
        "outputId": "c476e863-27fd-4a6f-f97d-0f054f35817f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ita: 6\n",
            "Fra: 1\n",
            "Usa: 1\n",
            "Nor: 4\n",
            "Jap: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that takes in input a list of integers and returns the sum of all\n",
        "values"
      ],
      "metadata": {
        "id": "-cgAcnvyLHPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1,2,4,5,6,4,9,7,8,0]\n",
        "def sam(a):\n",
        "  total = 0\n",
        "  for i in range(len(a)):\n",
        "    total += a[i]\n",
        "  return total\n",
        "print(sam(a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAht-UfZKqmY",
        "outputId": "007c441b-bf30-407a-8edc-a4f5cc5523d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that returns the sum of odd/even elements (an additional\n",
        "parameter must be used to distinguish between the two cases)"
      ],
      "metadata": {
        "id": "sjtENpQrMIgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sum_odd_even_elements(numbers, is_odd=True):\n",
        "    total = 0\n",
        "    for num in numbers:\n",
        "        if is_odd and num % 2 != 0:  # If computing the sum of odd elements\n",
        "            total += num\n",
        "        elif not is_odd and num % 2 == 0:  # If computing the sum of even elements\n",
        "            total += num\n",
        "    return total\n",
        "\n",
        "# Example usage:\n",
        "a = [1, 2, 4, 5, 6, 4, 9, 7, 8, 0]\n",
        "sum_odd = sum_odd_even_elements(a, is_odd=True)\n",
        "sum_even = sum_odd_even_elements(a, is_odd=False)\n",
        "\n",
        "print(\"Sum of odd elements:\", sum_odd)\n",
        "print(\"Sum of even elements:\", sum_even)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgmqS7NZMAJh",
        "outputId": "f7f27648-05a9-48e1-cd80-fa23897625f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of odd elements: 22\n",
            "Sum of even elements: 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sum_odd_even(numbers,is_odd=True):\n",
        "  total = 0\n",
        "  if is_odd and num%2!=0:\n",
        "    total+=num\n",
        "  elif not is_odd and num%2==0:\n",
        "    total+=num\n",
        "  return total\n",
        "a = [1,2,3,4,5,6,7,8,0]\n",
        "sum_odd = sum_odd_even_elements(a,is_odd=True)\n",
        "sum_even = sum_odd_even_elements(a,is_odd=False)\n",
        "print(\"Sum of odd elements:\",sum_odd)\n",
        "print(\"Sum of even elements:\",sum_even)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPrCXa84N1Qp",
        "outputId": "cfb73c66-fb87-4d9c-def2-c98f41cb1042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of odd elements: 16\n",
            "Sum of even elements: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that returns the sum of all elements at even/odd index"
      ],
      "metadata": {
        "id": "a-pzY-EDyY-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1, 2, 4, 5, 6, 4, 9, 7, 8, 0]\n",
        "def sum_of_elements(list):\n",
        "  for idx in range(len(list)):\n",
        "    print(idx)\n",
        "    even=0\n",
        "    odd=0\n",
        "    if idx==0 or idx%2==0:\n",
        "      even+=list[idx]\n",
        "    elif idx%2!=0:\n",
        "      odd+=list[idx]\n",
        "  print(even)\n",
        "\n",
        "sum_of_elements(a)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDR1H_2GyPyu",
        "outputId": "61d49fc7-6dba-4876-81e1-2d336ddc589f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sum_elements_at_indices(lst, odd=True):\n",
        "    total = 0\n",
        "    for i, num in enumerate(lst):\n",
        "        if (odd and i % 2 != 0) or (not odd and i % 2 == 0):\n",
        "            total += num\n",
        "    return total\n",
        "\n",
        "# Example usage:\n",
        "my_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "sum_even_indices = sum_elements_at_indices(my_list, odd=False)\n",
        "sum_odd_indices = sum_elements_at_indices(my_list, odd=True)\n",
        "\n",
        "print(\"Sum of elements at even indices:\", sum_even_indices)\n",
        "print(\"Sum of elements at odd indices:\", sum_odd_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEZNEdtXzdEn",
        "outputId": "e6a94fbb-e697-4445-c9ed-7b7cefdaf005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of elements at even indices: 25\n",
            "Sum of elements at odd indices: 30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that returns the minimum value in the list"
      ],
      "metadata": {
        "id": "jW4VVMHEFXdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1, 2, 4, 5, 6, 4, 9, 7, 8, 0]\n",
        "def minimum(list):\n",
        "  return min(list)\n",
        "minimum(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygM462tc3wcB",
        "outputId": "2b2271da-d17c-4ba0-b428-55abec9c5c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that returns the index of the minimum value in the list\n"
      ],
      "metadata": {
        "id": "3BCGHEzBGndZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "a = [1, 2, 4, 5, 6, 4, 9, 7, 8, 0]\n",
        "def minimum_indices(minim,a):\n",
        "  final=0\n",
        "  for idx in range(len(a)):\n",
        "    if minim == a[idx]:\n",
        "      final+=idx\n",
        "  return idx\n",
        "\n",
        "minim = min(a)\n",
        "print(minimum_indices(minim,a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShLoAjq2Gh2m",
        "outputId": "7fb2691e-5f44-42f5-8c82-c187eed6d308"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that returns a new list containing, sorted, the same values as a\n",
        "as previous exercise, but the new list must be sorted in reversed order"
      ],
      "metadata": {
        "id": "2iOc1CKBJ4CR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1, 2, 4, 5, 6, 4, 9, 7, 8, 0]\n",
        "def sorted_reverse(list):\n",
        "  new_list = sorted(list)\n",
        "  return new_list[::-1]\n",
        "print(sorted_reverse(a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gMb35oJJwp3",
        "outputId": "78c62bbd-f924-4428-82d6-f3dd58ab44db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9, 8, 7, 6, 5, 4, 4, 2, 1, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that returns True if the sum of all elements is odd and False\n",
        "otherwise. hint: re-use the function devised for exercise 1 above.\n"
      ],
      "metadata": {
        "id": "rT5AI8wiLdq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1, 2, 4, 5, 6, 4, 9, 7, 8, 0]\n",
        "def sum_odd_even_el(list):\n",
        "  sum = 0\n",
        "  for idx in range(len(list)):\n",
        "    sum+=list[idx]\n",
        "  return true_fals(sum)\n",
        "def true_fals(sum):\n",
        "  if sum%2==0:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "print(sum_odd_even_el(a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhE75IzaKiWv",
        "outputId": "ff23be08-512b-4e90-81b6-89e81596f701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that takes two integers from the user input and sums the elements\n",
        "at those indexes in a (must check that input elements correspond to valid indices)"
      ],
      "metadata": {
        "id": "ZApOCv7MM52X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1, 2, 4, 5, 6, 4, 9, 7, 8, 0]\n",
        "def sum_corresponding_indices(int1,int2,list):\n",
        "  if int1<0 or int1>len(list) or int2<0 or int2>len(list):\n",
        "    print(\"invalid indices\")\n",
        "    return None\n",
        "  else:\n",
        "    return list[int1]+list[int2]\n",
        "int1 = int(input(\"Enter the first integer>>> \"))\n",
        "int2 = int(input(\"Enter the second integer>>> \"))\n",
        "print(sum_corresponding_indices(int1,int2,a))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDRaXEEFMD7g",
        "outputId": "4a54614a-1a3b-4888-b669-a4d9fd81fe83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the first integer>>> 11\n",
            "Enter the second integer>>> 12\n",
            "invalid indices\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that returns two new lists, containing even or odd numbers in a"
      ],
      "metadata": {
        "id": "oCr_9yqVP5Oq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def two_list(list):\n",
        "  list_odd=[]\n",
        "  list_even=[]\n",
        "  for num in list:\n",
        "    if num%2==0:\n",
        "      list_even.append(num)\n",
        "    else:\n",
        "      list_odd.append(num)\n",
        "  return list_odd,list_even\n",
        "a = [1, 2, 4, 5, 6, 4, 9, 7, 8, 0]\n",
        "print(two_list(a))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO7-kEpSOCSY",
        "outputId": "92ee571e-c372-4765-bf07-bbc038a4b230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "([1, 5, 9, 7], [2, 4, 6, 4, 8, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = [1, 2, 4, 5, 6, 4, 9, 7, 8, 0]\n",
        "for num in a:\n",
        "  even =[]\n",
        "  if num%2==0:\n",
        "    even.append(num)\n",
        "print(even)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBIdSiMNQnDp",
        "outputId": "1b62685b-f9bc-4685-ef07-4d307cf7d173"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def separate_even_odd(numbers):\n",
        "    even_numbers = []\n",
        "    odd_numbers = []\n",
        "    for num in numbers:\n",
        "        if num % 2 == 0:\n",
        "            even_numbers.append(num)\n",
        "        else:\n",
        "            odd_numbers.append(num)\n",
        "    return even_numbers, odd_numbers\n",
        "\n",
        "a = [1, 2, 4, 5, 6, 4, 9, 7, 8, 0]\n",
        "print(separate_even_odd(a))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOrjpZ8mQwmh",
        "outputId": "900755d1-8d26-46ee-c2ba-90c397819f63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "([2, 4, 6, 4, 8, 0], [1, 5, 9, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function to append the integer number 3 at the end of a; (and test it on\n",
        "Python Tutor) a = (1,2,4,5,6,4,9,7,8,0)"
      ],
      "metadata": {
        "id": "hPut2v-H-U6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def append_3(tuple_input):\n",
        "    if isinstance(tuple_input, tuple):\n",
        "        return tuple_input + (3,)\n",
        "    else:\n",
        "        print(\"Input is not a tuple.\")\n",
        "\n",
        "a = (1, 2, 4, 5, 6, 4, 9, 7, 8, 0)\n",
        "a_with_3 = append_3(a)\n",
        "print(a_with_3)\n"
      ],
      "metadata": {
        "id": "VsEm1fBBSTly",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63d64738-0409-4702-a137-d6def1db5b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 2, 4, 5, 6, 4, 9, 7, 8, 0, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function to add the new tuple b = (11,12,13) after the first element in\n",
        "a; the function takes b and returns the updated version of a; check that the old\n",
        "tuple a is unchanged after the insertion"
      ],
      "metadata": {
        "id": "-fz9D_48-1fO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def addd(a,b):\n",
        "  if isinstance(a,tuple) and isinstance(b,tuple):\n",
        "    return a[:1]+b+a[1:]\n",
        "  else:\n",
        "    print(\"input is not a tuple.\")\n",
        "a=(1,2,4,5,6,4,9,7,8,0)\n",
        "b=(11,12,13)\n",
        "print(addd(a,b))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jLsX4La-sMI",
        "outputId": "256e4d7c-e1bc-4123-ebd0-351d00fe0aea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 11, 12, 13, 2, 4, 5, 6, 4, 9, 7, 8, 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that takes in input the tuple tup = ('h','e','l','l','o','\n",
        "','g','u','y','z'), and converts it into a string"
      ],
      "metadata": {
        "id": "BdHAQQnt_wD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tuple_to_string(tup):\n",
        "  if isinstance(tup,tuple):\n",
        "    return \"\".join(tup)\n",
        "  else:\n",
        "    print(\"Input is not a tuple\")\n",
        "\n",
        "tup = ('h','e','l','l','o','','g','u','y','z')\n",
        "tuple_to_string(tup)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dH50zGuY_sQQ",
        "outputId": "cd0b4386-034c-4d05-af3b-ecbc94b1dff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'helloguyz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tuple_to_string(tup):\n",
        "    if isinstance(tup, tuple):\n",
        "        return ''.join(tup)\n",
        "    else:\n",
        "        print(\"Input is not a tuple.\")\n",
        "\n",
        "tup = ('h', 'e', 'l', 'l', 'o', '\\n', 'g', 'u', 'y', 'z')\n",
        "resulting_string = tuple_to_string(tup)\n",
        "print(\"Resulting string:\", resulting_string)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJSj_sDS__C_",
        "outputId": "2d573e30-552d-4e62-aaea-d9bb66cf70ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resulting string: hello\n",
            "guyz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "modify previous function to handle also a tuple of int values, such as a =\n",
        "(1,2,4,5,6,4,9,7,8,0); hint: convert the tuple into a string before\n",
        "concatenating elements... and use casting"
      ],
      "metadata": {
        "id": "ihCVYgswAeSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tuple_to_string(tup):\n",
        "    if isinstance(tup, tuple):\n",
        "        return ''.join(map(str, tup))\n",
        "    else:\n",
        "        print(\"Input is not a tuple.\")\n",
        "\n",
        "# Test with tuple of characters\n",
        "tup_chars = ('h', 'e', 'l', 'l', 'o', '\\n', 'g', 'u', 'y', 'z')\n",
        "resulting_string_chars = tuple_to_string(tup_chars)\n",
        "print(\"Resulting string (chars):\", resulting_string_chars)\n",
        "\n",
        "# Test with tuple of integers\n",
        "tup_ints = (1, 2, 4, 5, 6, 4, 9, 7, 8, 0)\n",
        "resulting_string_ints = tuple_to_string(tup_ints)\n",
        "print(\"Resulting string (ints):\", resulting_string_ints)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq5RlYwCAOQ4",
        "outputId": "584f62b3-4981-4080-9855-020e07951027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resulting string (chars): hello\n",
            "guyz\n",
            "Resulting string (ints): 1245649780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " write a function that takes in input a tuple and a string, and returns True if the\n",
        "tuple contains the given string, and False otherwise"
      ],
      "metadata": {
        "id": "2FWkXMqjA5q1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def input_tuple_string(tup,st):\n",
        "  if isinstance(tup,tuple):\n",
        "    return st in (\"\".join(tup))\n",
        "  else:\n",
        "    print(\"Input is not a tuple\")\n",
        "st = \"o\"\n",
        "tup_chars = ('h', 'e', 'l', 'l', 'o', '\\n', 'g', 'u', 'y', 'z')\n",
        "print(input_tuple_string(tup_chars,st))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUlBUYHIA1FY",
        "outputId": "69773a2e-13ed-4cdc-f3e2-c7e8e3b747a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that takes in input a list of integers and returns a tuple of pairs (int,\n",
        "square). for example, if the input to the function was a = [2,3,4], the desired\n",
        "output is tup = ((2,4), (3,9), (4,16))"
      ],
      "metadata": {
        "id": "LK0YPhodCK2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tuple_of_pairs(lol):\n",
        "  if isinstance(a,list):\n",
        "    return tuple((x, x**2) for x in a)\n",
        "  else:\n",
        "    print(\"input is not a list\")\n",
        "a = [2,3,4]\n",
        "print(tuple_of_pairs(a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PMEmIe7B8Co",
        "outputId": "824021b8-1748-437c-a56c-8a03fa63fa95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((2, 4), (3, 9), (4, 16))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def int_list_to_tuple_of_pairs(int_list):\n",
        "    if isinstance(int_list, list):\n",
        "        return tuple((x, x**2) for x in int_list)\n",
        "    else:\n",
        "        print(\"Input is not a list.\")\n",
        "\n",
        "# Test the function\n",
        "a = [2, 3, 4]\n",
        "tup = int_list_to_tuple_of_pairs(a)\n",
        "print(tup)  # Output will be ((2, 4), (3, 9), (4, 16))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Cv_k3cvDybh",
        "outputId": "199cb308-a2fa-4616-d2ac-ddc6a9abe938"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((2, 4), (3, 9), (4, 16))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that takes a list of tuples (a = [(2,3),(4,5)]) and returns a list\n",
        "of lists, such as a = [[2,3],[4,5]];"
      ],
      "metadata": {
        "id": "-iEFs7uwENyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_of_lists(tup):\n",
        "  if isinstance(tup,list):\n",
        "    return [list(x) for x in tup]\n",
        "  else:\n",
        "    print(\"Input is not a list\")\n",
        "a=[(2,3),(4,5)]\n",
        "print(list_of_lists(a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fo8xrUqeD4rx",
        "outputId": "1ec0ae8e-e9ef-4e88-88e0-1569534412eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2, 3], [4, 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that takes a tuple of tuples such as a=((1,2,3),(4,5,6),\n",
        "(7,8,9)) and performs element-wise sum, returning results in a tuple. given the\n",
        "tuple a in input, the expected output is thus (6,15,24)."
      ],
      "metadata": {
        "id": "mAV6ae_QFrWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sum_tuples(tup):\n",
        "  if isinstance(tup,tuple):\n",
        "    return tuple(sum(x) for x in tup)\n",
        "  else:\n",
        "    print(\"input is not a tuple\")\n",
        "a=((1,2,3),(4,5,6),(7,8,9))\n",
        "print(sum_tuples(a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6RdfskSFX9M",
        "outputId": "cf474518-5978-4266-90b7-2791329a9c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6, 15, 24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function is_prime(num) that takes in input an integer and returns True\n",
        "if this is a prime number and False otherwise. the Sieve of Eratosthenes algorithm\n",
        "may be used"
      ],
      "metadata": {
        "id": "RZUt30J7HjdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_prime(num):\n",
        "  if isinstance(num,int):\n",
        "    num=str(num)\n",
        "    return num==num[::-1]\n",
        "  else:\n",
        "    print(\"input is not a integer\")\n",
        "a = int(input(\"Enter an integer number >>> \"))\n",
        "print(is_prime(a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLi3rzBNHHXa",
        "outputId": "1b9faf2c-7264-45e3-b3f5-d29ef601de96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter an integer number >>> 123\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that takes in input the integer bound and lists all prime numbers\n",
        "less than or equal to bound;"
      ],
      "metadata": {
        "id": "hnSFj-JyIHGD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_prime(num):\n",
        "    if num <= 1:\n",
        "        return False\n",
        "    elif num <= 3:\n",
        "        return True\n",
        "    elif num % 2 == 0 or num % 3 == 0:\n",
        "        return False\n",
        "    i = 5\n",
        "    while i * i <= num:\n",
        "        if num % i == 0 or num % (i + 2) == 0:\n",
        "            return False\n",
        "        i += 6\n",
        "    return True\n",
        "\n",
        "def list_primes(bound):\n",
        "    primes = []\n",
        "    for num in range(2, bound + 1):\n",
        "        if is_prime(num):\n",
        "            primes.append(num)\n",
        "    return primes\n",
        "\n",
        "# Test the function\n",
        "bound = 30\n",
        "prime_numbers = list_primes(bound)\n",
        "print(\"Prime numbers up to\", bound, \":\", prime_numbers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fW59jQB-H7x6",
        "outputId": "7e9407ba-6a98-46ae-bfa0-5cbd1504d995"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prime numbers up to 30 : [2, 3, 5, 7, 11, 13, 17, 19, 23, 29]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def list_prime(b):\n",
        "  numbers=[]\n",
        "  for num in range(2,b+1):\n",
        "    if all(num%i!=0 for i in range(2,int(num**0.5)+1)):\n",
        "      numbers.append(num)\n",
        "  return numbers\n",
        "bound = 30\n",
        "print(list_prime(bound))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF33GSHaIggL",
        "outputId": "fdd573b0-d082-4054-fe65-c3f05656022f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 3, 5, 7, 11, 13, 17, 19, 23, 29]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def list_primes(bound):\n",
        "    primes = []\n",
        "    for num in range(2, bound + 1):\n",
        "        if all(num % i != 0 for i in range(2, int(num ** 0.5) + 1)):\n",
        "            primes.append(num)\n",
        "    return primes\n",
        "\n",
        "# Test the function\n",
        "bound = 30\n",
        "prime_numbers = list_primes(bound)\n",
        "print(\"Prime numbers up to\", bound, \":\", prime_numbers)\n"
      ],
      "metadata": {
        "id": "6cqSk3RJJ0OU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that counts how many prime numbers are found in the range [0,\n",
        "bound]"
      ],
      "metadata": {
        "id": "_OjXdMJsLs3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def number_of_primes(b):\n",
        "  primes = []\n",
        "  count = 0\n",
        "  for num in range(2,b+1):\n",
        "    if all(num%i!=0 for i in range(2,int(num**0.5)+1)):\n",
        "      primes.append(num)\n",
        "      count+=1\n",
        "  return count\n",
        "bound = 30\n",
        "print(number_of_primes(bound))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NRvonGYLsRO",
        "outputId": "4200a843-aede-49f2-c369-9ea11949afc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that takes in input the integer nof_primes and returns the sum\n",
        "of the first nof_primes prime numbers"
      ],
      "metadata": {
        "id": "OgSd5aEuNJai"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_primes(bound):\n",
        "    primes = []\n",
        "    for num in range(2, bound + 1):\n",
        "        if all(num % i != 0 for i in range(2, int(num ** 0.5) + 1)):\n",
        "            primes.append(num)\n",
        "    return primes\n",
        "\n",
        "def sum_of_first_n_primes(nof_primes):\n",
        "    primes = list_primes(nof_primes ** 2)  # We get more primes than needed\n",
        "    return sum(primes[:nof_primes])\n",
        "\n",
        "# Test the function\n",
        "nof_primes = 5\n",
        "result = sum_of_first_n_primes(nof_primes)\n",
        "print(\"Sum of the first\", nof_primes, \"prime numbers:\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCXSw4jeM_r0",
        "outputId": "a766b11a-8990-45f1-d502-b0dd2a394047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of the first 5 prime numbers: 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def list_of_primes(bound):\n",
        "  numbers=[]\n",
        "  for num in range(2,bound+1):\n",
        "    if all(num%i!=0 for i in range(2,int(num**0.5)+1)):\n",
        "      numbers.append(num)\n",
        "  return numbers\n",
        "def sum_of_primes(number):\n",
        "  primes = list_of_primes(number**2)\n",
        "  return sum(primes[:number])\n",
        "nof_primes = 5\n",
        "result = sum_of_primes(nof_primes)\n",
        "print(\"Sum of the first\", nof_primes, \"prime numbers:\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ly36W4IMOZAd",
        "outputId": "52cc4fba-977a-4365-bdad-1a91ef611445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sum of the first 5 prime numbers: 28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that takes in input a and returns the elements from a zipped with\n",
        "the information on whether each one is even or odd, such as: [(1, 'odd'),\n",
        "(2, 'even', ...]"
      ],
      "metadata": {
        "id": "-8hHmlfOP3G0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def whether_odd_even(a):\n",
        "  lol = []\n",
        "  for num in a:\n",
        "    parity = 'even' if num%2==0 else 'odd'\n",
        "    lol.append((num,parity))\n",
        "  return lol\n",
        "a=(1,2,4,5,6,4,9,7,8,0)\n",
        "print(whether_odd_even(a))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qv0mvBlUPuDP",
        "outputId": "afeaac00-a7da-41ba-b2a3-07694afb4fad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(1, 'odd'), (2, 'even'), (4, 'even'), (5, 'odd'), (6, 'even'), (4, 'even'), (9, 'odd'), (7, 'odd'), (8, 'even'), (0, 'even')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that takes in input a and returns a new tuple with the first and last\n",
        "elements swapped (that is the first returned element must be 0, and the last one 1)"
      ],
      "metadata": {
        "id": "4UYcbT7bRXcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def swap_first_last(a):\n",
        "    if isinstance(a, tuple) and len(a) >= 2:\n",
        "        return (a[-1],) + a[1:-1] + (a[0],)\n",
        "    else:\n",
        "        print(\"Input is not a tuple or does not have at least two elements.\")\n",
        "\n",
        "# Test the function\n",
        "a =  (1,2,4,5,6,4,9,7,8,0)\n",
        "swapped_tuple = swap_first_last(a)\n",
        "print(swapped_tuple)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16_qU0WjRO89",
        "outputId": "6420d93d-e2c5-4d51-b3f4-c70acb7b1f2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, 2, 4, 5, 6, 4, 9, 7, 8, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that (checks that a contains an even number of elements), and\n",
        "returns a new tuple with element swapped as in the example:\n",
        "(1,2,4,5,6,3,9,7,8,0) ---> (0,8,7,9,3,6,5,4,2,1)"
      ],
      "metadata": {
        "id": "yU12XTgXSSaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def swap_elements(a):\n",
        "  for num in a:\n",
        "    if num%2==0:\n",
        "      return a[::-1]\n",
        "a=(1,2,4,5,6,4,9,7,8,0)\n",
        "print(swap_elements(a))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rmLY5gVSPII",
        "outputId": "b1b094c0-d303-40d4-c31d-4ff64f856287"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, 8, 7, 9, 4, 6, 5, 4, 2, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def swap_elements(a):\n",
        "    if isinstance(a, tuple) and len(a) % 2 == 0:\n",
        "        new_tuple = tuple()\n",
        "        for i in range(len(a) // 2):\n",
        "            new_tuple += (a[-(i+1)], a[i])\n",
        "        return new_tuple\n",
        "    else:\n",
        "        print(\"Input is not a tuple or does not contain an even number of elements.\")\n",
        "\n",
        "# Test the function\n",
        "a = (1, 2, 4, 5, 6, 3, 9, 7, 8, 0)\n",
        "swapped_tuple = swap_elements(a)\n",
        "print(swapped_tuple)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7U4jKxs1TT5o",
        "outputId": "5b2a6576-6aa2-49b7-c272-c142c39a14c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, 1, 8, 2, 7, 4, 9, 5, 3, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "\n",
        "def create_and_sort(n):\n",
        "    items = [randint(0, n**2) for _ in range(n)]\n",
        "    sorted_items = sorted(items)\n",
        "    return tuple(sorted_items)\n",
        "\n",
        "# Test the function\n",
        "n = 5\n",
        "sorted_tuple = create_and_sort(n)\n",
        "print(sorted_tuple)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UuqasvsTiLQ",
        "outputId": "6cc5a1d5-34dc-415d-b289-090d76613642"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 16, 18, 22, 24)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_a =['Mary','Dan',\"joe\"]\n",
        "list_b =[1,2,3,4]\n",
        "print(tuple(zip(list_a,list_b)))\n",
        "print(dict(zip(list_a,list_b)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvwpKpjhUCR4",
        "outputId": "52d35153-fb8a-4d07-a6c4-b31dc4bf1f19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(('Mary', 1), ('Dan', 2), ('joe', 3))\n",
            "{'Mary': 1, 'Dan': 2, 'joe': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict_1 = {'Mary': 1, 'Dan': 2}\n",
        "dict_2 = {'Joe': 3, 'Ada': 4}\n",
        "dict_3=dict_1.copy()\n",
        "dict_3.update(dict_2)\n",
        "print(dict_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3vrHFj4Zb6q",
        "outputId": "c200f511-5172-41ee-f2cd-aa4ab1cdf891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Mary': 1, 'Dan': 2, 'Joe': 3, 'Ada': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "phone_prefixes = {'Naples' : '081','Rome':\n",
        "'06','Bari': '080','Venice': '041'} write a function that takes in input a dict and a key, and returns True if the key is\n",
        "present and False otherwise"
      ],
      "metadata": {
        "id": "0W3LogRia2DA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_key_presence(dictionary, key):\n",
        "    if isinstance(dictionary, dict):\n",
        "        return key in dictionary\n",
        "    else:\n",
        "        print(\"Input is not a dictionary.\")\n",
        "\n",
        "# Test the function\n",
        "phone_prefixes = {'Naples': '081', 'Rome': '06', 'Bari': '080', 'Venice': '041'}\n",
        "key = 'Rome'\n",
        "print(check_key_presence(phone_prefixes, key))  # Output should be True\n",
        "\n",
        "key = 'Milan'\n",
        "print(check_key_presence(phone_prefixes, key))  # Output should be False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFe2cujbZ6gy",
        "outputId": "71965786-0484-47b3-e21c-0f49c080e54b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " write a function that takes two arguments, min and max. the function must 1) build\n",
        "a dictionary where the keys are numbers in the range [min,max], and the values are\n",
        "the square of the keys; and 2) print the created dictionary"
      ],
      "metadata": {
        "id": "MlLeXn7qbLA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_palindrome(num):\n",
        "    return str(num) == str(num)[::-1]\n",
        "\n",
        "def create_palindrome_dict(min_val, max_val):\n",
        "    palindrome_dict = {}\n",
        "    for i in range(min_val, max_val + 1):\n",
        "        palindrome_dict[i] = is_palindrome(i)\n",
        "    return palindrome_dict\n",
        "\n",
        "# Test the function\n",
        "min_val = 100\n",
        "max_val = 110\n",
        "result = create_palindrome_dict(min_val, max_val)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCBBHFXibHSL",
        "outputId": "d1394bde-bb6c-4a9d-d0f7-64cc95a4fc70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{100: False, 101: True, 102: False, 103: False, 104: False, 105: False, 106: False, 107: False, 108: False, 109: False, 110: False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that takes two arguments, min and max. the function must scan all\n",
        "integers in the range [min,max], and return a dictionary with numbers as keys, and\n",
        "as values 'True' for palindrome numbers and 'False' otherwise"
      ],
      "metadata": {
        "id": "0OC53jLOccSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_palindrome_numbers(dictionary):\n",
        "    for key, value in dictionary.items():\n",
        "        if value:  # If value is True (indicating the key is a palindrome)\n",
        "            print(f\"{key}: {value}\")\n",
        "\n",
        "# Test the function\n",
        "min_val = 100\n",
        "max_val = 110\n",
        "palindrome_dict = create_palindrome_dict(min_val, max_val)\n",
        "print_palindrome_numbers(palindrome_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgvlQhIqeFqM",
        "outputId": "87d6fe56-6a3e-4790-80ec-a5ed1f1e2d73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_palindrome_numbers(dictionary):\n",
        "    palindrome_numbers = []\n",
        "    for key, value in dictionary.items():\n",
        "        if value:  # If value is True (indicating the key is a palindrome)\n",
        "            palindrome_numbers.append(key)\n",
        "    return palindrome_numbers\n",
        "\n",
        "# Test the function\n",
        "min_val = 100\n",
        "max_val = 110\n",
        "palindrome_dict = create_palindrome_dict(min_val, max_val)\n",
        "palindrome_numbers = get_palindrome_numbers(palindrome_dict)\n",
        "print(\"Palindrome numbers:\", palindrome_numbers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXKL4P7OelON",
        "outputId": "d7b7fbdd-854b-4482-ccee-7f5b3b041741"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Palindrome numbers: [101]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Point:\n",
        "  \"\"\"has three attributes:\"\"\"\n",
        "  def __init__(self,x,y,color=\"unspecified\"):\n",
        "    self.x=x\n",
        "    self.y=y\n",
        "    self.color=color\n",
        "P1=Point(2,3)\n",
        "print(f\"P1.x:{P1.x}; P1.y:{P1.y};P1.color:{P1.color}\")\n",
        "P2=Point(3,5,'red')\n",
        "print(f\"P2.x:{P2.x};P2.y:{P2.y};P2.color:{P2.color}\")"
      ],
      "metadata": {
        "id": "jCno9eeTezp9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca850dd0-fd99-4387-9472-7dbeba549f03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P1.x:2; P1.y:3;P1.color:unspecified\n",
            "P2.x:3;P2.y:5;P2.color:red\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Point:\n",
        "\n",
        "  def __init__(self, x, y, color='unspecified'):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    self.color = color\n",
        "P1 = Point(2,3)\n",
        "print(f'P1.x: {P1.x}; P1.y: {P1.y}; P1.color: {P1.color}')\n",
        "P2 = Point(3, 5, 'red')\n",
        "print(f'P.x: {P2.x}; P.y: {P2.y}; P.color: {P2.color}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeJ1J58sBmMH",
        "outputId": "dcd976e2-a0a6-45b1-ad74-40d7a71b4b09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P1.x: 2; P1.y: 3; P1.color: unspecified\n",
            "P.x: 3; P.y: 5; P.color: red\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = 1.45\n",
        "print(f'{a:12.6f}')\n",
        "print(f'{a:12.4f}')\n",
        "print(f'{a:12.3f}')\n",
        "print(f'{a:12.2f}')\n",
        "print(f'{a:12.1f}')\n",
        "print(f'{a:12.0f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffYX_kn0Bxr2",
        "outputId": "f05aa699-2045-4139-b94d-72db7c45427d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    1.450000\n",
            "      1.4500\n",
            "       1.450\n",
            "        1.45\n",
            "         1.4\n",
            "           1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "let us consider a person counter; it is a basic device used to\n",
        "count people (in a reception, at the market, etc.). each\n",
        "person counter has its own value, and must have a method\n",
        "to get this value (let us call this get_value()), a method to\n",
        "increase such value by one (one_more()) for individuals\n",
        "and one for groups (increase_by_group(amount)). all\n",
        "such elements are instance attributes.\n",
        "- different instances should be created, e.g., a\n",
        "concertCounter and a boardingPassCounter\n",
        "- add a class variable, to keep track of all elements scored by\n",
        "all instances\n"
      ],
      "metadata": {
        "id": "m4Euv7uZEmhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PersonCounter:\n",
        "    total_elements = 0  # Class variable to keep track of all elements scored by all instances\n",
        "\n",
        "    def __init__(self):\n",
        "        self.counter = 0  # Instance attribute to store the counter value for each instance\n",
        "\n",
        "    def get_value(self):\n",
        "        return self.counter\n",
        "\n",
        "    def one_more(self):\n",
        "        self.counter += 1\n",
        "        PersonCounter.total_elements += 1\n",
        "\n",
        "    def increase_by_group(self, amount):\n",
        "        self.counter += amount\n",
        "        PersonCounter.total_elements += amount\n",
        "\n",
        "# Create instances\n",
        "concert_counter = PersonCounter()\n",
        "boarding_pass_counter = PersonCounter()\n",
        "\n",
        "# Interact with counters\n",
        "concert_counter.one_more()  # Increase counter by one for concertCounter\n",
        "concert_counter.one_more()\n",
        "boarding_pass_counter.increase_by_group(5)  # Increase counter by five for boardingPassCounter\n",
        "\n",
        "# Display counter values for each instance\n",
        "print(\"Concert Counter Value:\", concert_counter.get_value())\n",
        "print(\"Boarding Pass Counter Value:\", boarding_pass_counter.get_value())\n",
        "\n",
        "# Display total elements scored by all instances\n",
        "print(\"Total Elements Scored by All Counters:\", PersonCounter.total_elements)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-awLboXyDCie",
        "outputId": "f6d3cbc9-7939-4b8c-c43e-e32252e6bf85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Concert Counter Value: 2\n",
            "Boarding Pass Counter Value: 5\n",
            "Total Elements Scored by All Counters: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "define a class BankAccount, that must contain\n",
        "- a bank account identifier (may be built freely, but must be unique)\n",
        "- a client name, reporting the owner of the bank account\n",
        "- a balance attribute\n",
        "- a constructor to initialize the balance (may be to zero, or to an initial amount)\n",
        "- a method to deposit a sum and a method to withdraw\n",
        "- a method to close the bank account\n",
        "- a help method, to print all operations available\n",
        "- a method to print all information available for a given bank account\n",
        "- a method to transfer the available amount to another bank account"
      ],
      "metadata": {
        "id": "fIuhDGPcJBPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "\n",
        "class BankAccount:\n",
        "    def __init__(self, client_name, initial_balance=0):\n",
        "        self.account_id = uuid.uuid4()  # Generating a unique account identifier\n",
        "        self.client_name = client_name\n",
        "        self.balance = initial_balance\n",
        "\n",
        "    def deposit(self, amount):\n",
        "        if amount > 0:\n",
        "            self.balance += amount\n",
        "            print(f\"Deposited {amount} units into account {self.account_id}. New balance: {self.balance}\")\n",
        "        else:\n",
        "            print(\"Invalid deposit amount. Please enter a positive number.\")\n",
        "\n",
        "    def withdraw(self, amount):\n",
        "        if 0 < amount <= self.balance:\n",
        "            self.balance -= amount\n",
        "            print(f\"Withdrew {amount} units from account {self.account_id}. New balance: {self.balance}\")\n",
        "        else:\n",
        "            print(\"Insufficient funds or invalid withdrawal amount.\")\n",
        "\n",
        "    def close_account(self):\n",
        "        self.balance = 0\n",
        "        print(f\"Account {self.account_id} closed successfully.\")\n",
        "\n",
        "    def print_operations(self):\n",
        "        print(\"Operations available:\")\n",
        "        print(\"1. Deposit\")\n",
        "        print(\"2. Withdraw\")\n",
        "        print(\"3. Close Account\")\n",
        "        print(\"4. Transfer Amount\")\n",
        "        print(\"5. Print Account Information\")\n",
        "\n",
        "    def print_account_info(self):\n",
        "        print(f\"Account Information:\")\n",
        "        print(f\"Account ID: {self.account_id}\")\n",
        "        print(f\"Client Name: {self.client_name}\")\n",
        "        print(f\"Balance: {self.balance}\")\n",
        "\n",
        "    def transfer_amount(self, recipient_account, amount):\n",
        "        if amount <= self.balance:\n",
        "            self.balance -= amount\n",
        "            recipient_account.balance += amount\n",
        "            print(f\"Transferred {amount} units from account {self.account_id} to account {recipient_account.account_id}\")\n",
        "            print(f\"New balance for account {self.account_id}: {self.balance}\")\n",
        "            print(f\"New balance for account {recipient_account.account_id}: {recipient_account.balance}\")\n",
        "        else:\n",
        "            print(\"Insufficient funds for transfer.\")\n",
        "\n",
        "# Test the class\n",
        "client1_account = BankAccount(\"John Doe\", 1000)\n",
        "client2_account = BankAccount(\"Jane Smith\")\n",
        "\n",
        "client1_account.deposit(500)\n",
        "client1_account.withdraw(200)\n",
        "client1_account.transfer_amount(client2_account, 300)\n",
        "client2_account.print_account_info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8J-OgcHcEn7X",
        "outputId": "cf9db6d8-0636-4dab-b3ef-5f1118b20858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deposited 500 units into account c4e44fa7-00cb-4409-872d-4e477e4c2ed9. New balance: 1500\n",
            "Withdrew 200 units from account c4e44fa7-00cb-4409-872d-4e477e4c2ed9. New balance: 1300\n",
            "Transferred 300 units from account c4e44fa7-00cb-4409-872d-4e477e4c2ed9 to account fbbd6104-136e-4899-a57b-0127b41e1ee6\n",
            "New balance for account c4e44fa7-00cb-4409-872d-4e477e4c2ed9: 1000\n",
            "New balance for account fbbd6104-136e-4899-a57b-0127b41e1ee6: 300\n",
            "Account Information:\n",
            "Account ID: fbbd6104-136e-4899-a57b-0127b41e1ee6\n",
            "Client Name: Jane Smith\n",
            "Balance: 300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "\n",
        "class BankAccount:\n",
        "    def __init__(self):\n",
        "        self.account_id = uuid.uuid4()  # Generating a unique account identifier\n",
        "        self.client_name = input(\"Enter client name: \")\n",
        "        self.balance = float(input(\"Enter initial balance: \"))\n",
        "\n",
        "    def deposit(self):\n",
        "        amount = float(input(\"Enter deposit amount: \"))\n",
        "        if amount > 0:\n",
        "            self.balance += amount\n",
        "            print(f\"Deposited {amount} units into account {self.account_id}. New balance: {self.balance}\")\n",
        "        else:\n",
        "            print(\"Invalid deposit amount. Please enter a positive number.\")\n",
        "\n",
        "    def withdraw(self):\n",
        "        amount = float(input(\"Enter withdrawal amount: \"))\n",
        "        if 0 < amount <= self.balance:\n",
        "            self.balance -= amount\n",
        "            print(f\"Withdrew {amount} units from account {self.account_id}. New balance: {self.balance}\")\n",
        "        else:\n",
        "            print(\"Insufficient funds or invalid withdrawal amount.\")\n",
        "\n",
        "    def close_account(self):\n",
        "        self.balance = 0\n",
        "        print(f\"Account {self.account_id} closed successfully.\")\n",
        "\n",
        "    def print_operations(self):\n",
        "        print(\"Operations available:\")\n",
        "        print(\"1. Deposit\")\n",
        "        print(\"2. Withdraw\")\n",
        "        print(\"3. Close Account\")\n",
        "        print(\"4. Transfer Amount\")\n",
        "        print(\"5. Print Account Information\")\n",
        "\n",
        "    def print_account_info(self):\n",
        "        print(f\"Account Information:\")\n",
        "        print(f\"Account ID: {self.account_id}\")\n",
        "        print(f\"Client Name: {self.client_name}\")\n",
        "        print(f\"Balance: {self.balance}\")\n",
        "\n",
        "    def transfer_amount(self, recipient_account):\n",
        "        amount = float(input(\"Enter transfer amount: \"))\n",
        "        if amount <= self.balance:\n",
        "            self.balance -= amount\n",
        "            recipient_account.balance += amount\n",
        "            print(f\"Transferred {amount} units from account {self.account_id} to account {recipient_account.account_id}\")\n",
        "            print(f\"New balance for account {self.account_id}: {self.balance}\")\n",
        "            print(f\"New balance for account {recipient_account.account_id}: {recipient_account.balance}\")\n",
        "        else:\n",
        "            print(\"Insufficient funds for transfer.\")\n",
        "\n",
        "# Test the class\n",
        "client1_account = BankAccount()\n",
        "client2_account = BankAccount()\n",
        "\n",
        "client1_account.deposit()\n",
        "client1_account.withdraw()\n",
        "client1_account.transfer_amount(client2_account)\n",
        "client2_account.print_account_info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_lupGnkJF5i",
        "outputId": "4547f655-7a14-4742-a2d6-448a75ebfa1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter client name: anvar\n",
            "Enter initial balance: 1100\n",
            "Enter client name: anvar\n",
            "Enter initial balance: 1100\n",
            "Enter deposit amount: 500\n",
            "Deposited 500.0 units into account 7ea3fd3f-6c0e-405b-9280-88b1348d9c11. New balance: 1600.0\n",
            "Enter withdrawal amount: 100\n",
            "Withdrew 100.0 units from account 7ea3fd3f-6c0e-405b-9280-88b1348d9c11. New balance: 1500.0\n",
            "Enter transfer amount: 150\n",
            "Transferred 150.0 units from account 7ea3fd3f-6c0e-405b-9280-88b1348d9c11 to account bdc581ce-e916-46c7-b075-da6a40be0eb2\n",
            "New balance for account 7ea3fd3f-6c0e-405b-9280-88b1348d9c11: 1350.0\n",
            "New balance for account bdc581ce-e916-46c7-b075-da6a40be0eb2: 1250.0\n",
            "Account Information:\n",
            "Account ID: bdc581ce-e916-46c7-b075-da6a40be0eb2\n",
            "Client Name: anvar\n",
            "Balance: 1250.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "define a class CountVisitors (e.g., to bound the number of visitors in a\n",
        "museum); it must contain\n",
        "- a counter attribute\n",
        "- a method to increment the counter by one\n",
        "- a method to increment the counter by an arbitrary number\n",
        "- a method to set the limit of people allowed to enter\n",
        "- a method to check whether next visitor is allowed\n",
        "- a method to obtain the places left, given the number of persons already in\n",
        "- a method to undo an unwanted increment\n",
        "- a method to reset (set to 0) the counter"
      ],
      "metadata": {
        "id": "ouBvAvVvKgjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CountVisitors:\n",
        "    def __init__(self):\n",
        "        self.counter = 0\n",
        "        self.limit = None\n",
        "\n",
        "    def increment_by_one(self):\n",
        "        self.counter += 1\n",
        "\n",
        "    def increment_by_amount(self, amount):\n",
        "        self.counter += amount\n",
        "\n",
        "    def set_limit(self, limit):\n",
        "        self.limit = limit\n",
        "\n",
        "    def is_visitor_allowed(self):\n",
        "        if self.limit is None or self.counter < self.limit:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def places_left(self):\n",
        "        if self.limit is None:\n",
        "            return \"Unlimited\"\n",
        "        else:\n",
        "            return max(0, self.limit - self.counter)\n",
        "\n",
        "    def undo_increment(self):\n",
        "        self.counter -= 1\n",
        "\n",
        "    def reset_counter(self):\n",
        "        self.counter = 0\n",
        "\n",
        "# Test the class\n",
        "visitor_counter = CountVisitors()\n",
        "visitor_counter.set_limit(50)\n",
        "\n",
        "for _ in range(55):\n",
        "    if visitor_counter.is_visitor_allowed():\n",
        "        visitor_counter.increment_by_one()\n",
        "        print(\"Visitor allowed. Current count:\", visitor_counter.counter)\n",
        "    else:\n",
        "        print(\"Visitor not allowed. Limit reached.\")\n",
        "\n",
        "print(\"Places left:\", visitor_counter.places_left())\n",
        "\n",
        "visitor_counter.undo_increment()\n",
        "print(\"After undoing increment, counter:\", visitor_counter.counter)\n",
        "\n",
        "visitor_counter.reset_counter()\n",
        "print(\"After resetting counter, counter:\", visitor_counter.counter)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7rRIM0gJ1Gp",
        "outputId": "463baebe-e1b9-4e82-b653-e12913ff2bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visitor allowed. Current count: 1\n",
            "Visitor allowed. Current count: 2\n",
            "Visitor allowed. Current count: 3\n",
            "Visitor allowed. Current count: 4\n",
            "Visitor allowed. Current count: 5\n",
            "Visitor allowed. Current count: 6\n",
            "Visitor allowed. Current count: 7\n",
            "Visitor allowed. Current count: 8\n",
            "Visitor allowed. Current count: 9\n",
            "Visitor allowed. Current count: 10\n",
            "Visitor allowed. Current count: 11\n",
            "Visitor allowed. Current count: 12\n",
            "Visitor allowed. Current count: 13\n",
            "Visitor allowed. Current count: 14\n",
            "Visitor allowed. Current count: 15\n",
            "Visitor allowed. Current count: 16\n",
            "Visitor allowed. Current count: 17\n",
            "Visitor allowed. Current count: 18\n",
            "Visitor allowed. Current count: 19\n",
            "Visitor allowed. Current count: 20\n",
            "Visitor allowed. Current count: 21\n",
            "Visitor allowed. Current count: 22\n",
            "Visitor allowed. Current count: 23\n",
            "Visitor allowed. Current count: 24\n",
            "Visitor allowed. Current count: 25\n",
            "Visitor allowed. Current count: 26\n",
            "Visitor allowed. Current count: 27\n",
            "Visitor allowed. Current count: 28\n",
            "Visitor allowed. Current count: 29\n",
            "Visitor allowed. Current count: 30\n",
            "Visitor allowed. Current count: 31\n",
            "Visitor allowed. Current count: 32\n",
            "Visitor allowed. Current count: 33\n",
            "Visitor allowed. Current count: 34\n",
            "Visitor allowed. Current count: 35\n",
            "Visitor allowed. Current count: 36\n",
            "Visitor allowed. Current count: 37\n",
            "Visitor allowed. Current count: 38\n",
            "Visitor allowed. Current count: 39\n",
            "Visitor allowed. Current count: 40\n",
            "Visitor allowed. Current count: 41\n",
            "Visitor allowed. Current count: 42\n",
            "Visitor allowed. Current count: 43\n",
            "Visitor allowed. Current count: 44\n",
            "Visitor allowed. Current count: 45\n",
            "Visitor allowed. Current count: 46\n",
            "Visitor allowed. Current count: 47\n",
            "Visitor allowed. Current count: 48\n",
            "Visitor allowed. Current count: 49\n",
            "Visitor allowed. Current count: 50\n",
            "Visitor not allowed. Limit reached.\n",
            "Visitor not allowed. Limit reached.\n",
            "Visitor not allowed. Limit reached.\n",
            "Visitor not allowed. Limit reached.\n",
            "Visitor not allowed. Limit reached.\n",
            "Places left: 0\n",
            "After undoing increment, counter: 49\n",
            "After resetting counter, counter: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "refine the previous class by employing user input"
      ],
      "metadata": {
        "id": "GTK5JjE8LYqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CountVisitors:\n",
        "    def __init__(self):\n",
        "        self.counter = 0\n",
        "        self.limit = None\n",
        "\n",
        "    def increment_by_one(self):\n",
        "        self.counter += 1\n",
        "\n",
        "    def increment_by_amount(self):\n",
        "        amount = int(input(\"Enter the number of visitors to increment: \"))\n",
        "        if amount > 0:\n",
        "            self.counter += amount\n",
        "        else:\n",
        "            print(\"Invalid number of visitors. Please enter a positive number.\")\n",
        "\n",
        "    def set_limit(self):\n",
        "        self.limit = int(input(\"Enter the limit of people allowed to enter: \"))\n",
        "\n",
        "    def is_visitor_allowed(self):\n",
        "        if self.limit is None or self.counter < self.limit:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    def places_left(self):\n",
        "        if self.limit is None:\n",
        "            return \"Unlimited\"\n",
        "        else:\n",
        "            return max(0, self.limit - self.counter)\n",
        "\n",
        "    def undo_increment(self):\n",
        "        if self.counter > 0:\n",
        "            self.counter -= 1\n",
        "        else:\n",
        "            print(\"Counter is already at zero. Cannot undo further.\")\n",
        "\n",
        "    def reset_counter(self):\n",
        "        self.counter = 0\n",
        "\n",
        "# Test the class\n",
        "visitor_counter = CountVisitors()\n",
        "visitor_counter.set_limit()\n",
        "\n",
        "while True:\n",
        "    option = input(\"Select an option:\\n1. Increment by one\\n2. Increment by amount\\n3. Undo increment\\n4. Reset counter\\n5. Exit\\n\")\n",
        "\n",
        "    if option == '1':\n",
        "        if visitor_counter.is_visitor_allowed():\n",
        "            visitor_counter.increment_by_one()\n",
        "            print(\"Visitor allowed. Current count:\", visitor_counter.counter)\n",
        "        else:\n",
        "            print(\"Visitor not allowed. Limit reached.\")\n",
        "    elif option == '2':\n",
        "        visitor_counter.increment_by_amount()\n",
        "        print(\"Current count:\", visitor_counter.counter)\n",
        "    elif option == '3':\n",
        "        visitor_counter.undo_increment()\n",
        "        print(\"After undoing increment, counter:\", visitor_counter.counter)\n",
        "    elif option == '4':\n",
        "        visitor_counter.reset_counter()\n",
        "        print(\"After resetting counter, counter:\", visitor_counter.counter)\n",
        "    elif option == '5':\n",
        "        break\n",
        "    else:\n",
        "        print(\"Invalid option. Please select again.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20z7mtBqKr8S",
        "outputId": "917ce6aa-d00f-4bd0-b769-49164c2b01a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the limit of people allowed to enter: 50\n",
            "Select an option:\n",
            "1. Increment by one\n",
            "2. Increment by amount\n",
            "3. Undo increment\n",
            "4. Reset counter\n",
            "5. Exit\n",
            "1\n",
            "Visitor allowed. Current count: 1\n",
            "Select an option:\n",
            "1. Increment by one\n",
            "2. Increment by amount\n",
            "3. Undo increment\n",
            "4. Reset counter\n",
            "5. Exit\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "define a class PersonName, containing three attributes: first name, second name\n",
        "and family name\n",
        "- define a class Address, containing information on country, region, city, postal\n",
        "code, road, number\n",
        "- define a class Person containing a PersonName and an Address\n",
        "- create 5 persons, and fill them with the necessary information from the user input"
      ],
      "metadata": {
        "id": "8vLEHcbKLvjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PersonName:\n",
        "    def __init__(self, first_name, second_name, family_name):\n",
        "        self.first_name = first_name\n",
        "        self.second_name = second_name\n",
        "        self.family_name = family_name\n",
        "\n",
        "class Address:\n",
        "    def __init__(self, country, region, city, postal_code, road, number):\n",
        "        self.country = country\n",
        "        self.region = region\n",
        "        self.city = city\n",
        "        self.postal_code = postal_code\n",
        "        self.road = road\n",
        "        self.number = number\n",
        "\n",
        "class Person:\n",
        "    def __init__(self, person_name, address):\n",
        "        self.person_name = person_name\n",
        "        self.address = address\n",
        "\n",
        "# Create 5 persons and fill them with information from user input\n",
        "persons = []\n",
        "for _ in range(5):\n",
        "    print(\"Enter information for person\", _ + 1)\n",
        "    first_name = input(\"Enter first name: \")\n",
        "    second_name = input(\"Enter second name: \")\n",
        "    family_name = input(\"Enter family name: \")\n",
        "    country = input(\"Enter country: \")\n",
        "    region = input(\"Enter region: \")\n",
        "    city = input(\"Enter city: \")\n",
        "    postal_code = input(\"Enter postal code: \")\n",
        "    road = input(\"Enter road: \")\n",
        "    number = input(\"Enter number: \")\n",
        "\n",
        "    person_name = PersonName(first_name, second_name, family_name)\n",
        "    address = Address(country, region, city, postal_code, road, number)\n",
        "    person = Person(person_name, address)\n",
        "    persons.append(person)\n",
        "\n",
        "# Print information for each person\n",
        "for idx, person in enumerate(persons, start=1):\n",
        "    print(f\"\\nPerson {idx} Information:\")\n",
        "    print(\"Name:\", person.person_name.first_name, person.person_name.second_name, person.person_name.family_name)\n",
        "    print(\"Address:\", person.address.country, person.address.region, person.address.city, person.address.postal_code, person.address.road, person.address.number)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RM7_B32GLQ8q",
        "outputId": "3b22dd6b-63cf-4570-d12f-ed8230491498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter information for person 1\n",
            "Enter first name: an\n",
            "Enter second name: var\n",
            "Enter family name: so\n",
            "Enter country: uz\n",
            "Enter region: ta\n",
            "Enter city: yu\n",
            "Enter postal code: 11\n",
            "Enter road: 15\n",
            "Enter number: 11111\n",
            "Enter information for person 2\n",
            "Enter first name: sa\n",
            "Enter second name: qa\n",
            "Enter family name: ku\n",
            "Enter country: uz\n",
            "Enter region: ta\n",
            "Enter city: yu\n",
            "Enter postal code: 44\n",
            "Enter road: 90\n",
            "Enter number: 900\\\n",
            "Enter information for person 3\n",
            "Enter first name: afsd\n",
            "Enter second name: fsadfa\n",
            "Enter family name: sfasf\n",
            "Enter country: da\n",
            "Enter region: fa\n",
            "Enter city: fadf\n",
            "Enter postal code: fadsf\n",
            "Enter road: fasfd\n",
            "Enter number: gre\n",
            "Enter information for person 4\n",
            "Enter first name: rger\n",
            "Enter second name: rgre\n",
            "Enter family name: g\n",
            "Enter country: greg\n",
            "Enter region: greg\n",
            "Enter city: reqrw\n",
            "Enter postal code: rwq\n",
            "Enter road: qw\n",
            "Enter number: rwqe\n",
            "Enter information for person 5\n",
            "Enter first name: rwq\n",
            "Enter second name: rewq\n",
            "Enter family name: w\n",
            "Enter country: OJO\n",
            "Enter region: Oo\n",
            "Enter city: OJO\n",
            "Enter postal code: oj\n",
            "Enter road: ojlfe\n",
            "Enter number: ewfwfoi\n",
            "\n",
            "Person 1 Information:\n",
            "Name: an var so\n",
            "Address: uz ta yu 11 15 11111\n",
            "\n",
            "Person 2 Information:\n",
            "Name: sa qa ku\n",
            "Address: uz ta yu 44 90 900\\\n",
            "\n",
            "Person 3 Information:\n",
            "Name: afsd fsadfa sfasf\n",
            "Address: da fa fadf fadsf fasfd gre\n",
            "\n",
            "Person 4 Information:\n",
            "Name: rger rgre g\n",
            "Address: greg greg reqrw rwq qw rwqe\n",
            "\n",
            "Person 5 Information:\n",
            "Name: rwq rewq w\n",
            "Address: OJO Oo OJO oj ojlfe ewfwfoi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Shark:\n",
        "  def __init__(self,name,age):\n",
        "    self.name=name\n",
        "    self.age=age\n",
        "new_shark = Shark(\"Tammy\",5)\n",
        "print(new_shark.name)\n",
        "print(new_shark.age)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wf8ddXOL1Oy",
        "outputId": "dd1b3c60-a7f7-4099-da7d-e17538e87952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tammy\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "create another instance of Shark, named Tommy and aged 3. Print name and age.\n",
        "analyze the execution of this program through https://pythontutor.com/"
      ],
      "metadata": {
        "id": "ricSfyT-TR7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Shark:\n",
        "  def __init__(self,name,age):\n",
        "    self.name=name\n",
        "    self.age=age\n",
        "new_shark=Shark(\"Tammy\",5)\n",
        "print(new_shark.name)\n",
        "print(new_shark.age)\n",
        "another_shark = Shark(\"Tommy\",3)\n",
        "print(another_shark.name)\n",
        "print(another_shark.age)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkd9wd-dSxz0",
        "outputId": "5e42af62-2ca8-4d1b-9d9c-aea42ba74d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tammy\n",
            "5\n",
            "Tommy\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "what happens if we declare Shark as a subclass inheriting from Animal, that is\n",
        "Shark(Animal)?"
      ],
      "metadata": {
        "id": "HoMyNw56T8KV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Animal:\n",
        "    def __init__(self, species):\n",
        "        self.species = species\n",
        "\n",
        "class Shark(Animal):\n",
        "    def __init__(self, name, age):\n",
        "        super().__init__(\"Fish\")\n",
        "        self.name = name\n",
        "        self.age = age\n",
        "\n",
        "# Create instance of Shark\n",
        "new_shark = Shark(\"Tammy\", 5)\n",
        "print(new_shark.name)\n",
        "print(new_shark.age)\n",
        "print(new_shark.species)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hwjxChnTsmN",
        "outputId": "2b83206d-d2de-4683-a0b5-3ff724e155b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tammy\n",
            "5\n",
            "Fish\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "based on this class definition create (=create an instance of) some cards,\n",
        "such as Queen of Diamonds, Jack of Hearts, Ace of Spades, and then print out their\n",
        "name."
      ],
      "metadata": {
        "id": "TaybCAjKV4o6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Card:\n",
        "    \"\"\"Represents a standard playing card.\"\"\"\n",
        "    suit_names = ['Clubs', 'Diamonds', 'Hearts', 'Spades']\n",
        "    rank_names = [None, 'Ace', '2', '3', '4', '5', '6', '7',\n",
        "                  '8', '9', '10', 'Jack', 'Queen', 'King']\n",
        "\n",
        "    def __init__(self, suit=0, rank=2):\n",
        "        self.suit = suit\n",
        "        self.rank = rank\n",
        "\n",
        "    def __str__(self):\n",
        "        return '%s of %s' % (Card.rank_names[self.rank],\n",
        "                             Card.suit_names[self.suit])\n",
        "\n",
        "# Create instances of Card\n",
        "queen_of_diamonds = Card(1, 12)  # Queen of Diamonds\n",
        "jack_of_hearts = Card(2, 11)  # Jack of Hearts\n",
        "ace_of_spades = Card(3, 1)  # Ace of Spades\n",
        "\n",
        "# Print out the names of the cards\n",
        "print(queen_of_diamonds)\n",
        "print(jack_of_hearts)\n",
        "print(ace_of_spades)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f--hrDxT7G1",
        "outputId": "8a8554c8-b607-48ae-af8a-01c6a09784fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Queen of Diamonds\n",
            "Jack of Hearts\n",
            "Ace of Spades\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a program that randomly creates 10 pairs of cards (one will be the player\n",
        "card, and the other one the system card), and at each turn determines whether the\n",
        "player or the system wins (based on the aforementioned comparison rules; cards\n",
        "can be equal, in which case no winner is found).\n",
        "- the program must take note of (and print, at the end of execution) how many turns\n",
        "were won by the player, how many turns were won by the system, and how many\n",
        "ended in a draw"
      ],
      "metadata": {
        "id": "-K2-Wb_Sd0qH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class Card:\n",
        "    \"\"\"Represents a standard playing card.\"\"\"\n",
        "    suit_names = ['Clubs', 'Diamonds', 'Hearts', 'Spades']\n",
        "    rank_names = [None, 'Ace', '2', '3', '4', '5', '6', '7',\n",
        "                  '8', '9', '10', 'Jack', 'Queen', 'King']\n",
        "\n",
        "    def __init__(self, suit=0, rank=2):\n",
        "        self.suit = suit\n",
        "        self.rank = rank\n",
        "\n",
        "    def __str__(self):\n",
        "        return '%s of %s' % (Card.rank_names[self.rank],\n",
        "                             Card.suit_names[self.suit])\n",
        "\n",
        "def compare_cards(player_card, system_card):\n",
        "    if player_card.rank > system_card.rank:\n",
        "        return 'player'\n",
        "    elif player_card.rank < system_card.rank:\n",
        "        return 'system'\n",
        "    else:\n",
        "        return 'draw'\n",
        "\n",
        "def main():\n",
        "    player_wins = 0\n",
        "    system_wins = 0\n",
        "    draws = 0\n",
        "\n",
        "    for _ in range(10):\n",
        "        player_card = Card(random.randint(0, 3), random.randint(1, 13))\n",
        "        system_card = Card(random.randint(0, 3), random.randint(1, 13))\n",
        "\n",
        "        winner = compare_cards(player_card, system_card)\n",
        "        if winner == 'player':\n",
        "            player_wins += 1\n",
        "        elif winner == 'system':\n",
        "            system_wins += 1\n",
        "        else:\n",
        "            draws += 1\n",
        "\n",
        "    print(\"Player wins:\", player_wins)\n",
        "    print(\"System wins:\", system_wins)\n",
        "    print(\"Draws:\", draws)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnBx_TcJV2yu",
        "outputId": "1c6e133e-2833-414a-ccf8-5af8e83f858a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Player wins: 4\n",
            "System wins: 5\n",
            "Draws: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function to play 10 card games, and returning the final score for the system\n",
        "and the player"
      ],
      "metadata": {
        "id": "SfCN_n2heSgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class Card:\n",
        "    \"\"\"Represents a standard playing card.\"\"\"\n",
        "    suit_names = ['Clubs', 'Diamonds', 'Hearts', 'Spades']\n",
        "    rank_names = [None, 'Ace', '2', '3', '4', '5', '6', '7',\n",
        "                  '8', '9', '10', 'Jack', 'Queen', 'King']\n",
        "\n",
        "    def __init__(self, suit=0, rank=2):\n",
        "        self.suit = suit\n",
        "        self.rank = rank\n",
        "\n",
        "    def __str__(self):\n",
        "        return '%s of %s' % (Card.rank_names[self.rank],\n",
        "                             Card.suit_names[self.suit])\n",
        "\n",
        "def compare_cards(player_card, system_card):\n",
        "    if player_card.rank > system_card.rank:\n",
        "        return 'player'\n",
        "    elif player_card.rank < system_card.rank:\n",
        "        return 'system'\n",
        "    else:\n",
        "        return 'draw'\n",
        "\n",
        "def play_10_games():\n",
        "    player_wins = 0\n",
        "    system_wins = 0\n",
        "\n",
        "    for _ in range(10):\n",
        "        player_card = Card(random.randint(0, 3), random.randint(1, 13))\n",
        "        system_card = Card(random.randint(0, 3), random.randint(1, 13))\n",
        "\n",
        "        winner = compare_cards(player_card, system_card)\n",
        "        if winner == 'player':\n",
        "            player_wins += 1\n",
        "        elif winner == 'system':\n",
        "            system_wins += 1\n",
        "\n",
        "    return player_wins, system_wins\n",
        "\n",
        "# Test the function\n",
        "player_score, system_score = play_10_games()\n",
        "print(\"Player score:\", player_score)\n",
        "print(\"System score:\", system_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_v4POOFdztB",
        "outputId": "ca4d77aa-c6f5-47e3-c8f5-5e8a4ebae038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Player score: 5\n",
            "System score: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function to collect stats on how many times either the system or the player\n",
        "wins (also take note of draws), and print percentages for 10, 100, 1000 and 10k\n",
        "simulations"
      ],
      "metadata": {
        "id": "yUC68ubXeWdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class Card:\n",
        "    \"\"\"Represents a standard playing card.\"\"\"\n",
        "    suit_names = ['Clubs', 'Diamonds', 'Hearts', 'Spades']\n",
        "    rank_names = [None, 'Ace', '2', '3', '4', '5', '6', '7',\n",
        "                  '8', '9', '10', 'Jack', 'Queen', 'King']\n",
        "\n",
        "    def __init__(self, suit=0, rank=2):\n",
        "        self.suit = suit\n",
        "        self.rank = rank\n",
        "\n",
        "    def __str__(self):\n",
        "        return '%s of %s' % (Card.rank_names[self.rank],\n",
        "                             Card.suit_names[self.suit])\n",
        "\n",
        "def compare_cards(player_card, system_card):\n",
        "    if player_card.rank > system_card.rank:\n",
        "        return 'player'\n",
        "    elif player_card.rank < system_card.rank:\n",
        "        return 'system'\n",
        "    else:\n",
        "        return 'draw'\n",
        "\n",
        "def play_game():\n",
        "    player_card = Card(random.randint(0, 3), random.randint(1, 13))\n",
        "    system_card = Card(random.randint(0, 3), random.randint(1, 13))\n",
        "\n",
        "    return compare_cards(player_card, system_card)\n",
        "\n",
        "def collect_stats(simulations):\n",
        "    player_wins = 0\n",
        "    system_wins = 0\n",
        "    draws = 0\n",
        "\n",
        "    for _ in range(simulations):\n",
        "        result = play_game()\n",
        "        if result == 'player':\n",
        "            player_wins += 1\n",
        "        elif result == 'system':\n",
        "            system_wins += 1\n",
        "        else:\n",
        "            draws += 1\n",
        "\n",
        "    return player_wins, system_wins, draws\n",
        "\n",
        "def print_stats(simulations):\n",
        "    for n in simulations:\n",
        "        player_wins, system_wins, draws = collect_stats(n)\n",
        "        total_games = n\n",
        "        player_win_percent = (player_wins / total_games) * 100\n",
        "        system_win_percent = (system_wins / total_games) * 100\n",
        "        draw_percent = (draws / total_games) * 100\n",
        "\n",
        "        print(f\"For {total_games} simulations:\")\n",
        "        print(f\"Player wins: {player_win_percent:.2f}%\")\n",
        "        print(f\"System wins: {system_win_percent:.2f}%\")\n",
        "        print(f\"Draws: {draw_percent:.2f}%\")\n",
        "        print()\n",
        "\n",
        "# Test the function\n",
        "simulations = [10, 100, 1000, 10000]\n",
        "print_stats(simulations)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-08XQmUWeRj5",
        "outputId": "0bd0a154-a5d2-4d82-f7b3-faaaa2977558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For 10 simulations:\n",
            "Player wins: 50.00%\n",
            "System wins: 50.00%\n",
            "Draws: 0.00%\n",
            "\n",
            "For 100 simulations:\n",
            "Player wins: 39.00%\n",
            "System wins: 50.00%\n",
            "Draws: 11.00%\n",
            "\n",
            "For 1000 simulations:\n",
            "Player wins: 44.80%\n",
            "System wins: 46.00%\n",
            "Draws: 9.20%\n",
            "\n",
            "For 10000 simulations:\n",
            "Player wins: 47.37%\n",
            "System wins: 45.40%\n",
            "Draws: 7.23%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"La aurora.txt\") as new_file:\n",
        "  content=new_file.read()\n",
        "  print(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mg-cJfgBfj-K",
        "outputId": "f55562d5-cfc9-44b5-d625-5bf244bc114d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿La aurora\n",
            "\n",
            "\n",
            "\n",
            "1§1 La aurora de Nueva York tiene\n",
            "2§1 cuatro columnas de cieno\n",
            "3§1 y un huracán de negras palomas\n",
            "4§1 que chapotean las aguas podridas.\n",
            "5§1 La aurora de Nueva York gime\n",
            "6§1 por las inmensas escaleras\n",
            "7§1 buscando entre las aristas\n",
            "8§1 nardos de angustia dibujada.\n",
            "9§1 La aurora llega y nadie la recibe en su boca\n",
            "10§1 porque allí no hay mañana ni esperanza posible:\n",
            "11§1  A veces las monedas en enjambres furiosos\n",
            "12§1  taladran y devoran abandonados niños.\n",
            "13§1 Los primeros que salen comprenden con sus huesos\n",
            "14§1  que no habrá paraíso ni amores deshojados;\n",
            "15§1 saben que van al cieno de números y leyes,\n",
            "16§1 a los juegos sin arte, a sudores sin fruto.\n",
            "17§1 La luz es sepultada por cadenas y ruidos\n",
            "18§1 en impúdico reto de ciencia sin raíces.\n",
            "19§1 Por los barrios hay gentes que vacilan insomnes\n",
            "20§1 como recién salidas de un naufragio de sangre.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"La aurora.txt\") as new_file:\n",
        "  #content = new_file.read()\n",
        "  num_lines = 0\n",
        "  num_chars = 0\n",
        "  for line in new_file:\n",
        "    num_lines+=1\n",
        "    num_chars +=len(line)\n",
        "print(f\" The file contains overall {num_lines} lines\")\n",
        "print(f\" and {num_chars} characters\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPpECrzDgx6i",
        "outputId": "41765402-b427-4a42-881e-6b56146846bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The file contains overall 24 lines\n",
            " and 867 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "splitting strings"
      ],
      "metadata": {
        "id": "eC300N2pi5XC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_str = \"When I find myself in times of trouble\"\n",
        "tokens = my_str.split() #the split() method splits a string into a list\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ4YlieehpjS",
        "outputId": "a48443ef-fb8b-4c9f-a93d-5064addfe77b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['When', 'I', 'find', 'myself', 'in', 'times', 'of', 'trouble']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_str = \"a simple string\"\n",
        "my_tokens = my_str.split(\" \")\n",
        "print(f\"{my_tokens}\")\n",
        "my_str = \"another#simple#string\"\n",
        "my_tokens=my_str.split(\"#\",2)\n",
        "print(f\"{my_tokens}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHpoi6l9jA-T",
        "outputId": "36036ff6-9f15-40eb-9965-5f0fb989e205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'simple', 'string']\n",
            "['another', 'simple', 'string']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a Python program that reads all integer numbers in the file numbers.txt,\n",
        "and for each items prints whether it is even or odd"
      ],
      "metadata": {
        "id": "84KlsBCdn3ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"numbers.txt\") as new_file:\n",
        "  for num in new_file:\n",
        "    num=int(num)\n",
        "    if num%2==0:\n",
        "      print(f\"{num} is even\")\n",
        "    else:\n",
        "      print(f\"{num} is odd\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCUpg6jHjfdq",
        "outputId": "4ce01eb3-eb77-49af-d382-5d95b80d03f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12 is even\n",
            "14 is even\n",
            "16 is even\n",
            "20 is even\n",
            "17 is odd\n",
            "312 is even\n",
            "123 is odd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function check_line_by_line(src_str) that reads the file\n",
        "programming_languages.txt line by line, and counts how many times the\n",
        "string \"prog\" is found herein. hint: use the count() method from the class\n",
        "string"
      ],
      "metadata": {
        "id": "wIdAVf7XpPrt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"La aurora.txt\") as new_file:\n",
        "  counts = 0\n",
        "  for line in new_file:\n",
        "    if 'a' in line:\n",
        "      counts+=1\n",
        "print(counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWR-KS_xoib9",
        "outputId": "317e3f4d-e8bb-4885-caf3-4364a0413b44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_line_by_line(src_str):\n",
        "    count = 0\n",
        "    # Open the file for reading\n",
        "    with open(src_str, 'r') as file:\n",
        "        # Read each line from the file\n",
        "        for line in file:\n",
        "            # Count the occurrences of \"prog\" in the line\n",
        "            count += line.count(\"prog\")\n",
        "    return count\n",
        "\n",
        "# Test the function\n",
        "result = check_line_by_line(\"La aurora.txt\")\n",
        "print(\"Number of occurrences of 'prog':\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIRroUNgqDPO",
        "outputId": "a898dd20-d757-48f6-e84d-9c467a524576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of occurrences of 'prog': 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function check_whole_string(src_str) that reads the file\n",
        "programming_languages.txt as a single string, count how many times the\n",
        "string \"prog\" is found herein, and write another function double_check()\n",
        "(choose the arguments as you prefer) to verify that the above functions return\n",
        "the same value: double_check() must return True if both functions return the\n",
        "same value, False otherwise"
      ],
      "metadata": {
        "id": "hPOHRwecqXOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_whole_string(src_str):\n",
        "  count = 0\n",
        "  with open(src_str,'r') as new_file:\n",
        "    for line in new_file:\n",
        "      count +=line.count(\"a\")\n",
        "  return count\n",
        "result = check_whole_string(\"La aurora.txt\")\n",
        "print(\"Number of occurreneces of 'a' \",result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iMRWrhiqOv-",
        "outputId": "5e522853-219c-43fd-f10a-ab4cc68c4ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of occurreneces of 'a'  88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_whole_string(src_str):\n",
        "    # Open the file and read its contents as a single string\n",
        "    with open(src_str, 'r') as file:\n",
        "        content = file.read()\n",
        "\n",
        "    # Count the occurrences of \"prog\" in the content\n",
        "    count = content.count(\"prog\")\n",
        "    return count\n",
        "\n",
        "def double_check(src_str):\n",
        "    # Call both functions and compare their results\n",
        "    count_line_by_line = check_line_by_line(src_str)\n",
        "    count_whole_string = check_whole_string(src_str)\n",
        "\n",
        "    # Return True if both counts are the same, False otherwise\n",
        "    return count_line_by_line == count_whole_string\n",
        "\n",
        "# Test the double_check function\n",
        "result = double_check(\"La aurora.txt\")\n",
        "print(\"Double check result:\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_e6pnYqrykO",
        "outputId": "f8fd4ecd-dddd-4e08-f133-38904c10c371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Double check result: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function to remove punctuation from a string. hint: punctuation chars\n",
        "may be listed through the constant string.punctuation, (import string\n",
        "needed)\n"
      ],
      "metadata": {
        "id": "oWVnNV0cwcNJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "def remove_punctuation(src_str):\n",
        "  punctuations = string.punctuation\n",
        "  removed_string=\"\"\n",
        "  for char in src_str:\n",
        "    print(char)\n",
        "    if char not in punctuations:\n",
        "      removed_string +=char\n",
        "  return removed_string\n",
        "src_str = \"anvar @#?nigga/heyo\"\n",
        "result = remove_punctuation(src_str)\n",
        "print(result)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__jidZdKsMGG",
        "outputId": "06097ec8-bfec-41ec-af35-afc3a1d37856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a\n",
            "n\n",
            "v\n",
            "a\n",
            "r\n",
            " \n",
            "@\n",
            "#\n",
            "?\n",
            "n\n",
            "i\n",
            "g\n",
            "g\n",
            "a\n",
            "/\n",
            "h\n",
            "e\n",
            "y\n",
            "o\n",
            "anvar niggaheyo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuation(src_str):\n",
        "    punctuations = string.punctuation\n",
        "    removed_string = \"\"\n",
        "    for char in src_str:\n",
        "        if char not in punctuations:\n",
        "            removed_string += char\n",
        "    return removed_string\n",
        "\n",
        "src_str = \"anvar@#?nigga/heyo\"\n",
        "result = remove_punctuation(src_str)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlmJjhPFxZrI",
        "outputId": "502b1db1-ba56-49f2-a12a-c064433c631e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anvarniggaheyo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function to read the file programming_languages.txt and return a\n",
        "dictionary for all words containing the word count for each one, such as, e.g.:\n",
        "{'and': 29, 'to': 25, 'programming': 23, 'a': 22, ...} (hint:\n",
        "explore and use Counter from the collections library, which takes a list with\n",
        "repeated items and returns a dictionary with the items count)"
      ],
      "metadata": {
        "id": "0pgWIk51yp9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def word_count(file_path):\n",
        "    # Open the file and read its contents\n",
        "    with open(file_path, 'r') as file:\n",
        "        content = file.read()\n",
        "        print(content)\n",
        "\n",
        "    # Split the content into words and count the occurrences of each word\n",
        "    words = content.split()\n",
        "    print(words)\n",
        "    word_counts = Counter(words)\n",
        "\n",
        "    return word_counts\n",
        "\n",
        "# Test the function\n",
        "file_path = \"La aurora.txt\"\n",
        "word_counts = word_count(file_path)\n",
        "print(word_counts)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "it7zb211ypa-",
        "outputId": "57e59dae-4cd6-47bf-ad2e-a1e4233bd1ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿La aurora\n",
            "\n",
            "\n",
            "\n",
            "1§1 La aurora de Nueva York tiene\n",
            "2§1 cuatro columnas de cieno\n",
            "3§1 y un huracán de negras palomas\n",
            "4§1 que chapotean las aguas podridas.\n",
            "5§1 La aurora de Nueva York gime\n",
            "6§1 por las inmensas escaleras\n",
            "7§1 buscando entre las aristas\n",
            "8§1 nardos de angustia dibujada.\n",
            "9§1 La aurora llega y nadie la recibe en su boca\n",
            "10§1 porque allí no hay mañana ni esperanza posible:\n",
            "11§1  A veces las monedas en enjambres furiosos\n",
            "12§1  taladran y devoran abandonados niños.\n",
            "13§1 Los primeros que salen comprenden con sus huesos\n",
            "14§1  que no habrá paraíso ni amores deshojados;\n",
            "15§1 saben que van al cieno de números y leyes,\n",
            "16§1 a los juegos sin arte, a sudores sin fruto.\n",
            "17§1 La luz es sepultada por cadenas y ruidos\n",
            "18§1 en impúdico reto de ciencia sin raíces.\n",
            "19§1 Por los barrios hay gentes que vacilan insomnes\n",
            "20§1 como recién salidas de un naufragio de sangre.\n",
            "['\\ufeffLa', 'aurora', '1§1', 'La', 'aurora', 'de', 'Nueva', 'York', 'tiene', '2§1', 'cuatro', 'columnas', 'de', 'cieno', '3§1', 'y', 'un', 'huracán', 'de', 'negras', 'palomas', '4§1', 'que', 'chapotean', 'las', 'aguas', 'podridas.', '5§1', 'La', 'aurora', 'de', 'Nueva', 'York', 'gime', '6§1', 'por', 'las', 'inmensas', 'escaleras', '7§1', 'buscando', 'entre', 'las', 'aristas', '8§1', 'nardos', 'de', 'angustia', 'dibujada.', '9§1', 'La', 'aurora', 'llega', 'y', 'nadie', 'la', 'recibe', 'en', 'su', 'boca', '10§1', 'porque', 'allí', 'no', 'hay', 'mañana', 'ni', 'esperanza', 'posible:', '11§1', 'A', 'veces', 'las', 'monedas', 'en', 'enjambres', 'furiosos', '12§1', 'taladran', 'y', 'devoran', 'abandonados', 'niños.', '13§1', 'Los', 'primeros', 'que', 'salen', 'comprenden', 'con', 'sus', 'huesos', '14§1', 'que', 'no', 'habrá', 'paraíso', 'ni', 'amores', 'deshojados;', '15§1', 'saben', 'que', 'van', 'al', 'cieno', 'de', 'números', 'y', 'leyes,', '16§1', 'a', 'los', 'juegos', 'sin', 'arte,', 'a', 'sudores', 'sin', 'fruto.', '17§1', 'La', 'luz', 'es', 'sepultada', 'por', 'cadenas', 'y', 'ruidos', '18§1', 'en', 'impúdico', 'reto', 'de', 'ciencia', 'sin', 'raíces.', '19§1', 'Por', 'los', 'barrios', 'hay', 'gentes', 'que', 'vacilan', 'insomnes', '20§1', 'como', 'recién', 'salidas', 'de', 'un', 'naufragio', 'de', 'sangre.']\n",
            "Counter({'de': 9, 'y': 5, 'que': 5, 'aurora': 4, 'La': 4, 'las': 4, 'en': 3, 'sin': 3, 'Nueva': 2, 'York': 2, 'cieno': 2, 'un': 2, 'por': 2, 'no': 2, 'hay': 2, 'ni': 2, 'a': 2, 'los': 2, '\\ufeffLa': 1, '1§1': 1, 'tiene': 1, '2§1': 1, 'cuatro': 1, 'columnas': 1, '3§1': 1, 'huracán': 1, 'negras': 1, 'palomas': 1, '4§1': 1, 'chapotean': 1, 'aguas': 1, 'podridas.': 1, '5§1': 1, 'gime': 1, '6§1': 1, 'inmensas': 1, 'escaleras': 1, '7§1': 1, 'buscando': 1, 'entre': 1, 'aristas': 1, '8§1': 1, 'nardos': 1, 'angustia': 1, 'dibujada.': 1, '9§1': 1, 'llega': 1, 'nadie': 1, 'la': 1, 'recibe': 1, 'su': 1, 'boca': 1, '10§1': 1, 'porque': 1, 'allí': 1, 'mañana': 1, 'esperanza': 1, 'posible:': 1, '11§1': 1, 'A': 1, 'veces': 1, 'monedas': 1, 'enjambres': 1, 'furiosos': 1, '12§1': 1, 'taladran': 1, 'devoran': 1, 'abandonados': 1, 'niños.': 1, '13§1': 1, 'Los': 1, 'primeros': 1, 'salen': 1, 'comprenden': 1, 'con': 1, 'sus': 1, 'huesos': 1, '14§1': 1, 'habrá': 1, 'paraíso': 1, 'amores': 1, 'deshojados;': 1, '15§1': 1, 'saben': 1, 'van': 1, 'al': 1, 'números': 1, 'leyes,': 1, '16§1': 1, 'juegos': 1, 'arte,': 1, 'sudores': 1, 'fruto.': 1, '17§1': 1, 'luz': 1, 'es': 1, 'sepultada': 1, 'cadenas': 1, 'ruidos': 1, '18§1': 1, 'impúdico': 1, 'reto': 1, 'ciencia': 1, 'raíces.': 1, '19§1': 1, 'Por': 1, 'barrios': 1, 'gentes': 1, 'vacilan': 1, 'insomnes': 1, '20§1': 1, 'como': 1, 'recién': 1, 'salidas': 1, 'naufragio': 1, 'sangre.': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "refine the solution to ex 5 by filtering stopwords that are listed in the file\n",
        "stopwords_list.txt; the revised function should return a dictionary of terms\n",
        "in the programming_languages.txt file, but excluding tokens listed in the\n",
        "stopwords file. variant: add punctuation cleaning before the stopwords filtering"
      ],
      "metadata": {
        "id": "B32ZkP1J0x4f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import string\n",
        "\n",
        "def load_stopwords(stopwords_file):\n",
        "    with open(stopwords_file, 'r') as file:\n",
        "        stopwords = set(file.read().split())\n",
        "    return stopwords\n",
        "\n",
        "def clean_punctuation(text):\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    return text.translate(translator)\n",
        "\n",
        "def word_count_filtered(programming_languages_file, stopwords_file):\n",
        "    stopwords = load_stopwords(stopwords_file)\n",
        "\n",
        "    # Open and read the content of the programming languages file\n",
        "    with open(programming_languages_file, 'r') as file:\n",
        "        content = file.read()\n",
        "\n",
        "    # Clean punctuation from the content\n",
        "    content = clean_punctuation(content)\n",
        "\n",
        "    # Split the content into words\n",
        "    words = content.split()\n",
        "\n",
        "    # Filter out stopwords\n",
        "    words = [word for word in words if word.lower() not in stopwords]\n",
        "\n",
        "    # Count the occurrences of each word\n",
        "    word_counts = Counter(words)\n",
        "\n",
        "    return word_counts\n",
        "\n",
        "# Test the function\n",
        "programming_languages_file = \"programming_languages.txt\"\n",
        "stopwords_file = \"stopwords_list.txt\"\n",
        "word_counts_filtered = word_count_filtered(programming_languages_file, stopwords_file)\n",
        "print(word_counts_filtered)\n"
      ],
      "metadata": {
        "id": "Y6N73LM8yNBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "consider the file matrix.txt. it contains a matrix of integers. write a\n",
        "function row_sum, returning a list containing the sum for each row in the matrix,\n",
        "and a function mat_min, returning the lowest value contained in the matrix."
      ],
      "metadata": {
        "id": "xYu34OSe2FEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def row_sum(matrix_file):\n",
        "    # Read the matrix from the file\n",
        "    with open(matrix_file, 'r') as file:\n",
        "        matrix = [[int(num) for num in line.split()] for line in file]\n",
        "\n",
        "    # Calculate the sum for each row\n",
        "    row_sums = [sum(row) for row in matrix]\n",
        "\n",
        "    return row_sums\n",
        "\n",
        "def mat_min(matrix_file):\n",
        "    # Read the matrix from the file\n",
        "    with open(matrix_file, 'r') as file:\n",
        "        matrix = [[int(num) for num in line.split()] for line in file]\n",
        "\n",
        "    # Flatten the matrix to find the minimum value\n",
        "    flat_matrix = [num for row in matrix for num in row]\n",
        "    min_value = min(flat_matrix)\n",
        "\n",
        "    return min_value\n",
        "\n",
        "# Test the functions\n",
        "matrix_file = \"matrix.txt\"\n",
        "print(\"Row sums:\", row_sum(matrix_file))\n",
        "print(\"Minimum value in the matrix:\", mat_min(matrix_file))\n"
      ],
      "metadata": {
        "id": "gxuueppy2GuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_str = \" my_string\\n\"\n",
        "print(my_str.strip())\n",
        "my_str = \" qwertyui; \\n\"\n",
        "print(my_str.strip(\";\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZY5iBze79xju",
        "outputId": "8d61b22d-c19f-4866-8c65-f4b237abf99e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "my_string\n",
            " qwertyui; \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('La aurora.txt','w') as my_file:\n",
        "  my_file.write(\"File content is written;)\\n\")\n",
        "  my_file.write(\"let us add another line\")\n",
        "  print(my_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2RdSQng95Mc",
        "outputId": "d24b296a-dfc0-4515-f7a2-94df61deb4de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_io.TextIOWrapper name='La aurora.txt' mode='w' encoding='UTF-8'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('La aurora.txt','a') as my_file:\n",
        "  my_file.write(\"File content is written;)\\n\")\n",
        "  my_file.write(\"let us add another line\")\n",
        "  print(my_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsKsfutV-YHF",
        "outputId": "9e3f9c7d-0e30-4cef-a545-07cc00154cd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_io.TextIOWrapper name='La aurora.txt' mode='a' encoding='UTF-8'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that takes in input the file name of the stopwords, a string, and\n",
        "writes to a new file the list of terms contained in the input string after having\n",
        "filtered out stopwords. in this case. ANY REUSE of previous code is warmly\n",
        "encouraged...\n",
        "a. modify the code, and write another function to print to file the dictionary of\n",
        "filtered terms"
      ],
      "metadata": {
        "id": "o_Khq2lI-2m5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_terms_and_write(stopwords_file, input_string, output_file):\n",
        "    # Load stopwords\n",
        "    stopwords = load_stopwords(stopwords_file)\n",
        "\n",
        "    # Clean punctuation from the input string\n",
        "    input_string = clean_punctuation(input_string)\n",
        "\n",
        "    # Split the input string into terms\n",
        "    terms = input_string.split()\n",
        "\n",
        "    # Filter out stopwords\n",
        "    filtered_terms = [term for term in terms if term.lower() not in stopwords]\n",
        "\n",
        "    # Write filtered terms to the output file\n",
        "    with open(output_file, 'w') as file:\n",
        "        file.write('\\n'.join(filtered_terms))\n",
        "\n",
        "def print_filtered_terms_to_file(stopwords_file, input_string, output_file):\n",
        "    # Load stopwords\n",
        "    stopwords = load_stopwords(stopwords_file)\n",
        "\n",
        "    # Clean punctuation from the input string\n",
        "    input_string = clean_punctuation(input_string)\n",
        "\n",
        "    # Split the input string into terms\n",
        "    terms = input_string.split()\n",
        "\n",
        "    # Filter out stopwords and count occurrences of each term\n",
        "    filtered_terms = {term: terms.count(term) for term in terms if term.lower() not in stopwords}\n",
        "\n",
        "    # Write filtered terms and their counts to the output file\n",
        "    with open(output_file, 'w') as file:\n",
        "        for term, count in filtered_terms.items():\n",
        "            file.write(f\"{term}: {count}\\n\")\n",
        "\n",
        "# Test the functions\n",
        "stopwords_file = \"stopwords_list.txt\"\n",
        "input_string = \"This is a sample input string containing some stopwords such as and, to, the, is, in\"\n",
        "output_file = \"filtered_terms.txt\"\n",
        "\n",
        "# Test the first function\n",
        "filter_terms_and_write(stopwords_file, input_string, output_file)\n",
        "\n",
        "# Test the second function\n",
        "print_filtered_terms_to_file(stopwords_file, input_string, \"filtered_terms_with_counts.txt\")\n"
      ],
      "metadata": {
        "id": "nMCcN7vL-jBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def get_stopwds(stopwds_fname):\n",
        "  stopwords_list = []\n",
        "  with open(stopwds_fname) as in_file:\n",
        "    for line in in_file:\n",
        "      stopwords_list.append(line)\n",
        "  return stopwords_list\n",
        "\n",
        "def get_stopwds_2(stopwds_fname):\n",
        "  with open(stopwds_fname) as in_file:\n",
        "    stopwords = in_file.read()\n",
        "  return stopwords.split()\n",
        "\n",
        "  # return list of stopwords\n",
        "\n",
        "def remove_stopwds(stopwds_fname, in_string):\n",
        "  # get stopwords list\n",
        "  stopwords = get_stopwds_2(stopwds_fname)\n",
        "  # take each element in in_string (split it!!!)\n",
        "  tokens = in_string.split()\n",
        "  # if it is not a stopword, add it to the final_string\n",
        "  return [el for el in tokens if el.lower() not in stopwords]\n",
        "\n",
        "\n",
        "\n",
        "def print_all(f_name):\n",
        "  lines = []\n",
        "  with open(f_name) as in_file:\n",
        "    for line in in_file:\n",
        "      lines.append(line)\n",
        "  print(lines)\n",
        "\n",
        "def print_filtered(f_name):\n",
        "  lines = []\n",
        "  with open(f_name) as in_file:\n",
        "    for line in in_file:\n",
        "      lines.append(remove_stopwds('stopwords_list.txt', line))\n",
        "  print(lines)\n",
        "\n",
        "def print_filtered_dict(f_name):\n",
        "  lines = []\n",
        "  with open(f_name) as in_file:\n",
        "    for line in in_file:\n",
        "      filtered_tokens = remove_stopwds('stopwords_list.txt', line)\n",
        "      for token in filtered_tokens:\n",
        "        lines.append(token)\n",
        "  return Counter(lines)\n",
        "\n",
        "\n",
        "print_all('programming_languages.txt')\n",
        "print_filtered('programming_languages.txt')\n",
        "print(print_filtered_dict('programming_languages.txt'))"
      ],
      "metadata": {
        "id": "5Bfyd_Py_x0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_terms_and_write(stopwords_file, input_string, output_file):\n",
        "    # Load stopwords\n",
        "    with open(stopwords_file, 'r') as file:\n",
        "        stopwords = set(file.read().split())\n",
        "\n",
        "    # Clean punctuation from the input string\n",
        "    input_string = ''.join([char for char in input_string if char.isalnum() or char.isspace()])\n",
        "\n",
        "    # Split the input string into terms\n",
        "    terms = input_string.split()\n",
        "\n",
        "    # Filter out stopwords\n",
        "    filtered_terms = [term for term in terms if term.lower() not in stopwords]\n",
        "\n",
        "    # Write filtered terms to the output file\n",
        "    with open(output_file, 'w') as file:\n",
        "        for term in filtered_terms:\n",
        "            file.write(term + '\\n')\n",
        "\n",
        "# Test the function\n",
        "stopwords_file = \"stopwords.txt\"\n",
        "input_string = \"This is a sample input string containing some stopwords such as and, to, the, is, in\"\n",
        "output_file = \"filtered_terms.txt\"\n",
        "\n",
        "print(filter_terms_and_write(stopwords_file, input_string, output_file))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg5MpEsCAuch",
        "outputId": "bd7f5e17-6d6d-4e33-8a30-e81506cd3783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function to process the file 'organizations-1000.csv': it must read rows\n",
        "herein, select the rows associated to organizations founded before 2000 and\n",
        "print the output on a new file, 'organizations-filtered-1000.csv',"
      ],
      "metadata": {
        "id": "7OHenNWVJyAX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from csv import reader\n",
        "from csv import writer\n",
        "\n",
        "def filter_on_foundation_year():\n",
        "  in_file = open(\"organizations-1000.csv\")\n",
        "  out_file = open(\"organizations-1000-filtered.csv\", \"w\")\n",
        "  dd_reader = reader(in_file)\n",
        "  dd_writer = writer(out_file)\n",
        "  # Index,Organization Id, Name, Website, Country, Description, Founded, Industry, Number of employees\n",
        "  next(dd_reader)\n",
        "\n",
        "  for row in dd_reader:\n",
        "    if int(row[6]) < 2000:\n",
        "      print(f'{row[3]}; {row[4]}; {row[5]}; {row[6]}')\n",
        "      dd_writer.writerow([row[3], row[4], row[5], row[6]])\n",
        "  in_file.close()\n",
        "  out_file.close()\n",
        "\n",
        "filter_on_foundation_year()"
      ],
      "metadata": {
        "id": "IDwel75uIqOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "modify the previous function, by adding another argument, country (to select\n",
        "organization from that country), and make the year parametric (so that the\n",
        "foundation year is also an argument to the function)"
      ],
      "metadata": {
        "id": "5L7U8FTxNeK8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function invoking filter_data() to count how many records it\n",
        "returns. modify filter_data() so that it returns a list of lists of strings"
      ],
      "metadata": {
        "id": "SxrLL4YXSB_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from csv import reader\n",
        "from csv import writer\n",
        "\n",
        "def filter_data():\n",
        "    result = []\n",
        "    with open(\"FinalData.csv\") as in_file:\n",
        "        dd_reader = reader(in_file)\n",
        "        next(dd_reader)  # Skip header\n",
        "        for row in dd_reader:\n",
        "            if int(row[1]) < 2000:\n",
        "                result.append([row[3], row[4], row[5], row[6]])  # Append row as list of strings\n",
        "    return result\n",
        "\n",
        "def count_records():\n",
        "    filtered_data = filter_data()\n",
        "    return len(filtered_data)\n",
        "\n",
        "# Test the count_records function\n",
        "print(\"Number of records:\", count_records())"
      ],
      "metadata": {
        "id": "4ukNCtGWSF4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function get_avg(file_name) that reads a file containing two\n",
        "columns of integer numbers,; the function computes and returns the average of\n",
        "each column"
      ],
      "metadata": {
        "id": "3qpiydCrC_J2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_avg(file_name):\n",
        "  with open(file_name,'r') as new_file:\n",
        "    col1_sum=0\n",
        "    col2_sum=0\n",
        "    count=0\n",
        "    for line in new_file:\n",
        "      col1,col2 = map(int,line.split())\n",
        "      col1_sum+=col1\n",
        "      col2_sum+=col2\n",
        "      count+=1\n",
        "    average_col1 = col1_sum/count\n",
        "    average_col2=col2_cum/count\n",
        "    return average_col1,average_col2\n",
        "file_name = 'data.txt'\n",
        "average_col1,average_col2=get_avg(file_name)\n",
        "print(average_col1)\n",
        "print(average_col2)"
      ],
      "metadata": {
        "id": "5fAzZOEADAoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that asks the user a file name: the function must open the file,\n",
        "and print the number of characters, words and lines in that file"
      ],
      "metadata": {
        "id": "smrfqKOgEovK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def number_of_characters():\n",
        "  file_name = input(\"Enter a file name>>> \")\n",
        "  try:\n",
        "    with open(file_name,'r') as new_file:\n",
        "      content = new_file.read()\n",
        "      words = content.split()\n",
        "      num_characters = len(content)\n",
        "      num_words = len(words)\n",
        "      num_lines = content.count(\"\\n\")+1\n",
        "      print(num_characters)\n",
        "      print(num_words)\n",
        "      print(num_lines)\n",
        "    except FileNotFoundError:\n",
        "      print(\"File not found\")\n",
        "number_of_characters()\n",
        "\n"
      ],
      "metadata": {
        "id": "ZpnJ_J6GEqVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def file_stats():\n",
        "    # Prompt the user for a file name\n",
        "    file_name = input(\"Enter the file name: \")\n",
        "\n",
        "    try:\n",
        "        # Open the file\n",
        "        with open(file_name, 'r') as file:\n",
        "            # Read the file contents\n",
        "            content = file.read()\n",
        "\n",
        "            # Count the number of characters\n",
        "            num_chars = len(content)\n",
        "\n",
        "            # Count the number of words\n",
        "            num_words = len(content.split())\n",
        "\n",
        "            # Count the number of lines\n",
        "            num_lines = content.count('\\n') + 1\n",
        "\n",
        "            # Print the statistics\n",
        "            print(f\"Number of characters: {num_chars}\")\n",
        "            print(f\"Number of words: {num_words}\")\n",
        "            print(f\"Number of lines: {num_lines}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found. Please enter a valid file name.\")\n",
        "\n",
        "# Test the function\n",
        "file_stats()\n"
      ],
      "metadata": {
        "id": "vR85Vc6DI8Gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#file does not exist\n",
        "f_name = \"ksfdasfsdfa.txt\"\n",
        "try:\n",
        "  with open(f_name) as new_file:\n",
        "    contents = new_file.read()\n",
        "    print(contents)\n",
        "except IOError:\n",
        "  print(\"error: file not found... \")\n",
        "  print(\"but our program is still running:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhR4qoobJilm",
        "outputId": "6301ffb8-a5af-4599-e967-c5369685d5d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error: file not found... \n",
            "but our program is still running:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_even(int_num):\n",
        "  assert (int_num%2==0), \"this value had to be even\"\n",
        "  print(\"input was even>>> \")\n",
        "try:\n",
        "  check_even(5)\n",
        "except AssertionError:\n",
        "  print(f\"computation carries on even if the assertion failed\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3z8yLuxKH6J",
        "outputId": "eaeace45-2911-405d-f194-58d839fb3a2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "computation carries on even if the assertion failed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # 1. Using a Variable Without Assignment\n",
        "    print(undefined_variable)\n",
        "\n",
        "except NameError:\n",
        "    print(\"Variable is not defined!\")\n",
        "\n",
        "try:\n",
        "    # 2. Dividing by Zero\n",
        "    result = 10 / 0\n",
        "\n",
        "except ZeroDivisionError:\n",
        "    print(\"Cannot divide by zero!\")\n",
        "\n",
        "try:\n",
        "    # 3. Accessing a Non-existent Index in a List\n",
        "    my_list = [1, 2, 3]\n",
        "    print(my_list[10])\n",
        "\n",
        "except IndexError:\n",
        "    print(\"Index out of range!\")\n",
        "\n",
        "try:\n",
        "    # 4. Importing a Non-existent Library\n",
        "    import non_existent_library\n",
        "\n",
        "except ImportError:\n",
        "    print(\"Library does not exist!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LhbEHgELMLg",
        "outputId": "fef5c2b1-5b8e-4dd2-99e1-d3a7a3d9ba85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable is not defined!\n",
            "Cannot divide by zero!\n",
            "Index out of range!\n",
            "Library does not exist!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "define a function that computes the square root of a given\n",
        "number (parameter to the function); add a text to verify that this\n",
        "argument is positive (otherwise cannot compute this function),\n",
        "and if it is not, then raise a ValueError exception"
      ],
      "metadata": {
        "id": "oV0Nx9tjNkIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def square_root_number(number):\n",
        "  if number<=0:\n",
        "    raise ValueError(f\"number should not be less than or equal to 0\")\n",
        "  else:\n",
        "    return number**0.5\n",
        "square_root_number(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9WisPtuMvM6",
        "outputId": "1464bcba-095a-4882-f933-ad75af8e64bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_square_root(number):\n",
        "    if number < 0:\n",
        "        raise ValueError(\"Cannot compute square root of a negative number.\")\n",
        "    else:\n",
        "        return number ** 0.5\n",
        "\n",
        "# Test the function\n",
        "try:\n",
        "    number = float(input(\"Enter a positive number: \"))\n",
        "    result = compute_square_root(number)\n",
        "    print(f\"The square root of {number} is {result:.2f}\")\n",
        "except ValueError as ve:\n",
        "    print(ve)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jJMUylnOkw5",
        "outputId": "03c73ae8-bb0c-441a-f856-342a5f7ab33f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a positive number: 15\n",
            "The square root of 15.0 is 3.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download()\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"averaged_perceptron_tagger\")\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "example_string = \"IT was 2 p.m. on the afternoon of May 7, 1915. The Lusitania had been struck and was sinking rapidly, while the boats were being launched with all possible speed. The women and children were being lined up awaiting their turn. Some still clung desperately to husbands and fathers. One girl stood alone, slightly apart from the rest. She was quite young, not more than eighteen. She did not seem afraid, and her grave, steadfast eyes looked straight ahead.\"\n",
        "sent_tokenize(example_string)"
      ],
      "metadata": {
        "id": "U5hXuFgRPgmT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbb2d598-2f1b-4892-d4bb-2c1fc2b4bc3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> l\n",
            "Packages:\n",
            "  [ ] abc................. Australian Broadcasting Commission 2006\n",
            "  [ ] alpino.............. Alpino Dutch Treebank\n",
            "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
            "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
            "  [ ] basque_grammars..... Grammars for Basque\n",
            "  [ ] bcp47............... BCP-47 Language Tags\n",
            "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
            "                           Extraction Systems in Biology)\n",
            "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
            "  [ ] book_grammars....... Grammars from NLTK Book\n",
            "  [ ] brown............... Brown Corpus\n",
            "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
            "  [ ] cess_cat............ CESS-CAT Treebank\n",
            "  [ ] cess_esp............ CESS-ESP Treebank\n",
            "  [ ] chat80.............. Chat-80 Data Files\n",
            "  [ ] city_database....... City Database\n",
            "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
            "  [ ] comparative_sentences Comparative Sentence Dataset\n",
            "  [ ] comtrans............ ComTrans Corpus Sample\n",
            "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
            "Hit Enter to continue: \n",
            "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
            "  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n",
            "                           and Basque Subset)\n",
            "  [ ] crubadan............ Crubadan Corpus\n",
            "  [ ] dependency_treebank. Dependency Parsed Treebank\n",
            "  [ ] dolch............... Dolch Word List\n",
            "  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n",
            "                           Corpus\n",
            "  [ ] extended_omw........ Extended Open Multilingual WordNet\n",
            "  [ ] floresta............ Portuguese Treebank\n",
            "  [ ] framenet_v15........ FrameNet 1.5\n",
            "  [ ] framenet_v17........ FrameNet 1.7\n",
            "  [ ] gazetteers.......... Gazeteer Lists\n",
            "  [ ] genesis............. Genesis Corpus\n",
            "  [ ] gutenberg........... Project Gutenberg Selections\n",
            "  [ ] ieer................ NIST IE-ER DATA SAMPLE\n",
            "  [ ] inaugural........... C-Span Inaugural Address Corpus\n",
            "  [ ] indian.............. Indian Language POS-Tagged Corpus\n",
            "  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n",
            "                           ChaSen format)\n",
            "  [ ] kimmo............... PC-KIMMO Data Files\n",
            "Hit Enter to continue: \n",
            "  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n",
            "  [ ] large_grammars...... Large context-free and feature-based grammars\n",
            "                           for parser comparison\n",
            "  [ ] lin_thesaurus....... Lin's Dependency Thesaurus\n",
            "  [ ] mac_morpho.......... MAC-MORPHO: Brazilian Portuguese news text with\n",
            "                           part-of-speech tags\n",
            "  [ ] machado............. Machado de Assis -- Obra Completa\n",
            "  [ ] masc_tagged......... MASC Tagged Corpus\n",
            "  [ ] maxent_ne_chunker... ACE Named Entity Chunker (Maximum entropy)\n",
            "  [ ] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n",
            "  [ ] moses_sample........ Moses Sample Models\n",
            "  [ ] movie_reviews....... Sentiment Polarity Dataset Version 2.0\n",
            "  [ ] mte_teip5........... MULTEXT-East 1984 annotated corpus 4.0\n",
            "  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n",
            "                           2015) subset of the Paraphrase Database.\n",
            "  [ ] names............... Names Corpus, Version 1.3 (1994-03-29)\n",
            "  [ ] nombank.1.0......... NomBank Corpus 1.0\n",
            "  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n",
            "  [ ] nps_chat............ NPS Chat\n",
            "  [ ] omw-1.4............. Open Multilingual Wordnet\n",
            "  [ ] omw................. Open Multilingual Wordnet\n",
            "Hit Enter to continue: \n",
            "  [ ] opinion_lexicon..... Opinion Lexicon\n",
            "  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n",
            "  [ ] paradigms........... Paradigm Corpus\n",
            "  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n",
            "                           Evaluation Shared Task\n",
            "  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n",
            "                           character properties in Perl\n",
            "  [ ] pil................. The Patient Information Leaflet (PIL) Corpus\n",
            "  [ ] pl196x.............. Polish language of the XX century sixties\n",
            "  [ ] porter_test......... Porter Stemmer Test Files\n",
            "  [ ] ppattach............ Prepositional Phrase Attachment Corpus\n",
            "  [ ] problem_reports..... Problem Report Corpus\n",
            "  [ ] product_reviews_1... Product Reviews (5 Products)\n",
            "  [ ] product_reviews_2... Product Reviews (9 Products)\n",
            "  [ ] propbank............ Proposition Bank Corpus 1.0\n",
            "  [ ] pros_cons........... Pros and Cons\n",
            "  [ ] ptb................. Penn Treebank\n",
            "  [ ] punkt............... Punkt Tokenizer Models\n",
            "  [ ] qc.................. Experimental Data for Question Classification\n",
            "  [ ] reuters............. The Reuters-21578 benchmark corpus, ApteMod\n",
            "                           version\n",
            "Hit Enter to continue: \n",
            "  [ ] rslp................ RSLP Stemmer (Removedor de Sufixos da Lingua\n",
            "                           Portuguesa)\n",
            "  [ ] rte................. PASCAL RTE Challenges 1, 2, and 3\n",
            "  [ ] sample_grammars..... Sample Grammars\n",
            "  [ ] semcor.............. SemCor 3.0\n",
            "  [ ] senseval............ SENSEVAL 2 Corpus: Sense Tagged Text\n",
            "  [ ] sentence_polarity... Sentence Polarity Dataset v1.0\n",
            "  [ ] sentiwordnet........ SentiWordNet\n",
            "  [ ] shakespeare......... Shakespeare XML Corpus Sample\n",
            "  [ ] sinica_treebank..... Sinica Treebank Corpus Sample\n",
            "  [ ] smultron............ SMULTRON Corpus Sample\n",
            "  [ ] snowball_data....... Snowball Data\n",
            "  [ ] spanish_grammars.... Grammars for Spanish\n",
            "  [ ] state_union......... C-Span State of the Union Address Corpus\n",
            "  [ ] stopwords........... Stopwords Corpus\n",
            "  [ ] subjectivity........ Subjectivity Dataset v1.0\n",
            "  [ ] swadesh............. Swadesh Wordlists\n",
            "  [ ] switchboard......... Switchboard Corpus Sample\n",
            "  [ ] tagsets............. Help on Tagsets\n",
            "  [ ] timit............... TIMIT Corpus Sample\n",
            "  [ ] toolbox............. Toolbox Sample Files\n",
            "Hit Enter to continue: \n",
            "  [ ] treebank............ Penn Treebank Sample\n",
            "  [ ] twitter_samples..... Twitter Samples\n",
            "  [ ] udhr2............... Universal Declaration of Human Rights Corpus\n",
            "                           (Unicode Version)\n",
            "  [ ] udhr................ Universal Declaration of Human Rights Corpus\n",
            "  [ ] unicode_samples..... Unicode Samples\n",
            "  [ ] universal_tagset.... Mappings to the Universal Part-of-Speech Tagset\n",
            "  [ ] universal_treebanks_v20 Universal Treebanks Version 2.0\n",
            "  [ ] vader_lexicon....... VADER Sentiment Lexicon\n",
            "  [ ] verbnet3............ VerbNet Lexicon, Version 3.3\n",
            "  [ ] verbnet............. VerbNet Lexicon, Version 2.1\n",
            "  [ ] webtext............. Web Text Corpus\n",
            "  [ ] wmt15_eval.......... Evaluation data from WMT15\n",
            "  [ ] word2vec_sample..... Word2Vec Sample\n",
            "  [ ] wordnet2021......... Open English Wordnet 2021\n",
            "  [ ] wordnet2022......... Open English Wordnet 2022\n",
            "  [ ] wordnet31........... Wordnet 3.1\n",
            "  [ ] wordnet............. WordNet\n",
            "  [ ] wordnet_ic.......... WordNet-InfoContent\n",
            "  [ ] words............... Word Lists\n",
            "  [ ] ycoe................ York-Toronto-Helsinki Parsed Corpus of Old\n",
            "                           English Prose\n",
            "Hit Enter to continue: \n",
            "\n",
            "Collections:\n",
            "  [ ] all-corpora......... All the corpora\n",
            "  [ ] all-nltk............ All packages available on nltk_data gh-pages\n",
            "                           branch\n",
            "  [ ] all................. All packages\n",
            "  [ ] book................ Everything used in the NLTK Book\n",
            "  [ ] popular............. Popular packages\n",
            "  [ ] tests............... Packages for running tests\n",
            "  [ ] third-party......... Third-party data packages\n",
            "\n",
            "([*] marks installed packages)\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> \n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> l\n",
            "Packages:\n",
            "  [ ] abc................. Australian Broadcasting Commission 2006\n",
            "  [ ] alpino.............. Alpino Dutch Treebank\n",
            "  [ ] averaged_perceptron_tagger Averaged Perceptron Tagger\n",
            "  [ ] averaged_perceptron_tagger_ru Averaged Perceptron Tagger (Russian)\n",
            "  [ ] basque_grammars..... Grammars for Basque\n",
            "  [ ] bcp47............... BCP-47 Language Tags\n",
            "  [ ] biocreative_ppi..... BioCreAtIvE (Critical Assessment of Information\n",
            "                           Extraction Systems in Biology)\n",
            "  [ ] bllip_wsj_no_aux.... BLLIP Parser: WSJ Model\n",
            "  [ ] book_grammars....... Grammars from NLTK Book\n",
            "  [ ] brown............... Brown Corpus\n",
            "  [ ] brown_tei........... Brown Corpus (TEI XML Version)\n",
            "  [ ] cess_cat............ CESS-CAT Treebank\n",
            "  [ ] cess_esp............ CESS-ESP Treebank\n",
            "  [ ] chat80.............. Chat-80 Data Files\n",
            "  [ ] city_database....... City Database\n",
            "  [ ] cmudict............. The Carnegie Mellon Pronouncing Dictionary (0.6)\n",
            "  [ ] comparative_sentences Comparative Sentence Dataset\n",
            "  [ ] comtrans............ ComTrans Corpus Sample\n",
            "  [ ] conll2000........... CONLL 2000 Chunking Corpus\n",
            "Hit Enter to continue: \n",
            "  [ ] conll2002........... CONLL 2002 Named Entity Recognition Corpus\n",
            "  [ ] conll2007........... Dependency Treebanks from CoNLL 2007 (Catalan\n",
            "                           and Basque Subset)\n",
            "  [ ] crubadan............ Crubadan Corpus\n",
            "  [ ] dependency_treebank. Dependency Parsed Treebank\n",
            "  [ ] dolch............... Dolch Word List\n",
            "  [ ] europarl_raw........ Sample European Parliament Proceedings Parallel\n",
            "                           Corpus\n",
            "  [ ] extended_omw........ Extended Open Multilingual WordNet\n",
            "  [ ] floresta............ Portuguese Treebank\n",
            "  [ ] framenet_v15........ FrameNet 1.5\n",
            "  [ ] framenet_v17........ FrameNet 1.7\n",
            "  [ ] gazetteers.......... Gazeteer Lists\n",
            "  [ ] genesis............. Genesis Corpus\n",
            "  [ ] gutenberg........... Project Gutenberg Selections\n",
            "  [ ] ieer................ NIST IE-ER DATA SAMPLE\n",
            "  [ ] inaugural........... C-Span Inaugural Address Corpus\n",
            "  [ ] indian.............. Indian Language POS-Tagged Corpus\n",
            "  [ ] jeita............... JEITA Public Morphologically Tagged Corpus (in\n",
            "                           ChaSen format)\n",
            "  [ ] kimmo............... PC-KIMMO Data Files\n",
            "Hit Enter to continue: \n",
            "  [ ] knbc................ KNB Corpus (Annotated blog corpus)\n",
            "  [ ] large_grammars...... Large context-free and feature-based grammars\n",
            "                           for parser comparison\n",
            "  [ ] lin_thesaurus....... Lin's Dependency Thesaurus\n",
            "  [ ] mac_morpho.......... MAC-MORPHO: Brazilian Portuguese news text with\n",
            "                           part-of-speech tags\n",
            "  [ ] machado............. Machado de Assis -- Obra Completa\n",
            "  [ ] masc_tagged......... MASC Tagged Corpus\n",
            "  [ ] maxent_ne_chunker... ACE Named Entity Chunker (Maximum entropy)\n",
            "  [ ] maxent_treebank_pos_tagger Treebank Part of Speech Tagger (Maximum entropy)\n",
            "  [ ] moses_sample........ Moses Sample Models\n",
            "  [ ] movie_reviews....... Sentiment Polarity Dataset Version 2.0\n",
            "  [ ] mte_teip5........... MULTEXT-East 1984 annotated corpus 4.0\n",
            "  [ ] mwa_ppdb............ The monolingual word aligner (Sultan et al.\n",
            "                           2015) subset of the Paraphrase Database.\n",
            "  [ ] names............... Names Corpus, Version 1.3 (1994-03-29)\n",
            "  [ ] nombank.1.0......... NomBank Corpus 1.0\n",
            "  [ ] nonbreaking_prefixes Non-Breaking Prefixes (Moses Decoder)\n",
            "  [ ] nps_chat............ NPS Chat\n",
            "  [ ] omw-1.4............. Open Multilingual Wordnet\n",
            "  [ ] omw................. Open Multilingual Wordnet\n",
            "Hit Enter to continue: \n",
            "  [ ] opinion_lexicon..... Opinion Lexicon\n",
            "  [ ] panlex_swadesh...... PanLex Swadesh Corpora\n",
            "  [ ] paradigms........... Paradigm Corpus\n",
            "  [ ] pe08................ Cross-Framework and Cross-Domain Parser\n",
            "                           Evaluation Shared Task\n",
            "  [ ] perluniprops........ perluniprops: Index of Unicode Version 7.0.0\n",
            "                           character properties in Perl\n",
            "  [ ] pil................. The Patient Information Leaflet (PIL) Corpus\n",
            "  [ ] pl196x.............. Polish language of the XX century sixties\n",
            "  [ ] porter_test......... Porter Stemmer Test Files\n",
            "  [ ] ppattach............ Prepositional Phrase Attachment Corpus\n",
            "  [ ] problem_reports..... Problem Report Corpus\n",
            "  [ ] product_reviews_1... Product Reviews (5 Products)\n",
            "  [ ] product_reviews_2... Product Reviews (9 Products)\n",
            "  [ ] propbank............ Proposition Bank Corpus 1.0\n",
            "  [ ] pros_cons........... Pros and Cons\n",
            "  [ ] ptb................. Penn Treebank\n",
            "  [ ] punkt............... Punkt Tokenizer Models\n",
            "  [ ] qc.................. Experimental Data for Question Classification\n",
            "  [ ] reuters............. The Reuters-21578 benchmark corpus, ApteMod\n",
            "                           version\n",
            "Hit Enter to continue: \n",
            "  [ ] rslp................ RSLP Stemmer (Removedor de Sufixos da Lingua\n",
            "                           Portuguesa)\n",
            "  [ ] rte................. PASCAL RTE Challenges 1, 2, and 3\n",
            "  [ ] sample_grammars..... Sample Grammars\n",
            "  [ ] semcor.............. SemCor 3.0\n",
            "  [ ] senseval............ SENSEVAL 2 Corpus: Sense Tagged Text\n",
            "  [ ] sentence_polarity... Sentence Polarity Dataset v1.0\n",
            "  [ ] sentiwordnet........ SentiWordNet\n",
            "  [ ] shakespeare......... Shakespeare XML Corpus Sample\n",
            "  [ ] sinica_treebank..... Sinica Treebank Corpus Sample\n",
            "  [ ] smultron............ SMULTRON Corpus Sample\n",
            "  [ ] snowball_data....... Snowball Data\n",
            "  [ ] spanish_grammars.... Grammars for Spanish\n",
            "  [ ] state_union......... C-Span State of the Union Address Corpus\n",
            "  [ ] stopwords........... Stopwords Corpus\n",
            "  [ ] subjectivity........ Subjectivity Dataset v1.0\n",
            "  [ ] swadesh............. Swadesh Wordlists\n",
            "  [ ] switchboard......... Switchboard Corpus Sample\n",
            "  [ ] tagsets............. Help on Tagsets\n",
            "  [ ] timit............... TIMIT Corpus Sample\n",
            "  [ ] toolbox............. Toolbox Sample Files\n",
            "Hit Enter to continue: \n",
            "  [ ] treebank............ Penn Treebank Sample\n",
            "  [ ] twitter_samples..... Twitter Samples\n",
            "  [ ] udhr2............... Universal Declaration of Human Rights Corpus\n",
            "                           (Unicode Version)\n",
            "  [ ] udhr................ Universal Declaration of Human Rights Corpus\n",
            "  [ ] unicode_samples..... Unicode Samples\n",
            "  [ ] universal_tagset.... Mappings to the Universal Part-of-Speech Tagset\n",
            "  [ ] universal_treebanks_v20 Universal Treebanks Version 2.0\n",
            "  [ ] vader_lexicon....... VADER Sentiment Lexicon\n",
            "  [ ] verbnet3............ VerbNet Lexicon, Version 3.3\n",
            "  [ ] verbnet............. VerbNet Lexicon, Version 2.1\n",
            "  [ ] webtext............. Web Text Corpus\n",
            "  [ ] wmt15_eval.......... Evaluation data from WMT15\n",
            "  [ ] word2vec_sample..... Word2Vec Sample\n",
            "  [ ] wordnet2021......... Open English Wordnet 2021\n",
            "  [ ] wordnet2022......... Open English Wordnet 2022\n",
            "  [ ] wordnet31........... Wordnet 3.1\n",
            "  [ ] wordnet............. WordNet\n",
            "  [ ] wordnet_ic.......... WordNet-InfoContent\n",
            "  [ ] words............... Word Lists\n",
            "  [ ] ycoe................ York-Toronto-Helsinki Parsed Corpus of Old\n",
            "                           English Prose\n",
            "Hit Enter to continue: \n",
            "\n",
            "Collections:\n",
            "  [ ] all-corpora......... All the corpora\n",
            "  [ ] all-nltk............ All packages available on nltk_data gh-pages\n",
            "                           branch\n",
            "  [ ] all................. All packages\n",
            "  [ ] book................ Everything used in the NLTK Book\n",
            "  [ ] popular............. Popular packages\n",
            "  [ ] tests............... Packages for running tests\n",
            "  [ ] third-party......... Third-party data packages\n",
            "\n",
            "([*] marks installed packages)\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> \n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['IT was 2 p.m. on the afternoon of May 7, 1915.',\n",
              " 'The Lusitania had been struck and was sinking rapidly, while the boats were being launched with all possible speed.',\n",
              " 'The women and children were being lined up awaiting their turn.',\n",
              " 'Some still clung desperately to husbands and fathers.',\n",
              " 'One girl stood alone, slightly apart from the rest.',\n",
              " 'She was quite young, not more than eighteen.',\n",
              " 'She did not seem afraid, and her grave, steadfast eyes looked straight ahead.']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "! pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7FZGApdbV0h",
        "outputId": "f1e1011a-962a-419c-826b-815924f30d2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "example_string = \"IT was 2 p.m. on the afternoon of May 7, 1915. The Lusitania had been struck and was sinking rapidly, while the boats were being launched with all possible speed. The women and children were being lined up awaiting their turn. Some still clung desperately to husbands and fathers. One girl stood alone, slightly apart from the rest. She was quite young, not more than eighteen. She did not seem afraid, and her grave, steadfast eyes looked straight ahead.\"\n",
        "sent_tokenize(example_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_X8DT7_jbtdp",
        "outputId": "f502c858-683b-43bc-c56d-093f14d452d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['IT was 2 p.m. on the afternoon of May 7, 1915.',\n",
              " 'The Lusitania had been struck and was sinking rapidly, while the boats were being launched with all possible speed.',\n",
              " 'The women and children were being lined up awaiting their turn.',\n",
              " 'Some still clung desperately to husbands and fathers.',\n",
              " 'One girl stood alone, slightly apart from the rest.',\n",
              " 'She was quite young, not more than eighteen.',\n",
              " 'She did not seem afraid, and her grave, steadfast eyes looked straight ahead.']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "example_string = \"IT was 2 p.m. on the afternoon of May 7, 1915. The Lusitania had been struck and was sinking rapidly, while the boats were being launched with all possible speed. The women and children were being lined up awaiting their turn. Some still clung desperately to husbands and fathers. One girl stood alone, slightly apart from the rest. She was quite young, not more than eighteen. She did not seem afraid, and her grave, steadfast eyes looked straight ahead.\"\n",
        "word_tokenize(example_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgcyKGfGbx_X",
        "outputId": "d92c8474-a5d9-4938-a15f-4133ef82a1c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['IT',\n",
              " 'was',\n",
              " '2',\n",
              " 'p.m.',\n",
              " 'on',\n",
              " 'the',\n",
              " 'afternoon',\n",
              " 'of',\n",
              " 'May',\n",
              " '7',\n",
              " ',',\n",
              " '1915',\n",
              " '.',\n",
              " 'The',\n",
              " 'Lusitania',\n",
              " 'had',\n",
              " 'been',\n",
              " 'struck',\n",
              " 'and',\n",
              " 'was',\n",
              " 'sinking',\n",
              " 'rapidly',\n",
              " ',',\n",
              " 'while',\n",
              " 'the',\n",
              " 'boats',\n",
              " 'were',\n",
              " 'being',\n",
              " 'launched',\n",
              " 'with',\n",
              " 'all',\n",
              " 'possible',\n",
              " 'speed',\n",
              " '.',\n",
              " 'The',\n",
              " 'women',\n",
              " 'and',\n",
              " 'children',\n",
              " 'were',\n",
              " 'being',\n",
              " 'lined',\n",
              " 'up',\n",
              " 'awaiting',\n",
              " 'their',\n",
              " 'turn',\n",
              " '.',\n",
              " 'Some',\n",
              " 'still',\n",
              " 'clung',\n",
              " 'desperately',\n",
              " 'to',\n",
              " 'husbands',\n",
              " 'and',\n",
              " 'fathers',\n",
              " '.',\n",
              " 'One',\n",
              " 'girl',\n",
              " 'stood',\n",
              " 'alone',\n",
              " ',',\n",
              " 'slightly',\n",
              " 'apart',\n",
              " 'from',\n",
              " 'the',\n",
              " 'rest',\n",
              " '.',\n",
              " 'She',\n",
              " 'was',\n",
              " 'quite',\n",
              " 'young',\n",
              " ',',\n",
              " 'not',\n",
              " 'more',\n",
              " 'than',\n",
              " 'eighteen',\n",
              " '.',\n",
              " 'She',\n",
              " 'did',\n",
              " 'not',\n",
              " 'seem',\n",
              " 'afraid',\n",
              " ',',\n",
              " 'and',\n",
              " 'her',\n",
              " 'grave',\n",
              " ',',\n",
              " 'steadfast',\n",
              " 'eyes',\n",
              " 'looked',\n",
              " 'straight',\n",
              " 'ahead',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that returns the list of the word tokens contained in the\n",
        "example_string variable from the last code example"
      ],
      "metadata": {
        "id": "gNamdglEcG13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_of_word_tokens(given_string):\n",
        "  list_of_tokens = word_tokenize(given_string)\n",
        "  return list_of_tokens\n",
        "example_string = \"IT was 2 p.m. on the afternoon of May 7, 1915. The Lusitania had been struck and was sinking rapidly, while the boats were being launched with all possible speed. The women and children were being lined up awaiting their turn. Some still clung desperately to husbands and fathers. One girl stood alone, slightly apart from the rest. She was quite young, not more than eighteen. She did not seem afraid, and her grave, steadfast eyes looked straight ahead.\"\n",
        "print(list_of_word_tokens(example_string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avP7844Mb5nf",
        "outputId": "b6bf149e-9ec5-42bd-9456-6f80da501b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['IT', 'was', '2', 'p.m.', 'on', 'the', 'afternoon', 'of', 'May', '7', ',', '1915', '.', 'The', 'Lusitania', 'had', 'been', 'struck', 'and', 'was', 'sinking', 'rapidly', ',', 'while', 'the', 'boats', 'were', 'being', 'launched', 'with', 'all', 'possible', 'speed', '.', 'The', 'women', 'and', 'children', 'were', 'being', 'lined', 'up', 'awaiting', 'their', 'turn', '.', 'Some', 'still', 'clung', 'desperately', 'to', 'husbands', 'and', 'fathers', '.', 'One', 'girl', 'stood', 'alone', ',', 'slightly', 'apart', 'from', 'the', 'rest', '.', 'She', 'was', 'quite', 'young', ',', 'not', 'more', 'than', 'eighteen', '.', 'She', 'did', 'not', 'seem', 'afraid', ',', 'and', 'her', 'grave', ',', 'steadfast', 'eyes', 'looked', 'straight', 'ahead', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def tokenize_string(input_string):\n",
        "    # Using regular expression to find word tokens\n",
        "    word_tokens = re.findall(r'\\b\\w+\\b', input_string)\n",
        "    return word_tokens\n",
        "\n",
        "example_string = \"IT was 2 p.m. on the afternoon of May 7, 1915. The Lusitania had been struck and was sinking rapidly, while the boats were being launched with all possible speed. The women and children were being lined up awaiting their turn. Some still clung desperately to husbands and fathers. One girl stood alone, slightly apart from the rest. She was quite young, not more than eighteen. She did not seem afraid, and her grave, steadfast eyes looked straight ahead.\"\n",
        "\n",
        "print(tokenize_string(example_string))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtMUGVp9dTdo",
        "outputId": "ffaa637a-a08a-455a-a02b-4c30ae6bd5bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['IT', 'was', '2', 'p', 'm', 'on', 'the', 'afternoon', 'of', 'May', '7', '1915', 'The', 'Lusitania', 'had', 'been', 'struck', 'and', 'was', 'sinking', 'rapidly', 'while', 'the', 'boats', 'were', 'being', 'launched', 'with', 'all', 'possible', 'speed', 'The', 'women', 'and', 'children', 'were', 'being', 'lined', 'up', 'awaiting', 'their', 'turn', 'Some', 'still', 'clung', 'desperately', 'to', 'husbands', 'and', 'fathers', 'One', 'girl', 'stood', 'alone', 'slightly', 'apart', 'from', 'the', 'rest', 'She', 'was', 'quite', 'young', 'not', 'more', 'than', 'eighteen', 'She', 'did', 'not', 'seem', 'afraid', 'and', 'her', 'grave', 'steadfast', 'eyes', 'looked', 'straight', 'ahead']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that returns the set of the sentences contained in the\n",
        "example_string variable from the last code example"
      ],
      "metadata": {
        "id": "fXxzul11dzYo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_of_word_tokens(given_string):\n",
        "  list_of_tokens = sent_tokenize(given_string)\n",
        "  return list_of_tokens\n",
        "example_string = \"IT was 2 p.m. on the afternoon of May 7, 1915. The Lusitania had been struck and was sinking rapidly, while the boats were being launched with all possible speed. The women and children were being lined up awaiting their turn. Some still clung desperately to husbands and fathers. One girl stood alone, slightly apart from the rest. She was quite young, not more than eighteen. She did not seem afraid, and her grave, steadfast eyes looked straight ahead.\"\n",
        "print(list_of_word_tokens(example_string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5axrzRidtSJ",
        "outputId": "b291f1d9-b345-4a58-929d-95d9a6507451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['IT was 2 p.m. on the afternoon of May 7, 1915.', 'The Lusitania had been struck and was sinking rapidly, while the boats were being launched with all possible speed.', 'The women and children were being lined up awaiting their turn.', 'Some still clung desperately to husbands and fathers.', 'One girl stood alone, slightly apart from the rest.', 'She was quite young, not more than eighteen.', 'She did not seem afraid, and her grave, steadfast eyes looked straight ahead.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that returns the list of the (word) tokens that appear more than\n",
        "once in example_string"
      ],
      "metadata": {
        "id": "EMmIG0UeecUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_of_word(given_string):\n",
        "  list_of_tokens = word_tokenize(given_string)\n",
        "  empty_list = []\n",
        "  for word in list_of_tokens:\n",
        "    if list_of_tokens.count(word)>1:\n",
        "      empty_list.append(word)\n",
        "  return empty_list\n",
        "example_string = \"IT was 2 p.m. on the afternoon of May 7, 1915. The Lusitania had been struck and was sinking rapidly, while the boats were being launched with all possible speed. The women and children were being lined up awaiting their turn. Some still clung desperately to husbands and fathers. One girl stood alone, slightly apart from the rest. She was quite young, not more than eighteen. She did not seem afraid, and her grave, steadfast eyes looked straight ahead.\"\n",
        "result = list_of_word(example_string)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6_nkB85eUJY",
        "outputId": "d1cff7f0-be37-4a25-a9bc-d593302cd40e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['was', 'the', ',', '.', 'The', 'and', 'was', ',', 'the', 'were', 'being', '.', 'The', 'and', 'were', 'being', '.', 'and', '.', ',', 'the', '.', 'She', 'was', ',', 'not', '.', 'She', 'not', ',', 'and', ',', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that returns a dictionary containing, for each token in\n",
        "example_string, the number of times that token appears in example_string."
      ],
      "metadata": {
        "id": "ONosIBeEke3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "def list_of_word(given_string):\n",
        "  list_of_tokens = word_tokenize(given_string)\n",
        "  return Counter(list_of_tokens)\n",
        "example_string = \"IT was 2 p.m. on the afternoon of May 7, 1915. The Lusitania had been struck and was sinking rapidly, while the boats were being launched with all possible speed. The women and children were being lined up awaiting their turn. Some still clung desperately to husbands and fathers. One girl stood alone, slightly apart from the rest. She was quite young, not more than eighteen. She did not seem afraid, and her grave, steadfast eyes looked straight ahead.\"\n",
        "result = list_of_word(example_string)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqvKzJWjkajk",
        "outputId": "ab0660e7-12d8-4a0c-dda6-48cdb3a82fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'.': 7, ',': 6, 'and': 4, 'was': 3, 'the': 3, 'The': 2, 'were': 2, 'being': 2, 'She': 2, 'not': 2, 'IT': 1, '2': 1, 'p.m.': 1, 'on': 1, 'afternoon': 1, 'of': 1, 'May': 1, '7': 1, '1915': 1, 'Lusitania': 1, 'had': 1, 'been': 1, 'struck': 1, 'sinking': 1, 'rapidly': 1, 'while': 1, 'boats': 1, 'launched': 1, 'with': 1, 'all': 1, 'possible': 1, 'speed': 1, 'women': 1, 'children': 1, 'lined': 1, 'up': 1, 'awaiting': 1, 'their': 1, 'turn': 1, 'Some': 1, 'still': 1, 'clung': 1, 'desperately': 1, 'to': 1, 'husbands': 1, 'fathers': 1, 'One': 1, 'girl': 1, 'stood': 1, 'alone': 1, 'slightly': 1, 'apart': 1, 'from': 1, 'rest': 1, 'quite': 1, 'young': 1, 'more': 1, 'than': 1, 'eighteen': 1, 'did': 1, 'seem': 1, 'afraid': 1, 'her': 1, 'grave': 1, 'steadfast': 1, 'eyes': 1, 'looked': 1, 'straight': 1, 'ahead': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "stopword = stopwords.words(\"english\")\n",
        "example_string = \"The Lusitania had been struck and was sinking rapidly, while the boats were being launched with all possible speed.\"\n",
        "full_text=example_string.lower() #lowercasing\n",
        "word_tokens = word_tokenize(full_text)\n",
        "print(word_tokens[:20])\n",
        "filtered_tokens= [word for word in word_tokens if word.casefold() not in stopword]\n",
        "print(filtered_tokens[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwVidm2SnFTd",
        "outputId": "384c107e-4fff-4158-932f-5529920c1005"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'lusitania', 'had', 'been', 'struck', 'and', 'was', 'sinking', 'rapidly', ',', 'while', 'the', 'boats', 'were', 'being', 'launched', 'with', 'all', 'possible', 'speed']\n",
            "['lusitania', 'struck', 'sinking', 'rapidly', ',', 'boats', 'launched', 'possible', 'speed', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "stopword = stopwords.words(\"english\")\n",
        "example_string = \"The Lusitania had been struck and was sinking rapidly, while the boats were being launched with all possible speed.\"\n",
        "full_text=example_string.lower() #lowercasing\n",
        "word_tokens = word_tokenize(full_text)\n",
        "print(word_tokens[:20])\n",
        "filtered_tokens= [word for word in word_tokens if word not in stopword]\n",
        "print(filtered_tokens[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giymzzKJlFl7",
        "outputId": "34a9ab92-16a4-469e-e6c5-c82b4832f343"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'lusitania', 'had', 'been', 'struck', 'and', 'was', 'sinking', 'rapidly', ',', 'while', 'the', 'boats', 'were', 'being', 'launched', 'with', 'all', 'possible', 'speed']\n",
            "['lusitania', 'struck', 'sinking', 'rapidly', ',', 'boats', 'launched', 'possible', 'speed', '.']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")\n",
        "print(stopwords.fileids())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqGFhKs_o99l",
        "outputId": "3b127662-142c-4d16-ea9b-3fb7820934cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['arabic', 'azerbaijani', 'basque', 'bengali', 'catalan', 'chinese', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hebrew', 'hinglish', 'hungarian', 'indonesian', 'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian', 'russian', 'slovene', 'spanish', 'swedish', 'tajik', 'turkish']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "adapt the previous code snippet to handle an input in Italian (in the example we\n",
        "have a plain translation of the text above): what needs to be updated and what\n",
        "can be kept unchanged?"
      ],
      "metadata": {
        "id": "SlsgY5AlqUM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def find_duplicate_tokens(input_string):\n",
        "    # Tokenize the string using Italian word characters\n",
        "    word_tokens = re.findall(r'\\b[\\wÀ-ÿ]+\\b', input_string.lower())\n",
        "\n",
        "    # Count the occurrences of each token\n",
        "    token_counts = Counter(word_tokens)\n",
        "\n",
        "    # Find tokens that appear more than once\n",
        "    duplicates = [token for token, count in token_counts.items() if count > 1]\n",
        "\n",
        "    return duplicates\n",
        "\n",
        "example_string = \"Il Lusitania era stato colpito e stava affondando rapidamente, mentre le barche venivano lanciate a tutta velocità. Le donne e i bambini erano in fila in attesa del loro turno. Alcuni si aggrappavano ancora disperatamente a mariti e padri. Una ragazza era sola, leggermente in disparte dal resto.\"\n",
        "\n",
        "print(find_duplicate_tokens(example_string))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRHeVbPvqNmm",
        "outputId": "e3bc1aaa-0522-4588-977b-2cf009ecd5a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['era', 'e', 'le', 'a', 'in']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "port_stm = PorterStemmer()\n",
        "example_string = \"The Lusitania had been struck and was sinking rapidly, while the boats were being launched with all possible speed.\"\n",
        "words = word_tokenize(example_string)\n",
        "stemmed_words = [port_stm.stem(word) for word in words]\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOrjtZDK15La",
        "outputId": "fd23d89c-c269-4b22-f1a0-2512f36cf4a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'lusitania', 'had', 'been', 'struck', 'and', 'wa', 'sink', 'rapidli', ',', 'while', 'the', 'boat', 'were', 'be', 'launch', 'with', 'all', 'possibl', 'speed', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that takes a string in input and returns the list of the stemmed\n",
        "words contained in the example_string variable from the last code example"
      ],
      "metadata": {
        "id": "kmFchR5x3GnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_of_stemmed_words(in_string):\n",
        "  port = PorterStemmer()\n",
        "  words = word_tokenize(in_string)\n",
        "  stemmed_words = [port.stem(word) for word in words]\n",
        "  return stemmed_words\n",
        "example_string = \"The Lusitania had been struck and was sinking rapidly, while the boats were being launched with all possible speed.\"\n",
        "result = list_of_stemmed_words(example_string)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYJU7Oru2-cL",
        "outputId": "fb64879c-95cf-4588-cda1-a4148b23ece5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'lusitania', 'had', 'been', 'struck', 'and', 'wa', 'sink', 'rapidli', ',', 'while', 'the', 'boat', 'were', 'be', 'launch', 'with', 'all', 'possibl', 'speed', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "example_string = \"The Lusitania had been struck and was sinking rapidly, while the boats were being launched with all possible speed.\"\n",
        "words = word_tokenize(example_string)\n",
        "print(nltk.pos_tag(words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCeqqIqM4XlC",
        "outputId": "01054b70-f93f-485c-e28d-83778cb6df15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DT'), ('Lusitania', 'NNP'), ('had', 'VBD'), ('been', 'VBN'), ('struck', 'VBN'), ('and', 'CC'), ('was', 'VBD'), ('sinking', 'VBG'), ('rapidly', 'RB'), (',', ','), ('while', 'IN'), ('the', 'DT'), ('boats', 'NNS'), ('were', 'VBD'), ('being', 'VBG'), ('launched', 'VBN'), ('with', 'IN'), ('all', 'DT'), ('possible', 'JJ'), ('speed', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that takes an input string and returns only verbs therein"
      ],
      "metadata": {
        "id": "yohBgayp54pj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "def string_verbs(in_string):\n",
        "  words = word_tokenize(in_string)\n",
        "  pos_tagged = pos_tag(words)\n",
        "  verbs = [word for word,pos in pos_tagged if pos.startswith('VB')]\n",
        "  return verbs\n",
        "\n",
        "example_string = \"The Lusitania had been struck and was sinking rapidly, while the boats were being launched with all possible speed.\"\n",
        "result = string_verbs(example_string)\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k1iYwUM5kGL",
        "outputId": "9d81470e-f6fa-441a-f447-a831cc99a1f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['had', 'been', 'struck', 'was', 'sinking', 'were', 'being', 'launched']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"punkt\")\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "example_string = \"The Lusitania had been struck and was sinking rapidly, while the boats were being launched with all possible speed.\"\n",
        "words = word_tokenize(example_string)\n",
        "print(words)\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
        "print(lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vH36veDN7TXc",
        "outputId": "5825f0c8-980e-45f6-d4e6-23b10ce1840b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'Lusitania', 'had', 'been', 'struck', 'and', 'was', 'sinking', 'rapidly', ',', 'while', 'the', 'boats', 'were', 'being', 'launched', 'with', 'all', 'possible', 'speed', '.']\n",
            "['The', 'Lusitania', 'had', 'been', 'struck', 'and', 'wa', 'sinking', 'rapidly', ',', 'while', 'the', 'boat', 'were', 'being', 'launched', 'with', 'all', 'possible', 'speed', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"maxent_ne_chunker\")\n",
        "nltk.download('words')\n",
        "words = word_tokenize(\"While Ann was coming home, Jess went to Spain with Joy and her new Apple laptop.\",language=\"english\")\n",
        "pos_tags = nltk.pos_tag(words)\n",
        "tree = nltk.ne_chunk(pos_tags,binary=True)\n",
        "print(tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxFyfl-X_ord",
        "outputId": "25a8815b-f272-4c99-b83e-3109a6677ba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(S\n",
            "  While/IN\n",
            "  (NE Ann/NNP)\n",
            "  was/VBD\n",
            "  coming/VBG\n",
            "  home/RB\n",
            "  ,/,\n",
            "  (NE Jess/NNP)\n",
            "  went/VBD\n",
            "  to/TO\n",
            "  (NE Spain/NNP)\n",
            "  with/IN\n",
            "  (NE Joy/NNP)\n",
            "  and/CC\n",
            "  her/PRP$\n",
            "  new/JJ\n",
            "  Apple/NNP\n",
            "  laptop/NN\n",
            "  ./.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"maxent_ne_chunker\")\n",
        "nltk.download(\"words\")\n",
        "example_string = \"The Lusitania had been struck and was sinking rapidly; Jenny runaway and started swimming towards the US coast.\"\n",
        "def extract_ne(example_string):\n",
        "  words = word_tokenize(example_string, language='english')\n",
        "  tags = nltk.pos_tag(words)\n",
        "  tree = nltk.ne_chunk(tags, binary=True)\n",
        "  return set( \" \".join(i[0] for i in t) for t in tree if hasattr(t, \"label\") and t.label() == \"NE\" )\n",
        "extract_ne(example_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fidMYi0ABXEO",
        "outputId": "1b79b904-0839-4600-b27f-81bc4ea91e7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Jenny', 'Lusitania', 'US'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that takes an input string and returns only persons therein; test it\n",
        "on the example_string above"
      ],
      "metadata": {
        "id": "T5ivZCebCPy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "def extract_persons(input_string):\n",
        "    # Tokenize the input string into words\n",
        "    words = nltk.word_tokenize(input_string)\n",
        "\n",
        "    # Perform part-of-speech tagging\n",
        "    tagged_words = nltk.pos_tag(words)\n",
        "\n",
        "    # Perform named entity recognition\n",
        "    named_entities = nltk.ne_chunk(tagged_words)\n",
        "\n",
        "    # Extract persons\n",
        "    persons = []\n",
        "    for entity in named_entities:\n",
        "        if isinstance(entity, nltk.tree.Tree) and entity.label() == 'PERSON':\n",
        "            persons.extend([leaf[0] for leaf in entity])\n",
        "\n",
        "    return persons\n",
        "\n",
        "# Example usage:\n",
        "example_string = \"While Ann was coming home, Jess went to Spain with Joy and his new Apple laptop.\"\n",
        "persons = extract_persons(example_string)\n",
        "print(persons)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-024QpNABihd",
        "outputId": "3cd60d98-43e3-4f23-e303-ff41665d2849"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Ann', 'Jess', 'Joy']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"maxent_ne_chunker\")\n",
        "nltk.download(\"words\")\n",
        "\n",
        "example_string = \"The Lusitania had been struck and was sinking rapidly; Jenny runaway and started swimming towards the US coast.\"\n",
        "\n",
        "def extract_ne(example_string):\n",
        "    words = word_tokenize(example_string, language='english')\n",
        "    tags = nltk.pos_tag(words)\n",
        "    tree = nltk.ne_chunk(tags, binary=True)\n",
        "    return set(\n",
        "        \" \".join(i[0] for i in t)\n",
        "        for t in tree # for item in iterable\n",
        "        if hasattr(t, \"label\") and t.label() == \"NE\"\n",
        "    )\n",
        "extract_ne(example_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODch_SkhCORG",
        "outputId": "29fefc49-8b58-4d32-ca39-a38388b81d54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Jenny', 'Lusitania', 'US'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "spacy\n"
      ],
      "metadata": {
        "id": "_CdAfF9JJgqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "import spacy\n",
        "# spacy.prefer_gpu()\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"The Lusitania had been struck and was sinking rapidly; Jenny runaway and started swimming towards the US coast.\")\n",
        "for token in doc:\n",
        "  print(token.text, token.pos_, token.dep_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mO6ReqhCWl2",
        "outputId": "4f3b2469-1b31-4d91-d121-898e18359cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "The DET det\n",
            "Lusitania PROPN nsubjpass\n",
            "had AUX aux\n",
            "been AUX auxpass\n",
            "struck VERB ccomp\n",
            "and CCONJ cc\n",
            "was AUX aux\n",
            "sinking VERB conj\n",
            "rapidly ADV advmod\n",
            "; PUNCT punct\n",
            "Jenny PROPN nsubj\n",
            "runaway ADV ROOT\n",
            "and CCONJ cc\n",
            "started VERB conj\n",
            "swimming VERB xcomp\n",
            "towards ADP prep\n",
            "the DET det\n",
            "US PROPN compound\n",
            "coast NOUN pobj\n",
            ". PUNCT punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "span = doc[2:4]\n",
        "print(span)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIMqUmedJkcZ",
        "outputId": "47a83351-2c5a-4ebf-a589-4999d2617a31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "had been\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtering stop-words"
      ],
      "metadata": {
        "id": "Uic6LUVmRjCq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
        "print(f\"overall {len(spacy_stopwords)} stopwords are being employed...\")\n",
        "input_text = \"The Lusitania had been struck and was sinking rapidly; Jenny runaway and started swimming towards the US coast.\"\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "doc=nlp(input_text)\n",
        "print([token for token in doc if not token.is_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fzw38-HFReY1",
        "outputId": "44479b58-5fec-4bf8-c910-d25dbf07694e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "overall 326 stopwords are being employed...\n",
            "[Lusitania, struck, sinking, rapidly, ;, Jenny, runaway, started, swimming, coast, .]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization"
      ],
      "metadata": {
        "id": "bWt__GEQRltz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "input_text = \"The Lusitania hadbeen struck and was sinking rapidly; Jenny runaway and started swimming towards the US coast\"\n",
        "doc = nlp(input_text)\n",
        "print(doc)\n",
        "for token in doc:\n",
        "  print(f\"{str(token):>10}:{str(token.lemma_)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXa1BNrgRgqc",
        "outputId": "df2e71ba-3da0-4aa4-9690-b8b3b67b29b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Lusitania hadbeen struck and was sinking rapidly; Jenny runaway and started swimming towards the US coast\n",
            "       The:the\n",
            " Lusitania:Lusitania\n",
            "   hadbeen:hadbeen\n",
            "    struck:strike\n",
            "       and:and\n",
            "       was:be\n",
            "   sinking:sink\n",
            "   rapidly:rapidly\n",
            "         ;:;\n",
            "     Jenny:Jenny\n",
            "   runaway:runaway\n",
            "       and:and\n",
            "   started:start\n",
            "  swimming:swim\n",
            "   towards:towards\n",
            "       the:the\n",
            "        US:US\n",
            "     coast:coast\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word frequency"
      ],
      "metadata": {
        "id": "W3fAf1xfRstm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "text = \"An operating system (OS) is system software that manages computer\" \\\n",
        "\"hardware and software resources, and provides common services for\" \\\n",
        "\"computer programs. Time-sharing operating systems schedule tasks \" \\\n",
        "\"for efficient use of the system and may also include accounting \" \\\n",
        "\"software for cost allocation of processor time, mass storage, \" \\\n",
        "\"peripherals, and other resources. For hardware functions such as \" \\\n",
        "\"input and output and memory allocation, the operating system acts \" \\\n",
        "\"as an intermediary between programs and the computer hardware, \" \\\n",
        "\"although the application code is usually executed directly by the \" \\\n",
        "\"hardware and frequently makes system calls to an OS function or is \" \\\n",
        "\"interrupted by it. Operating systems are found on many devices that \" \\\n",
        "\"contain a computer – from cellular phones and video game consoles to \" \\\n",
        "\"web servers and supercomputers.\"\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc=nlp(text)\n",
        "words = [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
        "print(Counter(words).most_common(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rvlKj4GRoQs",
        "outputId": "a67aa457-7e18-4f7b-b3ac-207c0bba989f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('system', 5), ('operating', 3), ('software', 3), ('hardware', 3), ('OS', 2)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "POS tagging"
      ],
      "metadata": {
        "id": "L65BtnM3Rw5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "input_text = \"The Lusitania had been struck and was sinking rapidly.\"\n",
        "doc = nlp(input_text)\n",
        "for token in doc:\n",
        "  print(\n",
        "f'TOKEN: {str(token):10} \\\n",
        "TAG: {str(token.tag_):10} \\\n",
        "POS: {str(token.pos_):10} \\\n",
        "EXPLANATION: {spacy.explain(token.tag_):20}'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHG0pBGCRvBE",
        "outputId": "40a6233a-db41-4613-a7a4-2150ad7e33c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOKEN: The        TAG: DT         POS: DET        EXPLANATION: determiner          \n",
            "TOKEN: Lusitania  TAG: NNP        POS: PROPN      EXPLANATION: noun, proper singular\n",
            "TOKEN: had        TAG: VBD        POS: AUX        EXPLANATION: verb, past tense    \n",
            "TOKEN: been       TAG: VBN        POS: AUX        EXPLANATION: verb, past participle\n",
            "TOKEN: struck     TAG: VBN        POS: VERB       EXPLANATION: verb, past participle\n",
            "TOKEN: and        TAG: CC         POS: CCONJ      EXPLANATION: conjunction, coordinating\n",
            "TOKEN: was        TAG: VBD        POS: AUX        EXPLANATION: verb, past tense    \n",
            "TOKEN: sinking    TAG: VBG        POS: VERB       EXPLANATION: verb, gerund or present participle\n",
            "TOKEN: rapidly    TAG: RB         POS: ADV        EXPLANATION: adverb              \n",
            "TOKEN: .          TAG: .          POS: PUNCT      EXPLANATION: punctuation mark, sentence closer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "extracting tokens with specific POS"
      ],
      "metadata": {
        "id": "Db4KKd-KR1Bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "proper_nouns = []\n",
        "verbs = []\n",
        "for token in doc:\n",
        "  if token.pos_==\"PROPN\":\n",
        "    proper_nouns.append(token)\n",
        "  if token.pos_==\"VERB\":\n",
        "    verbs.append(token)\n",
        "print(proper_nouns)\n",
        "print(verbs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKbhfhtVRzDk",
        "outputId": "954f24bd-e33c-4f40-eb32-6f8507cb5e52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Lusitania]\n",
            "[struck, sinking]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "input_text = \"The Lusitania had been struck and was sinking rapidly; Jenny runaway and started swimming towards the US coast.\"\n",
        "doc = nlp(input_text)\n",
        "for chunk in doc.noun_chunks:\n",
        "  print(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3BQODO0R2_8",
        "outputId": "64437cf9-4bd9-424b-eadd-cf06126a3368"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Lusitania\n",
            "Jenny\n",
            "the US coast\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "extracting NPs"
      ],
      "metadata": {
        "id": "3zBpFicfSEeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "input_text = \"The Lusitania had been struck and was sinking rapidly; Jenny runaway and started swimming towards the US coast\"\n",
        "doc = nlp(input_text)\n",
        "for chunk in doc.noun_chunks:\n",
        "  print(chunk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yimnSfVXR5NT",
        "outputId": "ee5ae6b2-22f2-4f67-f616-34e077fb1df6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Lusitania\n",
            "Jenny\n",
            "the US coast\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "extracting VPs"
      ],
      "metadata": {
        "id": "gvQV6A7JS6wI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install textacy\n",
        "import textacy\n",
        "text = \"The Lusitania had been struck and was sinking rapidly; Jenny runaway and started swimming towards the US coast.\"\n",
        "patterns = [{\"POS\":\"AUX\"},{\"POS\":\"VERB\"}]\n",
        "doc = textacy.make_spacy_doc(text,lang=\"en_core_web_sm\")\n",
        "verb_phrases = textacy.extract.token_matches(doc,patterns=patterns)\n",
        "for chunk in verb_phrases:\n",
        "  print(chunk.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUWNxe6tS3um",
        "outputId": "abf4218c-f7cc-4b69-e14f-64f02f241d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting textacy\n",
            "  Downloading textacy-0.13.0-py3-none-any.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (5.3.3)\n",
            "Requirement already satisfied: catalogue~=2.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (2.0.10)\n",
            "Collecting cytoolz>=0.10.1 (from textacy)\n",
            "  Downloading cytoolz-0.12.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting floret~=0.10.0 (from textacy)\n",
            "  Downloading floret-0.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.4/320.4 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jellyfish>=0.8.0 (from textacy)\n",
            "  Downloading jellyfish-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.3.2)\n",
            "Requirement already satisfied: networkx>=2.7 in /usr/local/lib/python3.10/dist-packages (from textacy) (3.2.1)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.25.2)\n",
            "Collecting pyphen>=0.10.0 (from textacy)\n",
            "  Downloading pyphen-0.14.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (1.2.2)\n",
            "Requirement already satisfied: spacy~=3.0 in /usr/local/lib/python3.10/dist-packages (from textacy) (3.7.4)\n",
            "Requirement already satisfied: tqdm>=4.19.6 in /usr/local/lib/python3.10/dist-packages (from textacy) (4.66.2)\n",
            "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from cytoolz>=0.10.1->textacy) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->textacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->textacy) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->textacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.10.0->textacy) (2024.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->textacy) (3.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (2.4.8)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (6.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy~=3.0->textacy) (3.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy~=3.0->textacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy~=3.0->textacy) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy~=3.0->textacy) (4.10.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy~=3.0->textacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy~=3.0->textacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy~=3.0->textacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy~=3.0->textacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy~=3.0->textacy) (2.1.5)\n",
            "Installing collected packages: pyphen, jellyfish, floret, cytoolz, textacy\n",
            "Successfully installed cytoolz-0.12.3 floret-0.10.5 jellyfish-1.0.3 pyphen-0.14.0 textacy-0.13.0\n",
            "been struck\n",
            "was sinking\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Named-Entity Recognition"
      ],
      "metadata": {
        "id": "R6QFvokdTZI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "text = \"The Lusitania had been struck and was sinking rapidly; Jenny runaway and started swimming towards the US coast.\"\n",
        "doc = nlp(text)\n",
        "for ent in doc.ents:\n",
        "  print(f\"{ent.text:10}{ent.start_char:10}{ent.end_char:10} {ent.label_:10} {spacy.explain(ent.label_):10}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFyu_miDTVJ8",
        "outputId": "c42c54b0-c3d9-49a4-9bb8-a825a3e10f40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jenny             55        60 PERSON     People, including fictional\n",
            "US               102       104 GPE        Countries, cities, states\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "using spaCy write a function that returns the list of the word tokens contained in\n",
        "example_string"
      ],
      "metadata": {
        "id": "CFHOKSHZUDkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_of_word_tokens(in_string):\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  doc = nlp(in_string)\n",
        "  return [word.text for word in doc]\n",
        "example_string = \"The Lusitania had been struck and was sinking rapidly; Jenny runaway and started swimming towards the US coast.\"\n",
        "result = list_of_word_tokens(example_string)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bR88NoykT0lU",
        "outputId": "02a0269d-4999-4758-9b7e-bf84bba670d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'Lusitania', 'had', 'been', 'struck', 'and', 'was', 'sinking', 'rapidly', ';', 'Jenny', 'runaway', 'and', 'started', 'swimming', 'towards', 'the', 'US', 'coast', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "def tokenize_string_with_spacy(input_string):\n",
        "    # Load the English language model in spaCy\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    # Process the input string with spaCy\n",
        "    doc = nlp(input_string)\n",
        "\n",
        "    # Extract tokens from the processed document\n",
        "    tokens = [token.text for token in doc]\n",
        "\n",
        "    return tokens\n",
        "\n",
        "example_string = \"The Lusitania had been struck and was sinking rapidly; Jenny runaway and started swimming towards the US coast.\"\n",
        "print(tokenize_string_with_spacy(example_string))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uT0mQ316U9i0",
        "outputId": "7fe50c86-59fd-4877-f4d6-7c1ae12b07cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'Lusitania', 'had', 'been', 'struck', 'and', 'was', 'sinking', 'rapidly', ';', 'Jenny', 'runaway', 'and', 'started', 'swimming', 'towards', 'the', 'US', 'coast', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "using spaCy write a function that returns the list of the sentences contained in\n",
        "example_string"
      ],
      "metadata": {
        "id": "NKloVyivRWM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "def tokenize_string(input_string):\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  doc = nlp(input_string)\n",
        "  print(doc.sents)\n",
        "  sentences = [sent.text for sent in doc.sents]\n",
        "  return sentences\n",
        "\n",
        "example_string = \"The Lusitania had been struck and was sinking rapidly; Jenny runaway and started swimming towards the US coast.\"\n",
        "print(tokenize_string(example_string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN8r7llUVRXu",
        "outputId": "75a89b06-f17e-4656-9859-5e142f2aa2de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<generator object at 0x7b675ea4f9c0>\n",
            "['The Lusitania had been struck and was sinking rapidly; Jenny runaway and started swimming towards the US coast.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "using spaCy write a function that returns the list of the (word) tokens that appear\n",
        "more than once in example_string"
      ],
      "metadata": {
        "id": "Ht2rlbUvTC40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "def tokenize_string(input_string):\n",
        "  nlp=spacy.load(\"en_core_web_sm\")\n",
        "  doc = nlp(input_string)\n",
        "  tokens=[token.text for token in doc]\n",
        "  number_of_appearances = Counter(tokens)\n",
        "  duplicates = [token for token,count in number_of_appearances.items() if count>1]\n",
        "  return duplicates\n",
        "example_string = \"The Lusitania had been struck and was sinking rapidly; Jenny runaway and started swimming towards the US coast.\"\n",
        "print(tokenize_string(example_string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mh6TP90SeOj",
        "outputId": "ecf28fbe-1750-4950-dfa2-c98d508950a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['and']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "using spaCy write a function that returns a dictionary containing, for each token in\n",
        "example_string, the number of times that token appears in example_string."
      ],
      "metadata": {
        "id": "1LYGGk1fWe5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "def tokenize_strings(input_string):\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  doc = nlp(input_string)\n",
        "  tokens = [token.text for token in doc]\n",
        "  dictionary_containing = Counter(tokens)\n",
        "  return dictionary_containing\n",
        "example_string = \"The Lusitania had been struck and was sinking rapidly; Jenny runaway and started swimming towards the US coast.\"\n",
        "print(tokenize_strings(example_string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW7K2owBWeW3",
        "outputId": "27f78899-c40f-4f4b-ad98-24fb62b3e365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'and': 2, 'The': 1, 'Lusitania': 1, 'had': 1, 'been': 1, 'struck': 1, 'was': 1, 'sinking': 1, 'rapidly': 1, ';': 1, 'Jenny': 1, 'runaway': 1, 'started': 1, 'swimming': 1, 'towards': 1, 'the': 1, 'US': 1, 'coast': 1, '.': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "using spaCy adapt the previous code snippet to handle an input in Italian (in the\n",
        "example we have a plain translation of the text above): what needs to be updated\n",
        "and what can be kept unchanged?"
      ],
      "metadata": {
        "id": "pKFgXtDMYMoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "\n",
        "def count_tokens_with_spacy(input_string):\n",
        "    # Load the Italian language model in spaCy\n",
        "    nlp = spacy.load(\"it_core_news_sm\")\n",
        "\n",
        "    # Process the input string with spaCy\n",
        "    doc = nlp(input_string)\n",
        "\n",
        "    # Extract tokens from the processed document\n",
        "    tokens = [token.text for token in doc]\n",
        "\n",
        "    # Count the occurrences of each token\n",
        "    token_counts = Counter(tokens)\n",
        "\n",
        "    return token_counts\n",
        "\n",
        "example_string = \"Il Lusitania era stato colpito e stava affondando rapidamente; Jenny scappò e iniziò a nuotare verso la costa degli Stati Uniti.\"\n",
        "print(count_tokens_with_spacy(example_string))\n"
      ],
      "metadata": {
        "id": "RlUKD4m5YamN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "using spaCy write a function that takes an input string and returns only verbs\n",
        "therein"
      ],
      "metadata": {
        "id": "XkbO6kBhYgSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "def only_verbs(input_string):\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  doc = nlp(input_string)\n",
        "  tokens = [token.text for token in doc if token.pos_=='VERB']\n",
        "  return tokens\n",
        "example_string = \"The Lusitania had been struck and was sinking rapidly; Jenny runaway and started swimming towards the US coast.\"\n",
        "print(only_verbs(example_string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjW34rNHYgvl",
        "outputId": "c1575854-ef63-4782-ab39-c9cc33e4f017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['struck', 'sinking', 'started', 'swimming']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "using spaCy write a function that takes an input string and returns only persons\n",
        "therein; test it on the example_string"
      ],
      "metadata": {
        "id": "tPgYJqMXbWom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from collections import Counter\n",
        "def only_verbs(input_string):\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  doc = nlp(input_string)\n",
        "  tokens = [token.text for token in doc if token.pos_=='PROPN']\n",
        "  return tokens\n",
        "example_string = \"The Lusitania had been struck and was sinking rapidly; Jenny runaway and started swimming towards the US coast.\"\n",
        "print(only_verbs(example_string))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFeOvLBPbTHX",
        "outputId": "cff042d1-cc13-44a2-b2e5-0a72852ccd7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Lusitania', 'Jenny', 'US']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "def extract_persons_with_spacy(input_string):\n",
        "    # Load the English language model in spaCy\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    # Process the input string with spaCy\n",
        "    doc = nlp(input_string)\n",
        "\n",
        "    # Extract persons from the processed document\n",
        "    persons = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
        "\n",
        "    return persons\n",
        "\n",
        "# Example usage:\n",
        "example_string = \"The Lusitania had been struck and was sinking rapidly; Jenny runaway and started swimming towards the US coast.\"\n",
        "persons = extract_persons_with_spacy(example_string)\n",
        "print(persons)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gn2M4cHiccef",
        "outputId": "eb7af090-c615-445b-f2c1-9bd34cc68304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Jenny']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('gutenberg')\n",
        "nltk.corpus.gutenberg.fileids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW9Md3wLc1Ne",
        "outputId": "6eaf30a8-4b20-48a2-8a9f-ba4e03fcddf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'bible-kjv.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "let us plot the first line in each such file"
      ],
      "metadata": {
        "id": "iG7NC3ZVeoKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "from nltk.corpus import gutenberg\n",
        "for fileid in gutenberg.fileids():\n",
        "  print(f\"{gutenberg.sents(fileid)[:1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xhL5HWSenRR",
        "outputId": "4e840e18-4237-415f-ad66-b295a3f97827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['[', 'Emma', 'by', 'Jane', 'Austen', '1816', ']']]\n",
            "[['[', 'Persuasion', 'by', 'Jane', 'Austen', '1818', ']']]\n",
            "[['[', 'Sense', 'and', 'Sensibility', 'by', 'Jane', 'Austen', '1811', ']']]\n",
            "[['[', 'The', 'King', 'James', 'Bible', ']']]\n",
            "[['[', 'Poems', 'by', 'William', 'Blake', '1789', ']']]\n",
            "[['[', 'Stories', 'to', 'Tell', 'to', 'Children', 'by', 'Sara', 'Cone', 'Bryant', '1918', ']']]\n",
            "[['[', 'The', 'Adventures', 'of', 'Buster', 'Bear', 'by', 'Thornton', 'W', '.', 'Burgess', '1920', ']']]\n",
            "[['[', 'Alice', \"'\", 's', 'Adventures', 'in', 'Wonderland', 'by', 'Lewis', 'Carroll', '1865', ']']]\n",
            "[['[', 'The', 'Ball', 'and', 'The', 'Cross', 'by', 'G', '.', 'K', '.', 'Chesterton', '1909', ']']]\n",
            "[['[', 'The', 'Wisdom', 'of', 'Father', 'Brown', 'by', 'G', '.', 'K', '.', 'Chesterton', '1914', ']']]\n",
            "[['[', 'The', 'Man', 'Who', 'Was', 'Thursday', 'by', 'G', '.', 'K', '.', 'Chesterton', '1908', ']']]\n",
            "[['[', 'The', 'Parent', \"'\", 's', 'Assistant', ',', 'by', 'Maria', 'Edgeworth', ']']]\n",
            "[['[', 'Moby', 'Dick', 'by', 'Herman', 'Melville', '1851', ']']]\n",
            "[['[', 'Paradise', 'Lost', 'by', 'John', 'Milton', '1667', ']']]\n",
            "[['[', 'The', 'Tragedie', 'of', 'Julius', 'Caesar', 'by', 'William', 'Shakespeare', '1599', ']']]\n",
            "[['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', 'William', 'Shakespeare', '1599', ']']]\n",
            "[['[', 'The', 'Tragedie', 'of', 'Macbeth', 'by', 'William', 'Shakespeare', '1603', ']']]\n",
            "[['[', 'Leaves', 'of', 'Grass', 'by', 'Walt', 'Whitman', '1855', ']']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "getting chars, words and sentences"
      ],
      "metadata": {
        "id": "EQz6IUCJfUg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import gutenberg\n",
        "for fileid in gutenberg.fileids():\n",
        "  num_chars = len(gutenberg.raw(fileid))\n",
        "  num_words=len(gutenberg.words(fileid))\n",
        "  num_sents = len(gutenberg.sents(fileid))\n",
        "  print(f\"{fileid:>30};num_chars:{num_chars:10};num_words:{num_words:10};num_sents:{num_sents:10}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eL8pFI1QeVfY",
        "outputId": "52a218c1-eadc-42a0-ac11-82b97c885787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               austen-emma.txt;num_chars:    887071;num_words:    192427;num_sents:      7752\n",
            "         austen-persuasion.txt;num_chars:    466292;num_words:     98171;num_sents:      3747\n",
            "              austen-sense.txt;num_chars:    673022;num_words:    141576;num_sents:      4999\n",
            "                 bible-kjv.txt;num_chars:   4332554;num_words:   1010654;num_sents:     30103\n",
            "               blake-poems.txt;num_chars:     38153;num_words:      8354;num_sents:       438\n",
            "            bryant-stories.txt;num_chars:    249439;num_words:     55563;num_sents:      2863\n",
            "       burgess-busterbrown.txt;num_chars:     84663;num_words:     18963;num_sents:      1054\n",
            "             carroll-alice.txt;num_chars:    144395;num_words:     34110;num_sents:      1703\n",
            "           chesterton-ball.txt;num_chars:    457450;num_words:     96996;num_sents:      4779\n",
            "          chesterton-brown.txt;num_chars:    406629;num_words:     86063;num_sents:      3806\n",
            "       chesterton-thursday.txt;num_chars:    320525;num_words:     69213;num_sents:      3742\n",
            "         edgeworth-parents.txt;num_chars:    935158;num_words:    210663;num_sents:     10230\n",
            "        melville-moby_dick.txt;num_chars:   1242990;num_words:    260819;num_sents:     10059\n",
            "           milton-paradise.txt;num_chars:    468220;num_words:     96825;num_sents:      1851\n",
            "        shakespeare-caesar.txt;num_chars:    112310;num_words:     25833;num_sents:      2163\n",
            "        shakespeare-hamlet.txt;num_chars:    162881;num_words:     37360;num_sents:      3106\n",
            "       shakespeare-macbeth.txt;num_chars:    100351;num_words:     23140;num_sents:      1907\n",
            "            whitman-leaves.txt;num_chars:    711215;num_words:    154883;num_sents:      4250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that takes two arguments (a Gutenberg fileid and a token)\n",
        "and prints how many times the given token occurs in the book identified by\n",
        "the fileid. your output should help answering questions such as:\n",
        "- how many times does the word 'Rabbit' occur in Alice's Adventures in\n",
        "Wonderland?\n",
        "- and what about the word 'whale' in Moby Dick?\n",
        "- and 'Ophelia' in The Tragedie of Hamlet?\n"
      ],
      "metadata": {
        "id": "uxUwYE9yjhi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "def count_token_in_book(fileid, token):\n",
        "    # Load the Gutenberg corpus\n",
        "    nltk.download('gutenberg')\n",
        "    nltk.download('punkt')\n",
        "\n",
        "    # Get the words from the specified book\n",
        "    words = nltk.corpus.gutenberg.words(fileid)\n",
        "\n",
        "    # Count occurrences of the token\n",
        "    token_count = words.count(token)\n",
        "\n",
        "    return token_count\n",
        "\n",
        "# Example usage:\n",
        "print(\"Occurrences of 'Rabbit' in Alice's Adventures in Wonderland:\",\n",
        "      count_token_in_book('carroll-alice.txt', 'Rabbit'))\n",
        "print(\"Occurrences of 'whale' in Moby Dick:\",\n",
        "      count_token_in_book('melville-moby_dick.txt', 'whale'))\n",
        "print(\"Occurrences of 'Ophelia' in The Tragedie of Hamlet:\",\n",
        "      count_token_in_book('shakespeare-hamlet.txt', 'Ophelia'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UKRJl6Nhnhx",
        "outputId": "a013fa3b-2849-4836-c076-1281b24d97db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Occurrences of 'Rabbit' in Alice's Adventures in Wonderland: 45\n",
            "Occurrences of 'whale' in Moby Dick: 906\n",
            "Occurrences of 'Ophelia' in The Tragedie of Hamlet: 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that considers Shakespeare's work (that is, items with fields\n",
        "'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt')\n",
        "and for each of these extracts the 10 most frequent persons\n",
        "- if in the step before you used NLTK to extract NERs, then re-write your function\n",
        "by employing spaCy, and viceversa\n",
        "- add an argument to decide at run-time whether spaCy or NLTK should be\n",
        "used. that is, you should end up with only one function able to decide on\n",
        "whether to use NLTK or spaCy based on your invocation"
      ],
      "metadata": {
        "id": "hJUlayntlN1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import spacy\n",
        "from collections import Counter\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "def extract_persons(text, method='nltk'):\n",
        "    if method == 'nltk':\n",
        "        return extract_persons_with_nltk(text)\n",
        "    elif method == 'spacy':\n",
        "        return extract_persons_with_spacy(text)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid method. Choose 'nltk' or 'spacy'.\")\n",
        "\n",
        "def extract_persons_with_nltk(text):\n",
        "    # Tokenize the text\n",
        "    words = nltk.word_tokenize(text)\n",
        "\n",
        "    # Perform part-of-speech tagging\n",
        "    tagged_words = nltk.pos_tag(words)\n",
        "\n",
        "    # Perform named entity recognition\n",
        "    named_entities = nltk.ne_chunk(tagged_words)\n",
        "\n",
        "    # Extract persons\n",
        "    persons = []\n",
        "    for entity in named_entities:\n",
        "        if isinstance(entity, nltk.tree.Tree) and entity.label() == 'PERSON':\n",
        "            persons.extend([leaf[0] for leaf in entity])\n",
        "\n",
        "    return persons\n",
        "\n",
        "def extract_persons_with_spacy(text):\n",
        "    # Load the English language model in spaCy\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "    # Process the input text with spaCy\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Extract persons from the processed document\n",
        "    persons = [ent.text for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
        "\n",
        "    return persons\n",
        "\n",
        "def top_10_persons_in_shakespeare(method='nltk'):\n",
        "    shakespeare_files = ['shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt']\n",
        "    top_persons = Counter()\n",
        "\n",
        "    for file in shakespeare_files:\n",
        "        with open(nltk.data.find(f'corpora/gutenberg/{file}'), 'r', encoding='latin1') as f:  # Specify encoding\n",
        "            text = f.read()\n",
        "            persons = extract_persons(text, method)\n",
        "            top_persons.update(persons)\n",
        "\n",
        "    return top_persons.most_common(10)\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "print(\"Top 10 persons in Shakespeare's works using NLTK:\")\n",
        "print(top_10_persons_in_shakespeare('nltk'))\n",
        "\n",
        "print(\"\\nTop 10 persons in Shakespeare's works using spaCy:\")\n",
        "print(top_10_persons_in_shakespeare('spacy'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kUbJelijcXR",
        "outputId": "539cf2d7-4de1-41fe-87c2-cbb681b2b9e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 persons in Shakespeare's works using NLTK:\n",
            "[('Enter', 159), ('Caesar', 137), ('Brutus', 104), ('Cassius', 80), ('Exeunt', 73), ('Macb', 73), ('Bru', 72), ('Sir', 70), ('Which', 67), ('Antony', 66)]\n",
            "\n",
            "Top 10 persons in Shakespeare's works using spaCy:\n",
            "[('Brutus', 100), ('Ile', 49), ('Heauen', 39), ('Laer', 37), ('Thou', 35), ('Tis', 28), ('Shall', 21), ('Mal', 21), ('Loue', 20), ('Giue', 20)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Book:\n",
        "  def __init__(self, fileid, title='', author='', pub_year=''):\n",
        "    \"\"\" instance fields are defined here \"\"\"\n",
        "    self.fileid = fileid\n",
        "    self.set_text() # write the book text into the text field\n",
        "    self.title = title\n",
        "    self.author = author\n",
        "    self.pub_year = pub_year\n",
        "\n",
        "    self.parse_first_line()\n",
        "\n",
        "\n",
        "  def retrieve_text(self):\n",
        "    \"\"\" based on the given fileid, this method downloads the text\n",
        "      and returns a string\"\"\"\n",
        "    words = gutenberg.words(self.fileid)\n",
        "    return \" \".join(words)\n",
        "\n",
        "  def set_text(self):\n",
        "    \"\"\"  stores the text within the object\"\"\"\n",
        "    self.text = self.retrieve_text()\n",
        "    # print(f'[LOG-set_text] written text instance field')\n",
        "\n",
        "  def get_text(self):\n",
        "    \"\"\" to get the text stored within the object\"\"\"\n",
        "    return self.text\n",
        "\n",
        "  # =========== parse author, title and year =============\n",
        "  def parse_first_line(self):\n",
        "    # 'Emma', 'by', 'Jane', 'Austen', '1816', ']']]\n",
        "    # [['[', 'The', 'Adventures', 'of', 'Buster', 'Bear', 'by', 'Thornton', 'W', '.', 'Burgess', '1920', ']']]\n",
        "\n",
        "    # [['[', 'The', 'Tragedie', 'of', 'Julius', 'Caesar', 'by', 'William', 'Shakespeare', '1599', ']']]\n",
        "    # [['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', 'William', 'Shakespeare', '1599', ']']]\n",
        "    # [['[', 'The', 'Tragedie', 'of', 'Macbeth', 'by', 'William', 'Shakespeare', '1603', ']']]\n",
        "    first_line = gutenberg.sents(self.fileid)[:1][0]\n",
        "    first_line.remove('[')\n",
        "    first_line.remove(']')\n",
        "\n",
        "    idx = first_line.index('by')\n",
        "    title = ' '.join(first_line[:idx])\n",
        "    self.set_title(title.strip())\n",
        "\n",
        "    pub_year = first_line.pop()\n",
        "    self.set_pub_year(pub_year.strip())\n",
        "\n",
        "    author = ' '.join(first_line[idx+1:])\n",
        "    self.set_author(author.strip())\n",
        "\n",
        "\n",
        "  def set_author(self, author):\n",
        "    self.author = author\n",
        "\n",
        "  def get_author(self):\n",
        "    return self.author\n",
        "\n",
        "\n",
        "  def set_title(self, title):\n",
        "    self.title = title\n",
        "\n",
        "  def get_title(self):\n",
        "    return self.title\n",
        "\n",
        "\n",
        "  def set_pub_year(self, pub_year):\n",
        "    self.pub_year = pub_year\n",
        "\n",
        "  def get_pub_year(self):\n",
        "    return self.pub_year\n",
        "\n",
        "\n",
        "  def write_text_to_file(self):\n",
        "    \"\"\"\n",
        "      write to a file (whose name must be equal to fileid) the\n",
        "      content of the book (book_text), along with the optional\n",
        "      information on author and title\n",
        "    \"\"\"\n",
        "    with open (self.fileid, \"w\") as out_file:\n",
        "      out_file.write(self.get_text())\n",
        "    out_file.close()\n",
        "    print(f'[LOG-write_text_to_file] write to file completed')\n",
        "\n",
        "\n",
        "  def __str__(self):\n",
        "    return f'\\nfileid: {self.fileid:>40}\\nauthor:{self.author:>41}\\ntitle:{self.title:>42}\\npub_year:{self.pub_year:>39}'\n"
      ],
      "metadata": {
        "id": "NXPFFrLjkarq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Book:\n",
        "  def __init__(self, fileid, title='', author='', pub_year=''):\n",
        "    \"\"\" instance fields are defined here \"\"\"\n",
        "    self.fileid = fileid\n",
        "    self.set_text() # write the book text into the text field\n",
        "    self.title = title\n",
        "    self.author = author\n",
        "    self.pub_year = pub_year\n",
        "\n",
        "    self.parse_first_line()\n",
        "\n",
        "\n",
        "  def retrieve_text(self):\n",
        "    \"\"\" based on the given fileid, this method downloads the text\n",
        "      and returns a string\"\"\"\n",
        "    words = gutenberg.words(self.fileid)\n",
        "    return \" \".join(words)\n",
        "\n",
        "  def set_text(self):\n",
        "    \"\"\"  stores the text within the object\"\"\"\n",
        "    self.text = self.retrieve_text()\n",
        "    # print(f'[LOG-set_text] written text instance field')\n",
        "\n",
        "  def get_text(self):\n",
        "    \"\"\" to get the text stored within the object\"\"\"\n",
        "    return self.text\n",
        "\n",
        "  # =========== parse author, title and year =============\n",
        "  def parse_first_line(self):\n",
        "    # 'Emma', 'by', 'Jane', 'Austen', '1816', ']']]\n",
        "    # [['[', 'The', 'Adventures', 'of', 'Buster', 'Bear', 'by', 'Thornton', 'W', '.', 'Burgess', '1920', ']']]\n",
        "\n",
        "    # [['[', 'The', 'Tragedie', 'of', 'Julius', 'Caesar', 'by', 'William', 'Shakespeare', '1599', ']']]\n",
        "    # [['[', 'The', 'Tragedie', 'of', 'Hamlet', 'by', 'William', 'Shakespeare', '1599', ']']]\n",
        "    # [['[', 'The', 'Tragedie', 'of', 'Macbeth', 'by', 'William', 'Shakespeare', '1603', ']']]\n",
        "    first_line = gutenberg.sents(self.fileid)[:1][0]\n",
        "    first_line.remove('[')\n",
        "    first_line.remove(']')\n",
        "\n",
        "    idx = first_line.index('by')\n",
        "    title = ' '.join(first_line[:idx])\n",
        "    self.set_title(title.strip())\n",
        "\n",
        "    pub_year = first_line.pop()\n",
        "    self.set_pub_year(pub_year.strip())\n",
        "\n",
        "    author = ' '.join(first_line[idx+1:])\n",
        "    self.set_author(author.strip())\n",
        "\n",
        "\n",
        "  def set_author(self, author):\n",
        "    self.author = author\n",
        "\n",
        "  def get_author(self):\n",
        "    return self.author\n",
        "\n",
        "\n",
        "  def set_title(self, title):\n",
        "    self.title = title\n",
        "\n",
        "  def get_title(self):\n",
        "    return self.title\n",
        "\n",
        "\n",
        "  def set_pub_year(self, pub_year):\n",
        "    self.pub_year = pub_year\n",
        "\n",
        "  def get_pub_year(self):\n",
        "    return self.pub_year\n",
        "\n",
        "\n",
        "  def write_text_to_file(self):\n",
        "    \"\"\"\n",
        "      write to a file (whose name must be equal to fileid) the\n",
        "      content of the book (book_text), along with the optional\n",
        "      information on author and title\n",
        "    \"\"\"\n",
        "    with open (self.fileid, \"w\") as out_file:\n",
        "      out_file.write(self.get_text())\n",
        "    out_file.close()\n",
        "    print(f'[LOG-write_text_to_file] write to file completed')\n",
        "\n",
        "\n",
        "  def __str__(self):\n",
        "    return f'\\nfileid: {self.fileid:>40}\\nauthor:{self.author:>41}\\ntitle:{self.title:>42}\\npub_year:{self.pub_year:>39}'\n"
      ],
      "metadata": {
        "id": "wFYDSv31lch6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " test the class Book (this step involves creating an instance...) by printing the\n",
        "string containing the information in the fields fileid, title, author,\n",
        "pub_year (hint: this should be done by invoicing the __str__() method)\n",
        "for the following plays by Shakespeare: shakespeare-caesar.txt, shakespearehamlet.txt, shakespeare-macbeth.txt."
      ],
      "metadata": {
        "id": "ExxF5Y1tmKO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "caesar_book = Book('shakespeare-caesar.txt')\n",
        "print(caesar_book)\n",
        "# caesar_book.write_text_to_file()\n",
        "# caesar_book.parse_first_line()\n",
        "\n",
        "hamlet_book = Book('shakespeare-hamlet.txt')\n",
        "print(hamlet_book)\n",
        "\n",
        "macbeth_book = Book('shakespeare-macbeth.txt')\n",
        "print(macbeth_book)\n",
        "\n",
        "# shakespeare-caesar.txt\n",
        "# shakespeare-hamlet.txt\n",
        "# shakespeare-macbeth.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLoWHMgQlmy6",
        "outputId": "f236d55e-3a37-49dd-dc70-f9c1adb71b68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: None, Title: None, Publication Year: None\n",
            "Author: None, Title: None, Publication Year: None\n",
            "Author: None, Title: None, Publication Year: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "class Book:\n",
        "    def __init__(self, fileid):\n",
        "        self.fileid = fileid\n",
        "        self.author = None\n",
        "        self.title = None\n",
        "        self.pub_year = None\n",
        "        self.text = None\n",
        "\n",
        "    def retrieve_text(self):\n",
        "        # Download the text of the book\n",
        "        nltk.download('gutenberg')\n",
        "        self.text = nltk.corpus.gutenberg.raw(self.fileid)\n",
        "        return self.text\n",
        "\n",
        "    def parse_first_line(self):\n",
        "    # Parse the first line to extract author, title, and publication year\n",
        "      first_line = self.text.split('\\n')[0].strip()\n",
        "      parts = first_line.split(',')\n",
        "\n",
        "      if len(parts) >= 3:\n",
        "        self.author = parts[0].strip()\n",
        "        self.title = parts[1].strip()\n",
        "        self.pub_year = parts[2].strip()\n",
        "      elif len(parts) == 2:\n",
        "        self.author = parts[0].strip()\n",
        "        self.title = parts[1].strip()\n",
        "        self.pub_year = None\n",
        "      else:\n",
        "        self.author = None\n",
        "        self.title = None\n",
        "        self.pub_year = None\n",
        "\n",
        "\n",
        "    def get_author(self):\n",
        "        return self.author\n",
        "\n",
        "    def set_author(self, author):\n",
        "        self.author = author\n",
        "\n",
        "    def get_title(self):\n",
        "        return self.title\n",
        "\n",
        "    def set_title(self, title):\n",
        "        self.title = title\n",
        "\n",
        "    def get_pub_year(self):\n",
        "        return self.pub_year\n",
        "\n",
        "    def set_pub_year(self, pub_year):\n",
        "        self.pub_year = pub_year\n",
        "\n",
        "    def write_to_file(self):\n",
        "        # Write the book content along with author and title information to a file\n",
        "        filename = f\"{self.fileid}.txt\"\n",
        "        with open(filename, 'w') as f:\n",
        "            f.write(f\"Author: {self.author}\\n\")\n",
        "            f.write(f\"Title: {self.title}\\n\")\n",
        "            f.write(self.text)\n",
        "\n",
        "    def __str__(self):\n",
        "        return f\"Author: {self.author}, Title: {self.title}, Publication Year: {self.pub_year}\"\n",
        "\n",
        "# Example usage:\n",
        "book = Book('shakespeare-hamlet.txt')\n",
        "book.retrieve_text()\n",
        "book.parse_first_line()\n",
        "print(book)\n",
        "book.write_to_file()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWAH3rV5lsSy",
        "outputId": "2d9346b4-0621-4b55-a437-101a7f27cad7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: None, Title: None, Publication Year: None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Addition and subtraction on vectors"
      ],
      "metadata": {
        "id": "L-8a0vjaBCV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = np.array([3,2])\n",
        "b = np.array([1,2])\n",
        "print(a+b)\n",
        "print(a-b)\n",
        "print(a)\n",
        "print(b)"
      ],
      "metadata": {
        "id": "-NsUDCLQl4M7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00f5cd2e-be30-4989-8606-1b5ca0e7623a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4 4]\n",
            "[2 0]\n",
            "[3 2]\n",
            "[1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scaling on vectors"
      ],
      "metadata": {
        "id": "h2JtXyt3BbOG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = np.array([3,2])\n",
        ".5*a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FVK_ukNBjzb",
        "outputId": "a8d9c845-448a-4426-b8ca-3e560a2ec9f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.5, 1. ])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "vector length or norm"
      ],
      "metadata": {
        "id": "qWKbezWNCjgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a_x = 3\n",
        "a_y = 2\n",
        "print(f\"{np.sqrt(a_x**2+a_y**2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhF64U1cBwmL",
        "outputId": "523c2a90-2126-4124-ea5c-983e3c40c8ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.605551275463989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([3,2])\n",
        "print(f\"np.linalg.norm(a)={np.linalg.norm(a)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUvJnrSYCylE",
        "outputId": "a514c348-4b42-48bb-b7b3-53861ee8b2f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "np.linalg.norm(a)=3.605551275463989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dot product"
      ],
      "metadata": {
        "id": "suTdWFHVD05h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v = np.array([3,2])\n",
        "u = np.array([1,2])\n",
        "print(f\"np.dot(v,u)={np.dot(v,u)}\")\n",
        "print(f\"v@u={v@u}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLdav_p1C_fk",
        "outputId": "1028e013-ad4e-45c4-ee90-ba1447bc9b40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "np.dot(v,u)=7\n",
            "v@u=7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function named vector_addition that accepts two lists\n",
        "representing vectors vector1 and vector2 as input. Ensure that both\n",
        "vectors have the same length. Implement the function to perform\n",
        "element-wise addition of the corresponding elements of the two\n",
        "vectors and return the resulting vector."
      ],
      "metadata": {
        "id": "FxeO7XY-ErZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def vector_addition(vector1,vector2):\n",
        "  if len(vector1) != len(vector2):\n",
        "    raise ValueError(\"length of the vectors should be the same\")\n",
        "  result =[x+y for x,y in zip(vector1,vector2)]\n",
        "  return result\n",
        "vector1 = np.array([1,2,3])\n",
        "vector2 =np.array([4,5,6])\n",
        "result = vector_addition(vector1,vector2)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x0qvXgQEDX9",
        "outputId": "8849bf7d-2f96-4b77-f8b1-aebbb417b66d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 7, 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function that takes in input two lists as vectors and returns as\n",
        "output their dot product (you cannot use library functions from\n",
        "NumPy...); remember that the dot product of two vectors is a number\n",
        "computed through this formula: u⃗⋅v⃗= u1v1 + u2v2"
      ],
      "metadata": {
        "id": "UUUvbV9pKJ_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vector_dot_product(list1,list2):\n",
        "  if len(list1) != len(list2):\n",
        "    raise ValueError(\"Length of the lists should be the same\")\n",
        "  result = sum([x*y for x,y in zip(list1,list2)])\n",
        "  return result\n",
        "list1 = [1,2,3,4,5,6]\n",
        "list2 =[7,8,9,10,11,12]\n",
        "print(vector_dot_product(list1,list2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jymMGucpFFH9",
        "outputId": "a81ae048-bfdc-41e7-fb39-dbaf628ee9ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "transpose matrix"
      ],
      "metadata": {
        "id": "zwJvP_nTS3wE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "in_matrix = np.matrix([[1,2,3],[4,5,6]])\n",
        "transposed = in_matrix.transpose()\n",
        "print(f\"original matrix: \\n{in_matrix}\")\n",
        "print(f\"transposed matrix: \\n{transposed}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzAFZOCaR6Ri",
        "outputId": "9bda0bd6-875a-4485-8f97-0577e194acff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original matrix: \n",
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "transposed matrix: \n",
            "[[1 4]\n",
            " [2 5]\n",
            " [3 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a program to obtain the transpose of the matrix a=[[1,2],\n",
        "[3,4],[5,6]]. Your implementation cannot contain any library\n",
        "function."
      ],
      "metadata": {
        "id": "x0XV_mAOTYBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def transpose_matrix(matrix):\n",
        "    # Get the number of rows and columns in the original matrix\n",
        "    num_rows = len(matrix)\n",
        "    num_cols = len(matrix[0])\n",
        "    print(num_rows)\n",
        "    print(num_cols)\n",
        "    # Create an empty matrix to store the transpose\n",
        "    transpose = []\n",
        "\n",
        "    # Iterate through the columns of the original matrix\n",
        "    for j in range(num_cols):\n",
        "        # Create a new row for each column in the original matrix\n",
        "        new_row = []\n",
        "        # Iterate through the rows of the original matrix\n",
        "        for i in range(num_rows):\n",
        "            # Append the element at position (i, j) to the new row\n",
        "            new_row.append(matrix[i][j])\n",
        "        # Append the new row to the transpose matrix\n",
        "        transpose.append(new_row)\n",
        "\n",
        "    return transpose\n",
        "\n",
        "# Original matrix\n",
        "a = [[1, 2],\n",
        "     [3, 4],\n",
        "     [5, 6]]\n",
        "\n",
        "# Obtain the transpose of the matrix\n",
        "transpose_a = transpose_matrix(a)\n",
        "print(transpose_a)\n",
        "# Print the transpose matrix\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xk32PilkTL7y",
        "outputId": "e18abd52-974d-45a3-bb87-9e49abc3b09c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "2\n",
            "[[1, 3, 5], [2, 4, 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transpose(amatrix):\n",
        "  rows = len(amatrix)\n",
        "  cols = len(amatrix[0])\n",
        "\n",
        "  new_matr = []\n",
        "  for j in range(cols):\n",
        "    l_rows =[amatrix[i][j] for i in range(rows)]\n",
        "    new_matr.append(l_rows)\n",
        "  return new_matr\n",
        "\n",
        "amatrix = [[1,2],[3,4],[5,6]]\n",
        "\n",
        "print(amatrix)\n",
        "print(get_transpose(amatrix))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG1lEGt3VWXq",
        "outputId": "3f225516-db13-4d93-e50b-57153d453f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1, 2], [3, 4], [5, 6]]\n",
            "[[1, 3, 5], [2, 4, 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function to test whether a matrix is symmetric; the function takes as\n",
        "input a matrix (as a plain list), and returns True if the matrix is symmetric, and\n",
        "False otherwise"
      ],
      "metadata": {
        "id": "7pc-xJRNV8p8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_symmetric(matrix):\n",
        "    # Get the number of rows and columns in the matrix\n",
        "    num_rows = len(matrix)\n",
        "    num_cols = len(matrix[0])\n",
        "\n",
        "    # Check if the matrix is square\n",
        "    if num_rows != num_cols:\n",
        "        return False\n",
        "\n",
        "    # Obtain the transpose of the matrix\n",
        "    transpose_matrix = []\n",
        "    for j in range(num_cols):\n",
        "        new_row = []\n",
        "        for i in range(num_rows):\n",
        "            new_row.append(matrix[i][j])\n",
        "        transpose_matrix.append(new_row)\n",
        "\n",
        "    # Check if the matrix is equal to its transpose\n",
        "    for i in range(num_rows):\n",
        "        for j in range(num_cols):\n",
        "            if matrix[i][j] != transpose_matrix[i][j]:\n",
        "                return False\n",
        "\n",
        "    return True\n",
        "\n",
        "# Example usage:\n",
        "matrix1 = [[1, 2, 3],\n",
        "           [2, 4, 5],\n",
        "           [3, 5, 6]]\n",
        "\n",
        "matrix2 = [[1, 2, 3],\n",
        "           [2, 4, 2],\n",
        "           [3, 2, 1]]\n",
        "\n",
        "print(\"Matrix 1 is symmetric:\", is_symmetric(matrix1))\n",
        "print(\"Matrix 2 is symmetric:\", is_symmetric(matrix2))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypxl_z3YiArV",
        "outputId": "9f49692c-ae84-4e85-eb2b-e74fdae6ced6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix 1 is symmetric: True\n",
            "Matrix 2 is symmetric: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that takes in input a matrix (as a plain list) and returns its\n",
        "transpose\n",
        "- check that your function returns the same matrix as the NumPy\n",
        "method transpose()."
      ],
      "metadata": {
        "id": "4E5jFn1fjcuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transpose_list(matrix):\n",
        "  rows = len(matrix)\n",
        "  cols = len(matrix[0])\n",
        "  transpose_matrix = []\n",
        "  for j in range(cols):\n",
        "    rows1 =[]\n",
        "    for i in range(rows):\n",
        "      rows1.append(matrix[i][j])\n",
        "    transpose_matrix.append(rows1)\n",
        "  return transpose_matrix\n",
        "def transpose_numpy(matrix1):\n",
        "  import numpy as np\n",
        "  matrix1 = np.array(matrix1)\n",
        "  transpose = matrix1.transpose().tolist()\n",
        "  return transpose\n",
        "def check(m1,m2):\n",
        "  return m1==m2\n",
        "matrix1 = [[1, 2, 3],\n",
        "           [2, 4, 5],\n",
        "           [3, 5, 6]]\n",
        "m1 = transpose_list(matrix1)\n",
        "m2 = transpose_numpy(matrix1)\n",
        "print(check(m1,m2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "POEnR_NoiHM1",
        "outputId": "4f0a2543-a1a5-427d-e2ea-fec3d22b9172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[1,2,3],\n",
        "              [4,5,6],\n",
        "              [7,8,9]])\n",
        "b = np.array([1,2,3])\n",
        "print(a@b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXaGxMA3l3NI",
        "outputId": "792a1562-9dcc-42e2-93da-70399870fb6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14 32 50]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that takes in input a matrix and a vector (of appropriate size)\n",
        "and returns the result of the matrix-vector product; in other words, reimplement the '@' operator."
      ],
      "metadata": {
        "id": "fVcupu9_oyvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix_vector_product(matrix, vector):\n",
        "    # Get the dimensions of the matrix and vector\n",
        "    num_rows = len(matrix)\n",
        "    num_cols = len(matrix[0])\n",
        "    vector_length = len(vector)\n",
        "\n",
        "    # Check if the number of columns in the matrix matches the length of the vector\n",
        "    if num_cols != vector_length:\n",
        "        raise ValueError(\"Matrix and vector dimensions are not compatible for multiplication\")\n",
        "\n",
        "    # Initialize the result vector\n",
        "    result = [0] * num_rows\n",
        "\n",
        "    # Perform matrix-vector multiplication\n",
        "    for i in range(num_rows):\n",
        "        for j in range(num_cols):\n",
        "            result[i] += matrix[i][j] * vector[j]\n",
        "\n",
        "    return result\n",
        "\n",
        "# Example usage:\n",
        "matrix = [[1, 2, 3],\n",
        "          [4, 5, 6],\n",
        "          [7,8,9]]\n",
        "vector = [1, 2, 3]\n",
        "\n",
        "result = matrix_vector_product(matrix, vector)\n",
        "print(\"Result of matrix-vector product:\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7DmLMUanqqx",
        "outputId": "64918439-3464-4287-ef3f-b32964b25eb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result of matrix-vector product: [14, 32, 50]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function that takes in input a matrix and returns a vector. each\n",
        "element in the vector contains the sum of a matrix row. For example,\n",
        "given the matrix a = [[1,2,3], [4,5,6], [7,8,9]], the function\n",
        "must return the vector [6,15,24].\n",
        "- Modify, if required, former function to make it handle also a vector as\n",
        "its input"
      ],
      "metadata": {
        "id": "wixNYG1BppcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vector(matrix):\n",
        "  sums = []\n",
        "  for row in matrix:\n",
        "    sums.append(sum(row))\n",
        "  return sums\n",
        "matrix = [[1, 2, 3],\n",
        "          [4, 5, 6],\n",
        "          [7,8,9]]\n",
        "print(vector(matrix))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nclN-YJdor-R",
        "outputId": "f1a7ae46-033d-4fc6-e986-b710ad03bb5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6, 15, 24]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Write a function that takes in input a matrix and returns as output a\n",
        "vector containing the sum of its columns"
      ],
      "metadata": {
        "id": "tv_PaGvBwtBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sum_columns(matrix):\n",
        "    num_rows = len(matrix)\n",
        "    num_cols = len(matrix[0]) if matrix else 0\n",
        "\n",
        "    column_sums = [0] * num_cols\n",
        "    print(column_sums)\n",
        "    for i in range(num_rows):\n",
        "        for j in range(num_cols):\n",
        "            column_sums[j] += matrix[i][j]\n",
        "\n",
        "    return column_sums\n",
        "\n",
        "# Example usage:\n",
        "matrix = [\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9]\n",
        "]\n",
        "\n",
        "result = sum_columns(matrix)\n",
        "print(result)  # Output will be [12, 15, 18]\n"
      ],
      "metadata": {
        "id": "HecusglxqVnD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4170cae8-cdf6-4518-a93d-c7d546d2a09b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0]\n",
            "[12, 15, 18]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = np.array([[1,2],\n",
        "              [3,4],\n",
        "              [5,6]])\n",
        "b = np.array([[1,2],[3,4]])\n",
        "print(a@b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1SZiSoMVy1-M",
        "outputId": "c347fb7e-d65e-447c-fd3f-fe0405d58835"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 7 10]\n",
            " [15 22]\n",
            " [23 34]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " write a function that takes in input a matrix and a matrix (of appropriate\n",
        "size) and returns the result of the product"
      ],
      "metadata": {
        "id": "e9IgRrb28Z6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def product_matrix(matrix1,matrix2):\n",
        "  if len(matrix1[0])!=len(matrix2):\n",
        "    raise ValueError(\"Length of col of matrix1 and leng of row of matrix2 should be the same\")\n",
        "  result = [[0] * len(matrix2[0]) for _ in range(len(matrix1))]\n",
        "  for i in range(len(matrix1)):\n",
        "    for j in range(len(matrix2[0])):\n",
        "      for k in range(len(matrix2)):\n",
        "        result[i][j] += matrix1[i][k]*matrix2[k][j]\n",
        "  return result\n",
        "matrix1 = [[ 1, 2],[ 3, 4],[ 5 ,6]]\n",
        "matrix2 = [[ 1, 2],[ 3, 4]]\n",
        "print(product_matrix(matrix1,matrix2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8BcLWH-zbWW",
        "outputId": "592ac9ca-ace2-4984-8a47-4943646bd02d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7, 10], [15, 22], [23, 34]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix_multiply(matrix1, matrix2):\n",
        "    # Check if matrices are compatible for multiplication\n",
        "    if len(matrix1[0]) != len(matrix2):\n",
        "        raise ValueError(\"Matrices are not compatible for multiplication\")\n",
        "\n",
        "    # Initialize result matrix with appropriate size\n",
        "    result = [[0] * len(matrix2[0]) for _ in range(len(matrix1))]\n",
        "\n",
        "    # Perform matrix multiplication\n",
        "    for i in range(len(matrix1)):\n",
        "        for j in range(len(matrix2[0])):\n",
        "            for k in range(len(matrix2)):\n",
        "                result[i][j] += matrix1[i][k] * matrix2[k][j]\n",
        "\n",
        "    return result\n",
        "\n",
        "# Example usage:\n",
        "matrix1 = [[ 1, 2],\n",
        "[ 3, 4],\n",
        "[ 5 ,6]]\n",
        "matrix2 = [[ 1, 2],\n",
        "[ 3, 4]]\n",
        "result = matrix_multiply(matrix1, matrix2)\n",
        "for row in result:\n",
        "    print(row)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HsUAP1l6pOO",
        "outputId": "002e8589-60cb-4944-90d5-1d3d55f302e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7, 10]\n",
            "[15, 22]\n",
            "[23, 34]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "introducing PyTorch tensors"
      ],
      "metadata": {
        "id": "BBRuvWyN9rd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "x = torch.arange(6)\n",
        "print(x)\n",
        "print(x.shape)\n",
        "X = torch.arange(6).reshape(3, 2)\n",
        "print(X.shape)\n",
        "print(X)\n",
        "print(X.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_3mUI5E7EF-",
        "outputId": "dab08f8c-df94-4b86-8f1c-2024cf9f480d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5])\n",
            "torch.Size([6])\n",
            "torch.Size([3, 2])\n",
            "tensor([[0, 1],\n",
            "        [2, 3],\n",
            "        [4, 5]])\n",
            "tensor([[0, 2, 4],\n",
            "        [1, 3, 5]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sum and reduction of torch\n"
      ],
      "metadata": {
        "id": "srAT8SmO-MH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
        "B = A.clone() # create a copy of A\n",
        "print(A)\n",
        "print(A.shape, A.sum())\n",
        "# To sum over all elements along the rows (axis 0), we specify axis=0 in sum\n",
        "print(A.shape, A.sum(axis=0).shape)\n",
        "print(A.sum(axis=0))\n",
        "# with axis=1 we reduce the column dimension (axis 1)\n",
        "# by summing up elements of all the columns.\n",
        "print(A.shape, A.sum(axis=1).shape)\n",
        "print(A.sum(axis=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USx7cMY99uPA",
        "outputId": "1f1f740b-1591-4e56-a29b-bef02306f190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 1., 2.],\n",
            "        [3., 4., 5.]])\n",
            "torch.Size([2, 3]) tensor(15.)\n",
            "torch.Size([2, 3]) torch.Size([3])\n",
            "tensor([3., 5., 7.])\n",
            "torch.Size([2, 3]) torch.Size([2])\n",
            "tensor([ 3., 12.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dot product"
      ],
      "metadata": {
        "id": "7SLrBVgm-cnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(6, dtype=torch.int32)\n",
        "b = a.clone()\n",
        "a, b, torch.dot(a,b), torch.sum(a*b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIRi491g-PVA",
        "outputId": "140faac2-6f4e-4cc4-8902-cb91d396db8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0, 1, 2, 3, 4, 5], dtype=torch.int32),\n",
              " tensor([0, 1, 2, 3, 4, 5], dtype=torch.int32),\n",
              " tensor(55, dtype=torch.int32),\n",
              " tensor(55))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "matrix-vector product"
      ],
      "metadata": {
        "id": "BDAHdWbl-k5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A_mat = torch.arange(6, dtype=torch.int32).reshape(3,2)\n",
        "b_vec = torch.arange(2, dtype=torch.int32)\n",
        "torch.mv(A_mat,b_vec), A_mat@b_vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8cT2HzK-emv",
        "outputId": "94bad7a2-aba2-48b2-9d5a-1301fccbaa27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 3, 5], dtype=torch.int32), tensor([1, 3, 5], dtype=torch.int32))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "matrix-matrix product"
      ],
      "metadata": {
        "id": "nfZYo3bF-u3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A_mat = torch.arange(6, dtype=torch.int32).reshape(3,2)\n",
        "B_mat = torch.ones(6, dtype=torch.int32).reshape(2,3)\n",
        "torch.mm(A_mat,B_mat), A_mat@B_mat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMhK4KoS-nkA",
        "outputId": "1872191d-8f9f-44fa-de08-2639c5f83ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1, 1, 1],\n",
              "         [5, 5, 5],\n",
              "         [9, 9, 9]], dtype=torch.int32),\n",
              " tensor([[1, 1, 1],\n",
              "         [5, 5, 5],\n",
              "         [9, 9, 9]], dtype=torch.int32))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "you are given the sales data of some store for each branch in the form of matrices, where each row\n",
        "represents a product and each column represents a day. calculate the total sales for each product\n",
        "across all branches over a certain period. the following matrices are given, representing the daily\n",
        "sales for each branch:\n",
        "1. Matrix represents the sales data for Branch A, where each element represents the quantity\n",
        "of product sold on day .\n",
        "2. Matrix represents the sales data for Branch B, where each element represents the quantity\n",
        "of product sold on day .\n",
        "write a Python program using PyTorch tensors to calculate the total sales for each product across all\n",
        "branches. use\n",
        "sales_data_branch_a = torch.tensor([\n",
        "[10, 20, 30],\n",
        "[15, 25, 35],\n",
        "[5, 10, 15]]),\n",
        "sales_data_branch_b = torch.tensor([\n",
        "[25, 15, 10],\n",
        "[20, 10, 5],\n",
        "[30, 20, 15]])"
      ],
      "metadata": {
        "id": "ZSnyRbDVATcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Given sales data for each branch\n",
        "sales_data_branch_a = torch.tensor([\n",
        "    [10, 20, 30],\n",
        "    [15, 25, 35],\n",
        "    [5, 10, 15]\n",
        "])\n",
        "\n",
        "sales_data_branch_b = torch.tensor([\n",
        "    [25, 15, 10],\n",
        "    [20, 10, 5],\n",
        "    [30, 20, 15]\n",
        "])\n",
        "\n",
        "# Calculate total sales across all branches\n",
        "total_sales = sales_data_branch_a + sales_data_branch_b\n",
        "\n",
        "# Print total sales for each product\n",
        "print(\"Total sales for each product across all branches:\")\n",
        "print(total_sales)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYrO9LDq_r9Y",
        "outputId": "2d234243-3a5d-4b2e-dbe1-087ac34e19a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total sales for each product across all branches:\n",
            "tensor([[35, 35, 40],\n",
            "        [35, 35, 40],\n",
            "        [35, 30, 30]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "by exploiting the result of the previous exercise, compute the overall incomes (that is,\n",
        "for all products), and the incomes for each product listed on rows of the\n",
        "sales_data_branch_a and sales_data_branch_b matrices"
      ],
      "metadata": {
        "id": "Wxpgbw96AYYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Given sales data for each branch\n",
        "sales_data_branch_a = torch.tensor([\n",
        "    [10, 20, 30],\n",
        "    [15, 25, 35],\n",
        "    [5, 10, 15]\n",
        "])\n",
        "\n",
        "sales_data_branch_b = torch.tensor([\n",
        "    [25, 15, 10],\n",
        "    [20, 10, 5],\n",
        "    [30, 20, 15]\n",
        "])\n",
        "\n",
        "# Calculate total sales for all products\n",
        "overall_incomes = torch.sum(sales_data_branch_a + sales_data_branch_b)\n",
        "\n",
        "# Calculate total sales for each product\n",
        "incomes_per_product = torch.sum(sales_data_branch_a + sales_data_branch_b, dim=0)\n",
        "\n",
        "# Calculate incomes for each product listed on rows of sales_data_branch_a and sales_data_branch_b\n",
        "incomes_branch_a = torch.sum(sales_data_branch_a, dim=1)\n",
        "incomes_branch_b = torch.sum(sales_data_branch_b, dim=1)\n",
        "\n",
        "# Print results\n",
        "print(\"Overall incomes (total sales for all products):\", overall_incomes.item())\n",
        "print(\"Incomes for each product:\", incomes_per_product.tolist())\n",
        "print(\"Incomes for each product listed on rows of sales_data_branch_a:\", incomes_branch_a.tolist())\n",
        "print(\"Incomes for each product listed on rows of sales_data_branch_b:\", incomes_branch_b.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDZDixq0AOg_",
        "outputId": "d143d89c-b0c3-4598-8b8f-9f68912f841e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall incomes (total sales for all products): 315\n",
            "Incomes for each product: [105, 100, 110]\n",
            "Incomes for each product listed on rows of sales_data_branch_a: [60, 75, 30]\n",
            "Incomes for each product listed on rows of sales_data_branch_b: [50, 35, 65]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "a = np.array([3,2])\n",
        "0.5*a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FDRkmINPAsr3",
        "outputId": "4f542929-3a30-4868-b4c0-cb2c2d43cdad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.5, 1. ])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x =3\n",
        "y = 2\n",
        "print(np.sqrt(x**2+y**2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McjTd4XvA4Yo",
        "outputId": "0f4dbb06-ffaa-48ab-ecb8-64db252838d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.605551275463989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "dot product"
      ],
      "metadata": {
        "id": "g_EcURrNBQf9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u = np.array([3,2])\n",
        "v = np.array([1,2])\n",
        "print(v@u)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq-kH7FCBEhK",
        "outputId": "93576473-5e3f-4290-a59f-8d0870f7f722"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vector_addition(list1,list2):\n",
        "  if len(list1)!=len(list2):\n",
        "    raise ValueError(\"Length should be the same\")\n",
        "  sum_list = zip(list1,list2)\n",
        "  print(sum_list)\n",
        "  sum_final=[x+y for x,y in sum_list]\n",
        "  return sum_final\n",
        "vector1 = [1,2,3]\n",
        "vector2 = [4,5,6]\n",
        "print(vector_addition(vector1,vector2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uMNbLdSQBbxo",
        "outputId": "0893b592-6e46-4738-cfb6-62d3bbdcf10e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<zip object at 0x7dd814f5de80>\n",
            "[5, 7, 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# u*v = u1*v1+u2*v2\n",
        "def dor_product(list1,list2):\n",
        "  dot_product = 0\n",
        "  zip_list = zip(list1,list2)\n",
        "  multiply_list = [x*y for x,y in zip_list]\n",
        "  for i in range(len(multiply_list)):\n",
        "    dot_product += multiply_list[i]\n",
        "  return dot_product\n",
        "vector1 = [1,2,3]\n",
        "vector2 = [4,5,6]\n",
        "print(dor_product(vector1,vector2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqx5rUvlKRBD",
        "outputId": "3a488c55-112c-4ba4-d738-a9fd75e6f610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "in_matrix = np.matrix([[1,2,3],[4,5,6]])\n",
        "transposed = in_matrix.transpose()\n",
        "print(transposed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y79EjIGLxvj",
        "outputId": "eb9704b2-57e6-4e9b-8c84-3fe208433110"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 4]\n",
            " [2 5]\n",
            " [3 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transpose_matrix(matrix):\n",
        "  rows = len(matrix)\n",
        "  cols = len(matrix[0])\n",
        "  result = [[0]*rows for _ in range(cols)]\n",
        "  print(result)\n",
        "  for i in range(rows):\n",
        "    for j in range(cols):\n",
        "      result[j][i]=matrix[i][j]\n",
        "  return result\n",
        "matrix = [[1,2],[3,4],[5,6]]\n",
        "transpose_matrix(matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ypz8ODuHMWn0",
        "outputId": "a91e73cb-c8ca-4dc0-a1e6-fd6a88dba881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 0, 0], [0, 0, 0]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 3, 5], [2, 4, 6]]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function to test whether a matrix is symmetric; the function takes as\n",
        "input a matrix (as a plain list), and returns True if the matrix is symmetric, and\n",
        "False otherwise."
      ],
      "metadata": {
        "id": "TV34abumRRV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def symmetric_matrix(matrix):\n",
        "  rows = len(matrix)\n",
        "  cols = len(matrix[0])\n",
        "  result = [[0]*rows for _ in range(cols)]\n",
        "  for i in range(rows):\n",
        "    for j in range(cols):\n",
        "      result[j][i] = matrix[i][j]\n",
        "  return result\n",
        "def symmetric(matrix1,matrix2):\n",
        "  return matrix1==matrix2\n",
        "matrix1= [\n",
        "    [1, 2, 3],\n",
        "    [2, 4, 5],\n",
        "    [3, 5, 6]\n",
        "]\n",
        "matrix2 = symmetric_matrix(matrix1)\n",
        "print(symmetric(matrix1,matrix2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5Tu9jG0PJVl",
        "outputId": "cc5c19d7-0dd9-4357-be2a-b80845e5a633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transpose(matrix):\n",
        "  rows = len(matrix)\n",
        "  cols = len(matrix[0])\n",
        "  result = [[0]*rows for _ in range(cols)]\n",
        "  for i in range(rows):\n",
        "    for j in range(cols):\n",
        "      result[j][i]=matrix[i][j]\n",
        "  return result\n",
        "def transpose_numpy(matrix):\n",
        "  in_matrix = np.matrix(matrix)\n",
        "  transposed = in_matrix.transpose()\n",
        "  return transposed\n",
        "def check_equal(matrix_transpose1,matrix_transpose2):\n",
        "  return matrix_transpose1 == matrix_transpose2\n",
        "\n",
        "matrix= [[1, 2, 3],[4, 5, 6]]\n",
        "matrix_transpose1 = transpose(matrix)\n",
        "matrix_transpose2 = transpose_numpy(matrix)\n",
        "print(check_equal(matrix_transpose1,matrix_transpose2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LbxiIJLkRFt2",
        "outputId": "07489cc6-4d7d-487e-98c5-febca7bc2e20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ True  True]\n",
            " [ True  True]\n",
            " [ True  True]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transpose_matrix(matrix):\n",
        "    # Get the dimensions of the original matrix\n",
        "    rows = len(matrix)\n",
        "    cols = len(matrix[0])\n",
        "\n",
        "    # Initialize the transpose matrix\n",
        "    transpose = [[0] * rows for _ in range(cols)]\n",
        "\n",
        "    # Iterate over the original matrix and populate the transpose matrix\n",
        "    for i in range(rows):\n",
        "        for j in range(cols):\n",
        "            transpose[j][i] = matrix[i][j]\n",
        "\n",
        "    return transpose\n",
        "\n",
        "# Example usage:\n",
        "matrix = [\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6]\n",
        "]\n",
        "\n",
        "# Get the transpose of the matrix using the custom function\n",
        "transpose_custom = transpose_matrix(matrix)\n",
        "\n",
        "# Print the transpose obtained using the custom function\n",
        "print(\"Transpose using custom function:\")\n",
        "for row in transpose_custom:\n",
        "    print(row)\n",
        "\n",
        "# Verify the result by comparing with the transpose obtained using NumPy\n",
        "import numpy as np\n",
        "\n",
        "# Convert the matrix to a NumPy array\n",
        "matrix_np = np.array(matrix)\n",
        "\n",
        "# Get the transpose of the matrix using NumPy's transpose method\n",
        "transpose_np = np.transpose(matrix_np)\n",
        "\n",
        "# Print the transpose obtained using NumPy's transpose method\n",
        "print(\"\\nTranspose using NumPy's transpose method:\")\n",
        "print(transpose_np)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeIlWXRCSTX-",
        "outputId": "77911031-f6e0-45ba-df57-f37d59dc7562"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transpose using custom function:\n",
            "[1, 4]\n",
            "[2, 5]\n",
            "[3, 6]\n",
            "\n",
            "Transpose using NumPy's transpose method:\n",
            "[[1 4]\n",
            " [2 5]\n",
            " [3 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[1,2,3],\n",
        "               [4,5,6],\n",
        "               [7,8,9]])\n",
        "b = np.array([1,2,3])\n",
        "print(a@b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IINuwKmwSvkV",
        "outputId": "491799d2-a496-499c-898b-4918daa47669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14 32 50]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix_vector(matrix,vector):\n",
        "  matrix_rows =len(matrix)\n",
        "  matrix_cols = len(matrix[0])\n",
        "  vector_length= len(vector)\n",
        "  result = [0]*matrix_rows\n",
        "  print(result)\n",
        "  for i in range(matrix_rows):\n",
        "    for j in range(matrix_cols):\n",
        "        result[i] += matrix[i][j]*vector[j]\n",
        "  return result\n",
        "matrix = [[1,2,3],\n",
        "               [4,5,6],\n",
        "               [7,8,9]]\n",
        "vector = [1,2,3]\n",
        "print(matrix_vector(matrix,vector))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGQZNuwZS_ae",
        "outputId": "70adee9b-4e6b-4293-c5f1-291a97e7796f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0]\n",
            "[14, 32, 50]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix_vector_product(matrix, vector):\n",
        "    # Check if the number of columns in the matrix matches the length of the vector\n",
        "    if len(matrix[0]) != len(vector):\n",
        "        raise ValueError(\"Number of columns in the matrix must match the length of the vector\")\n",
        "\n",
        "    # Initialize the result vector\n",
        "    result = [0] * len(matrix)\n",
        "\n",
        "    # Perform matrix-vector multiplication\n",
        "    for i in range(len(matrix)):\n",
        "        for j in range(len(matrix[0])):\n",
        "            result[i] += matrix[i][j] * vector[j]\n",
        "\n",
        "    return result\n",
        "\n",
        "# Example usage:\n",
        "matrix = [\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6]\n",
        "]\n",
        "vector = [1, 2, 3]\n",
        "\n",
        "# Perform matrix-vector product using the custom function\n",
        "result = matrix_vector_product(matrix, vector)\n",
        "print(\"Result of matrix-vector product:\", result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL6E9dp3Us3X",
        "outputId": "87ae94c0-c75d-43b4-df88-32febb5adb1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result of matrix-vector product: [14, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vector(matrix):\n",
        "  result =[]\n",
        "  for row in matrix:\n",
        "    result.append(sum(row))\n",
        "  return result\n",
        "a = [[1,2,3], [4,5,6], [7,8,9]]\n",
        "print(vector(a))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MV5uNKEYa4Cz",
        "outputId": "3c54fc88-9bbb-43a1-a713-5c7ec440c6e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6, 15, 24]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vector_columns(matrix):\n",
        "  rows = len(matrix)\n",
        "  cols = len(matrix[0])\n",
        "  result = [0]*cols\n",
        "  for i in range(rows):\n",
        "    for j in range(cols):\n",
        "      result[j]+=matrix[i][j]\n",
        "  return result\n",
        "matrix = [\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9]\n",
        "]\n",
        "print(vector_columns(matrix))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu_hUNlKbT5q",
        "outputId": "a05a0728-a95f-40d8-c30d-bce20e8eb0be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12, 15, 18]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_multiplicaton (matrix1,matrix2):\n",
        "  rows = len(matrix1)\n",
        "  cols = len(matrix2[0])\n",
        "  result = [[0]*cols for _ in range(rows)]\n",
        "  print(result)\n",
        "  for i in range(rows):\n",
        "    for j in range(cols):\n",
        "      for k in range(len(matrix2)):\n",
        "        result[i][j]+=matrix1[i][k]*matrix2[k][j]\n",
        "  return result\n",
        "matrix1 = [\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "]\n",
        "matrix2 = [\n",
        "    [7, 8],\n",
        "    [9, 10],\n",
        "    [11, 12],\n",
        "]\n",
        "print(compute_multiplicaton(matrix1,matrix2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bdzm-8WZcJwO",
        "outputId": "0cca9f68-b453-46d4-f447-961901bf63e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0, 0], [0, 0]]\n",
            "[[58, 64], [139, 154]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "multiplying matrices , matrixes"
      ],
      "metadata": {
        "id": "MXwKM3JDeFik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix_multiply(matrix1, matrix2):\n",
        "    # Check if matrices are compatible for multiplication\n",
        "    if len(matrix1[0]) != len(matrix2):\n",
        "        raise ValueError(\"Matrices are not compatible for multiplication\")\n",
        "\n",
        "    # Initialize result matrix with appropriate size\n",
        "    result = [[0] * len(matrix2[0]) for _ in range(len(matrix1))]\n",
        "\n",
        "    # Perform matrix multiplication\n",
        "    for i in range(len(matrix1)):\n",
        "        for j in range(len(matrix2[0])):\n",
        "            for k in range(len(matrix2)):\n",
        "                result[i][j] += matrix1[i][k] * matrix2[k][j]\n",
        "\n",
        "    return result\n",
        "\n",
        "# Example usage:\n",
        "matrix1 = [\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "]\n",
        "matrix2 = [\n",
        "    [7, 8],\n",
        "    [9, 10],\n",
        "    [11, 12],\n",
        "]\n",
        "\n",
        "result = matrix_multiply(matrix1, matrix2)\n",
        "for row in result:\n",
        "    print(row)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6yU0rPzdn4B",
        "outputId": "0c5aaad7-87e4-43a3-a787-a54fe0b71997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[58, 64]\n",
            "[139, 154]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.arange(1,5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4RO4syOdtZq",
        "outputId": "d82850db-89dc-49d3-bfb1-85ab93e193f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.zeros((3,1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dc-cFYCfdXx",
        "outputId": "0b549577-d0e4-4e7b-b82f-aa3013ed02da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.],\n",
              "       [0.],\n",
              "       [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.zeros((3,2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yw8GFerCfmWk",
        "outputId": "c561c458-fa45-4d64-9d27-cbc6688fd355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.full((2,3),7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LW7spdngfoJD",
        "outputId": "543b52c4-c350-42a2-d128-8da306dd16a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[7, 7, 7],\n",
              "       [7, 7, 7]])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.arange(1,11).reshape(2,5)\n",
        "print(arr)\n",
        "arr = arr.reshape(10)\n",
        "print(arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsH1bN0Dfuwb",
        "outputId": "ebabcf76-60b8-4a9f-de60-4859712c8981"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  2  3  4  5]\n",
            " [ 6  7  8  9 10]]\n",
            "[ 1  2  3  4  5  6  7  8  9 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we read a CSV file row-by-row, appending to a list, and\n",
        "then converting it to a NumPy array"
      ],
      "metadata": {
        "id": "ycQGoOFHhzV_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "data = []\n",
        "with open('test.csv','r') as csvfile:\n",
        "  file_reader = csv.reader(csvfile,delimiter = ',')\n",
        "  for row in file_reader:\n",
        "    data.append(row)\n",
        "data=np.array(data)\n",
        "data.shape"
      ],
      "metadata": {
        "id": "LjBeccZEhgGm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "indexing and slicing on numpy"
      ],
      "metadata": {
        "id": "_FWe46rhiKZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "arr = np.arange(1,11)\n",
        "arr = arr.reshape(5,2)\n",
        "print(arr)\n",
        "print(arr[0:1])\n",
        "print(arr[-1])\n",
        "print(arr[-2])\n",
        "print(arr[:2])\n",
        "print(arr[2:])\n",
        "print(arr[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SOg_9WRiIuw",
        "outputId": "b2c19290-7c1f-4723-8b6c-fc39c16d6521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1  2]\n",
            " [ 3  4]\n",
            " [ 5  6]\n",
            " [ 7  8]\n",
            " [ 9 10]]\n",
            "[[1 2]]\n",
            "[ 9 10]\n",
            "[7 8]\n",
            "[[1 2]\n",
            " [3 4]]\n",
            "[[ 5  6]\n",
            " [ 7  8]\n",
            " [ 9 10]]\n",
            "[1 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sorting elements on numpys"
      ],
      "metadata": {
        "id": "j7H0ICKJjQGp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[6,1,4,2],\n",
        "              [9,5,4,8]])\n",
        "np.sort(a,axis=1,kind='mergesort') #sort by column"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imviBjGOiXWc",
        "outputId": "79e8dd78-08a7-4b1f-c752-ea29d76c896c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 4, 6],\n",
              "       [4, 5, 8, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([[6,1,4,2],\n",
        "              [9,5,4,8]])\n",
        "np.sort(a,axis=0,kind='mergesort') #sort by row"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lrv0iLIHjc1l",
        "outputId": "a55456f4-b843-420c-bce4-ab43d41d25c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6, 1, 4, 2],\n",
              "       [9, 5, 4, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "adding/multiplying a scalar and a matrix on numpy"
      ],
      "metadata": {
        "id": "zPWLE-1njr5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_arr = np.array([[1,2,3],\n",
        "                   [4,5,6],\n",
        "                   [7,8,9]])\n",
        "print(my_arr)\n",
        "print(my_arr + 1)\n",
        "print(my_arr*2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNwhX7uejpBG",
        "outputId": "04f7b8d4-2dd0-42dc-f975-5e917021e0cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 2 3]\n",
            " [4 5 6]\n",
            " [7 8 9]]\n",
            "[[ 2  3  4]\n",
            " [ 5  6  7]\n",
            " [ 8  9 10]]\n",
            "[[ 2  4  6]\n",
            " [ 8 10 12]\n",
            " [14 16 18]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "data sampling (through np)"
      ],
      "metadata": {
        "id": "FXppCXeWkZOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "# default plotting parameters\n",
        "matplotlib.rcParams.update({'font.size': 16,\n",
        "'figure.figsize': [10, 6],\n",
        "'lines.markersize': 6})\n",
        "uniform_data = np.random.rand(100000)\n",
        "normal_data = np.random.normal(loc=5, scale=3.0, size=100000)"
      ],
      "metadata": {
        "id": "6ysdgFuqj68W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "plotting (less relevant)"
      ],
      "metadata": {
        "id": "LeLSmQobkiC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure() # define the figure\n",
        "ax1 = fig.add_subplot(1,2,1) # set location of first subplot\n",
        "ax1.hist(x=uniform_data, bins='auto',alpha=0.9, rwidth=0.8)\n",
        "ax1.set_title(\"Uniform Distribution\")\n",
        "ax2 = fig.add_subplot(1,2,2) # set location of second subplot\n",
        "ax2.hist(x=normal_data, bins='auto', alpha=0.9, rwidth=0.8)\n",
        "ax2.set_title(\"Normal Distribution\")\n",
        "ax1.set_ylabel('Frequency')\n",
        "ax1.set_xlabel('x')\n",
        "ax2.set_xlabel('x')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "TTVdOIwmkbud",
        "outputId": "c4106bc3-17c8-4733-f64b-54488da7c15c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mask arrays"
      ],
      "metadata": {
        "id": "h_f16IThk63f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_col = [\n",
        "['Fears for T N pension after talks', 'text1'],\n",
        "['iPod Comparison', 'text2'],\n",
        "['Calif. Aims to Limit Farm-Related Smog (AP)', 'text3'],\n",
        "['The Race is On', 'text4']\n",
        "]\n",
        "print(np.asarray(full_col).shape)\n",
        "mask_array = (np.asarray(full_col)[:,0] == \"iPod Comparison\")\n",
        "print(mask_array)\n",
        "print(np.asarray(full_col)[mask_array])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvF9zSI3kkUN",
        "outputId": "70ac3afa-643f-4d32-a414-29663e9ae3e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 2)\n",
            "[False  True False False]\n",
            "[['iPod Comparison' 'text2']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"test.csv\")\n",
        "df.shape\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "bljwVNLPk9Al",
        "outputId": "a861fb4e-e7ab-468c-a73c-4bf5e80a8001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   3                  Fears for T N pension after talks  \\\n",
              "0  4  The Race is On: Second Private Team Sets Launc...   \n",
              "1  4      Ky. Company Wins Grant to Study Peptides (AP)   \n",
              "2  4      Prediction Unit Helps Forecast Wildfires (AP)   \n",
              "3  4        Calif. Aims to Limit Farm-Related Smog (AP)   \n",
              "4  4  Open Letter Against British Copyright Indoctri...   \n",
              "\n",
              "  Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.  \n",
              "0  SPACE.com - TORONTO, Canada -- A second\\team o...                                                                               \n",
              "1  AP - A company founded by a chemistry research...                                                                               \n",
              "2  AP - It's barely dawn when Mike Fitzpatrick st...                                                                               \n",
              "3  AP - Southern California's smog-fighting agenc...                                                                               \n",
              "4  The British Department for Education and Skill...                                                                               "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-74a78827-dcea-43d5-9d96-25ef3bb2a61f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>3</th>\n",
              "      <th>Fears for T N pension after talks</th>\n",
              "      <th>Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>The Race is On: Second Private Team Sets Launc...</td>\n",
              "      <td>SPACE.com - TORONTO, Canada -- A second\\team o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>Ky. Company Wins Grant to Study Peptides (AP)</td>\n",
              "      <td>AP - A company founded by a chemistry research...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>Prediction Unit Helps Forecast Wildfires (AP)</td>\n",
              "      <td>AP - It's barely dawn when Mike Fitzpatrick st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Calif. Aims to Limit Farm-Related Smog (AP)</td>\n",
              "      <td>AP - Southern California's smog-fighting agenc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Open Letter Against British Copyright Indoctri...</td>\n",
              "      <td>The British Department for Education and Skill...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74a78827-dcea-43d5-9d96-25ef3bb2a61f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-74a78827-dcea-43d5-9d96-25ef3bb2a61f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-74a78827-dcea-43d5-9d96-25ef3bb2a61f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-770a4560-af78-45fe-bd8a-d81621409583\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-770a4560-af78-45fe-bd8a-d81621409583')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-770a4560-af78-45fe-bd8a-d81621409583 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 7599,\n  \"fields\": [\n    {\n      \"column\": \"3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          3,\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fears for T N pension after talks\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7568,\n        \"samples\": [\n          \"'Nano-needle' operates on cell\",\n          \"INTERVIEW: Australia #39;s QBE Consolidates European Units\",\n          \"British Energy to delist to save rescue plan\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7593,\n        \"samples\": [\n          \"Microsoft chief executive Steve Ballmer says the software giant is listening to customers, and wants to make the company and its employees more accountable for delivering on its plans.\",\n          \"Hewlett-Packard Co. (HPQ.N: Quote, Profile, Research) and Intel Corp. (INTC.O: Quote, Profile, Research) on Wednesday ended their 10-year partnership to co-develop the Itanium chip \",\n          \"Lehman Brothers Holdings Inc. is close to settling a class action lawsuit for \\\\$220 million stemming from allegations that it colluded with other brokerages to mislead Enron Corp.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "let us assume that the 3 columns in the file test.csv (from the\n",
        "utils/ directory) contain news wires, and each record\n",
        "encodes information on topic, title, text. develop a\n",
        "simple program to\n",
        "- compute how many different topics are present in the file\n",
        "- select only data associated to a given topic, say topic 4\n",
        "- count how many elements were found in the previous\n",
        "step"
      ],
      "metadata": {
        "id": "KBvNcSMQmxHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def read_csv_file(filename):\n",
        "    # Read data from the CSV file\n",
        "    data = []\n",
        "    with open(filename, 'r') as file:\n",
        "        reader = csv.reader(file)\n",
        "        for row in reader:\n",
        "            data.append(row)\n",
        "    return data\n",
        "\n",
        "def count_unique_topics(data):\n",
        "    # Compute how many different topics are present in the file\n",
        "    topics = set(row[0] for row in data)\n",
        "    return len(topics)\n",
        "\n",
        "def select_data_by_topic(data, topic):\n",
        "    # Select only data associated with a given topic\n",
        "    selected_data = [row for row in data if row[0] == topic]\n",
        "    return selected_data\n",
        "\n",
        "def count_elements(data):\n",
        "    # Count how many elements were found\n",
        "    return len(data)\n",
        "\n",
        "# Filename of the CSV file\n",
        "filename = 'test.csv'\n",
        "\n",
        "# Read data from the CSV file\n",
        "data = read_csv_file(filename)\n",
        "\n",
        "# Task 1: Compute how many different topics are present in the file\n",
        "unique_topics = count_unique_topics(data)\n",
        "print(\"Number of different topics:\", unique_topics)\n",
        "\n",
        "# Task 2: Select only data associated with a given topic, say topic 4\n",
        "selected_topic = 'topic4'\n",
        "selected_data = select_data_by_topic(data, selected_topic)\n",
        "\n",
        "# Task 3: Count how many elements were found in the previous step\n",
        "count_selected_elements = count_elements(selected_data)\n",
        "print(\"Number of elements found for topic {}: {}\".format(selected_topic, count_selected_elements))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fhOgtH4lund",
        "outputId": "98d3cd87-8ef0-48c8-a300-168e7a6e53bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of different topics: 4\n",
            "Number of elements found for topic topic4: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mathematical functions\n",
        "• many functions available off the shelf, to compute basic\n",
        "statistics functions, such as mean, std, var"
      ],
      "metadata": {
        "id": "OdPsMuq7teF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dd_arr = np.arange(1,11).reshape(5,2)\n",
        "col1 = dd_arr[:,0]\n",
        "col2 = dd_arr[:,1]\n",
        "print(col1)\n",
        "print(col2)\n",
        "print(f'mean of col1 is {col1.mean()} std is {round(col1.std(),2)}')\n",
        "print(f'mean of col2 is {col2.mean()} std is {round(col2.std(),2)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt5xfju-mZC1",
        "outputId": "6f29de30-9042-4672-e972-5f9113e8cc9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 3 5 7 9]\n",
            "[ 2  4  6  8 10]\n",
            "mean of col1 is 5.0 std is 2.83\n",
            "mean of col2 is 6.0 std is 2.83\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating a DataFrame from scratch"
      ],
      "metadata": {
        "id": "JlFTG3Louyc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "clothes_data = {'shirts':[5,2,1,2],\n",
        "                \"trousers\":[3,1,0,2]}\n",
        "purchases = pd.DataFrame(clothes_data)\n",
        "purchases"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "ySGY6mvBtf8Y",
        "outputId": "c65f4739-9fb2-413a-9017-9d238822620e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   shirts  trousers\n",
              "0       5         3\n",
              "1       2         1\n",
              "2       1         0\n",
              "3       2         2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4197e8dd-6f03-450e-9412-e46bb9429d42\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>shirts</th>\n",
              "      <th>trousers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4197e8dd-6f03-450e-9412-e46bb9429d42')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4197e8dd-6f03-450e-9412-e46bb9429d42 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4197e8dd-6f03-450e-9412-e46bb9429d42');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8fef4621-f1c4-4c7d-b6e7-a27b18e18885\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8fef4621-f1c4-4c7d-b6e7-a27b18e18885')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8fef4621-f1c4-4c7d-b6e7-a27b18e18885 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "purchases",
              "summary": "{\n  \"name\": \"purchases\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"shirts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5,\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trousers\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "purchases = pd.DataFrame(clothes_data,index = ['Ada','Mary','Jess','Tom'])\n",
        "purchases"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "cBSqDB22vGCK",
        "outputId": "f84fd221-b949-493d-b5b9-b0a3947c3bcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      shirts  trousers\n",
              "Ada        5         3\n",
              "Mary       2         1\n",
              "Jess       1         0\n",
              "Tom        2         2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-640b3b3f-bf78-4056-ba97-9d6e4dd94b61\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>shirts</th>\n",
              "      <th>trousers</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Ada</th>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mary</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jess</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tom</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-640b3b3f-bf78-4056-ba97-9d6e4dd94b61')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-640b3b3f-bf78-4056-ba97-9d6e4dd94b61 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-640b3b3f-bf78-4056-ba97-9d6e4dd94b61');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-86b6d9b7-6e79-47ce-b622-c77941154070\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86b6d9b7-6e79-47ce-b622-c77941154070')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-86b6d9b7-6e79-47ce-b622-c77941154070 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "purchases",
              "summary": "{\n  \"name\": \"purchases\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"shirts\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5,\n          2,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trousers\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1,\n          2,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "purchases.loc['Tom']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqa5AAXivY_I",
        "outputId": "ad3d29fa-9381-4c4b-b4f4-5e54eb1e6a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shirts      2\n",
              "trousers    2\n",
              "Name: Tom, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"concreteness_ratings.csv\", index_col = \"Word\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "Q8ZtUDzgvdPy",
        "outputId": "7686ce72-44b3-4c87-e390-57b9ec8b9d9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Bigram  Conc.M  Conc.SD  Unknown  Total  Percent_known  \\\n",
              "Word                                                                    \n",
              "roadsweeper         0    4.85     0.37        1     27           0.96   \n",
              "traindriver         0    4.54     0.71        3     29           0.90   \n",
              "tush                0    4.45     1.01        3     25           0.88   \n",
              "hairdress           0    3.93     1.28        0     29           1.00   \n",
              "pharmaceutics       0    3.77     1.41        4     26           0.85   \n",
              "\n",
              "               SUBTLEX Dom_Pos  \n",
              "Word                            \n",
              "roadsweeper          0       0  \n",
              "traindriver          0       0  \n",
              "tush                66       0  \n",
              "hairdress            1       0  \n",
              "pharmaceutics        0       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a2967a2-89f7-4bcf-82ef-c39261b30d7b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bigram</th>\n",
              "      <th>Conc.M</th>\n",
              "      <th>Conc.SD</th>\n",
              "      <th>Unknown</th>\n",
              "      <th>Total</th>\n",
              "      <th>Percent_known</th>\n",
              "      <th>SUBTLEX</th>\n",
              "      <th>Dom_Pos</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>roadsweeper</th>\n",
              "      <td>0</td>\n",
              "      <td>4.85</td>\n",
              "      <td>0.37</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>traindriver</th>\n",
              "      <td>0</td>\n",
              "      <td>4.54</td>\n",
              "      <td>0.71</td>\n",
              "      <td>3</td>\n",
              "      <td>29</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tush</th>\n",
              "      <td>0</td>\n",
              "      <td>4.45</td>\n",
              "      <td>1.01</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "      <td>0.88</td>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hairdress</th>\n",
              "      <td>0</td>\n",
              "      <td>3.93</td>\n",
              "      <td>1.28</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pharmaceutics</th>\n",
              "      <td>0</td>\n",
              "      <td>3.77</td>\n",
              "      <td>1.41</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a2967a2-89f7-4bcf-82ef-c39261b30d7b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3a2967a2-89f7-4bcf-82ef-c39261b30d7b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3a2967a2-89f7-4bcf-82ef-c39261b30d7b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2c7cc50a-18e0-4eab-8275-268ec7240b3d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c7cc50a-18e0-4eab-8275-268ec7240b3d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2c7cc50a-18e0-4eab-8275-268ec7240b3d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 39954,\n  \"fields\": [\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39953,\n        \"samples\": [\n          \"sexually\",\n          \"revisionism\",\n          \"compressor\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bigram\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0386021803079468,\n        \"min\": 1.04,\n        \"max\": 5.0,\n        \"num_unique_values\": 368,\n        \"samples\": [\n          3.16,\n          4.68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.SD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.31093059573336734,\n        \"min\": 0.0,\n        \"max\": 1.89,\n        \"num_unique_values\": 165,\n        \"samples\": [\n          0.56,\n          1.63\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unknown\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 620,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1,\n          19\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 174,\n        \"min\": 21,\n        \"max\": 6072,\n        \"num_unique_values\": 37,\n        \"samples\": [\n          5870,\n          6064\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Percent_known\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04500878702071559,\n        \"min\": 0.85,\n        \"max\": 1.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.96,\n          0.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SUBTLEX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22420,\n        \"min\": 0,\n        \"max\": 2134713,\n        \"num_unique_values\": 2737,\n        \"samples\": [\n          819,\n          3602\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dom_Pos\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"0\",\n          \"Adjective\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "get further information on non-Null elements, Dtype for each\n",
        "field"
      ],
      "metadata": {
        "id": "TOJpVqgiwJuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjv4r-Cqv_ky",
        "outputId": "4a5b1ce9-df95-4e6d-90c3-7665d15d43a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 39954 entries, roadsweeper to essentialness\n",
            "Data columns (total 8 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   Bigram         39954 non-null  int64  \n",
            " 1   Conc.M         39954 non-null  float64\n",
            " 2   Conc.SD        39954 non-null  float64\n",
            " 3   Unknown        39954 non-null  int64  \n",
            " 4   Total          39954 non-null  int64  \n",
            " 5   Percent_known  39954 non-null  float64\n",
            " 6   SUBTLEX        39954 non-null  int64  \n",
            " 7   Dom_Pos        28707 non-null  object \n",
            "dtypes: float64(3), int64(4), object(1)\n",
            "memory usage: 3.8+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "duplicates\n",
        "• no duplicates in this dataset, but we can simulate\n",
        "duplicates by simply doubling data\n",
        "- pandas provides a function to drop duplicates,\n",
        "drop_duplicates(); we can check whether it acts as expected"
      ],
      "metadata": {
        "id": "EU4TrVZqwUKg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_df = pd.concat([df,df])\n",
        "tmp_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7lUwuaRwGlh",
        "outputId": "d5519460-e77e-48bf-dc3b-2d20979cc4d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(79908, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_df.drop_duplicates().shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMjzqeMkwbe5",
        "outputId": "6b889ac8-e354-4742-de4f-593cea89ab99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37707, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "missing values\n",
        "• we are likely to encounter missing or null values, and we have two\n",
        "options in dealing with null elements:\n",
        "- drop rows or columns with nulls\n",
        "- replace null values with non-null values (a technique known as imputation)\n",
        "• then we can check which cells in our DataFrame are null"
      ],
      "metadata": {
        "id": "g2Eau-YNwpnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "_aiZ9FTrwfcJ",
        "outputId": "e7c24bc1-1ef1-4b15-9a8d-4533720ff5d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Bigram  Conc.M  Conc.SD  Unknown  Total  Percent_known  \\\n",
              "Word                                                                      \n",
              "roadsweeper       False   False    False    False  False          False   \n",
              "traindriver       False   False    False    False  False          False   \n",
              "tush              False   False    False    False  False          False   \n",
              "hairdress         False   False    False    False  False          False   \n",
              "pharmaceutics     False   False    False    False  False          False   \n",
              "...                 ...     ...      ...      ...    ...            ...   \n",
              "unenvied          False   False    False    False  False          False   \n",
              "agnostically      False   False    False    False  False          False   \n",
              "conceptualistic   False   False    False    False  False          False   \n",
              "conventionalism   False   False    False    False  False          False   \n",
              "essentialness     False   False    False    False  False          False   \n",
              "\n",
              "                 SUBTLEX  Dom_Pos  \n",
              "Word                               \n",
              "roadsweeper        False    False  \n",
              "traindriver        False    False  \n",
              "tush               False    False  \n",
              "hairdress          False    False  \n",
              "pharmaceutics      False    False  \n",
              "...                  ...      ...  \n",
              "unenvied           False     True  \n",
              "agnostically       False     True  \n",
              "conceptualistic    False     True  \n",
              "conventionalism    False     True  \n",
              "essentialness      False     True  \n",
              "\n",
              "[39954 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4a8488e2-e96b-44ac-866d-f5a1a3b94638\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bigram</th>\n",
              "      <th>Conc.M</th>\n",
              "      <th>Conc.SD</th>\n",
              "      <th>Unknown</th>\n",
              "      <th>Total</th>\n",
              "      <th>Percent_known</th>\n",
              "      <th>SUBTLEX</th>\n",
              "      <th>Dom_Pos</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>roadsweeper</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>traindriver</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tush</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hairdress</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pharmaceutics</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unenvied</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>agnostically</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conceptualistic</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>conventionalism</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>essentialness</th>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39954 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a8488e2-e96b-44ac-866d-f5a1a3b94638')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4a8488e2-e96b-44ac-866d-f5a1a3b94638 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4a8488e2-e96b-44ac-866d-f5a1a3b94638');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-dd1f0f8f-9b3b-4098-b242-f8165f84058c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dd1f0f8f-9b3b-4098-b242-f8165f84058c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-dd1f0f8f-9b3b-4098-b242-f8165f84058c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 39954,\n  \"fields\": [\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39953,\n        \"samples\": [\n          \"sexually\",\n          \"revisionism\",\n          \"compressor\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bigram\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.M\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.SD\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unknown\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Percent_known\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SUBTLEX\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          false\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dom_Pos\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzVWBBVdwsAh",
        "outputId": "fb3617a4-29ae-4870-e4ad-c33d13c63cd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Bigram               0\n",
              "Conc.M               0\n",
              "Conc.SD              0\n",
              "Unknown              0\n",
              "Total                0\n",
              "Percent_known        0\n",
              "SUBTLEX              0\n",
              "Dom_Pos          11247\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "GVIN1iINwvQp",
        "outputId": "a3cc1a60-bc3e-4514-9f3a-e804c969edea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Bigram  Conc.M  Conc.SD  Unknown  Total  Percent_known  \\\n",
              "Word                                                                    \n",
              "roadsweeper         0    4.85     0.37        1     27           0.96   \n",
              "traindriver         0    4.54     0.71        3     29           0.90   \n",
              "tush                0    4.45     1.01        3     25           0.88   \n",
              "hairdress           0    3.93     1.28        0     29           1.00   \n",
              "pharmaceutics       0    3.77     1.41        4     26           0.85   \n",
              "...               ...     ...      ...      ...    ...            ...   \n",
              "spiriting           0    1.33     0.68        4     31           0.87   \n",
              "hope                0    1.25     0.59        0     28           1.00   \n",
              "zing                0    1.23     0.43        4     26           0.85   \n",
              "idealize            0    1.19     0.40        0     27           1.00   \n",
              "would               0    1.12     0.34        3     27           0.89   \n",
              "\n",
              "               SUBTLEX Dom_Pos  \n",
              "Word                            \n",
              "roadsweeper          0       0  \n",
              "traindriver          0       0  \n",
              "tush                66       0  \n",
              "hairdress            1       0  \n",
              "pharmaceutics        0       0  \n",
              "...                ...     ...  \n",
              "spiriting            3    Verb  \n",
              "hope             16352    Verb  \n",
              "zing                60    Verb  \n",
              "idealize             6    Verb  \n",
              "would            90162    Verb  \n",
              "\n",
              "[28707 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fdd7e5ec-4579-417a-8ded-1024fa46054f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bigram</th>\n",
              "      <th>Conc.M</th>\n",
              "      <th>Conc.SD</th>\n",
              "      <th>Unknown</th>\n",
              "      <th>Total</th>\n",
              "      <th>Percent_known</th>\n",
              "      <th>SUBTLEX</th>\n",
              "      <th>Dom_Pos</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>roadsweeper</th>\n",
              "      <td>0</td>\n",
              "      <td>4.85</td>\n",
              "      <td>0.37</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>traindriver</th>\n",
              "      <td>0</td>\n",
              "      <td>4.54</td>\n",
              "      <td>0.71</td>\n",
              "      <td>3</td>\n",
              "      <td>29</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tush</th>\n",
              "      <td>0</td>\n",
              "      <td>4.45</td>\n",
              "      <td>1.01</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "      <td>0.88</td>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hairdress</th>\n",
              "      <td>0</td>\n",
              "      <td>3.93</td>\n",
              "      <td>1.28</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pharmaceutics</th>\n",
              "      <td>0</td>\n",
              "      <td>3.77</td>\n",
              "      <td>1.41</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spiriting</th>\n",
              "      <td>0</td>\n",
              "      <td>1.33</td>\n",
              "      <td>0.68</td>\n",
              "      <td>4</td>\n",
              "      <td>31</td>\n",
              "      <td>0.87</td>\n",
              "      <td>3</td>\n",
              "      <td>Verb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hope</th>\n",
              "      <td>0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>1.00</td>\n",
              "      <td>16352</td>\n",
              "      <td>Verb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zing</th>\n",
              "      <td>0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.43</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>0.85</td>\n",
              "      <td>60</td>\n",
              "      <td>Verb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>idealize</th>\n",
              "      <td>0</td>\n",
              "      <td>1.19</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>1.00</td>\n",
              "      <td>6</td>\n",
              "      <td>Verb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>would</th>\n",
              "      <td>0</td>\n",
              "      <td>1.12</td>\n",
              "      <td>0.34</td>\n",
              "      <td>3</td>\n",
              "      <td>27</td>\n",
              "      <td>0.89</td>\n",
              "      <td>90162</td>\n",
              "      <td>Verb</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28707 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fdd7e5ec-4579-417a-8ded-1024fa46054f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fdd7e5ec-4579-417a-8ded-1024fa46054f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fdd7e5ec-4579-417a-8ded-1024fa46054f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-62eb64f8-02f1-4da4-b405-c36cdaa6ed4b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-62eb64f8-02f1-4da4-b405-c36cdaa6ed4b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-62eb64f8-02f1-4da4-b405-c36cdaa6ed4b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 28707,\n  \"fields\": [\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 28706,\n        \"samples\": [\n          \"disparate\",\n          \"jazzman\",\n          \"fathom\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bigram\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0186505158474155,\n        \"min\": 1.04,\n        \"max\": 5.0,\n        \"num_unique_values\": 366,\n        \"samples\": [\n          2.83\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.SD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.30495379642859727,\n        \"min\": 0.0,\n        \"max\": 1.89,\n        \"num_unique_values\": 165,\n        \"samples\": [\n          0.56\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unknown\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 0,\n        \"max\": 620,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 203,\n        \"min\": 21,\n        \"max\": 6072,\n        \"num_unique_values\": 37,\n        \"samples\": [\n          5870\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Percent_known\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.040786636677765505,\n        \"min\": 0.85,\n        \"max\": 1.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.96\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SUBTLEX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26438,\n        \"min\": 0,\n        \"max\": 2134713,\n        \"num_unique_values\": 2731,\n        \"samples\": [\n          1250\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dom_Pos\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "describe\n",
        "• the describe() function returns a summary of the distribution\n",
        "of continuous variables"
      ],
      "metadata": {
        "id": "Nnbuxfhlw28g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "ZkOxWMOMwy4p",
        "outputId": "2dfb9ffb-5e50-475b-9df4-5e01c701c095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Bigram        Conc.M       Conc.SD       Unknown         Total  \\\n",
              "count  39954.000000  39954.000000  39954.000000  39954.000000  39954.000000   \n",
              "mean       0.072483      3.036267      1.148359      0.999825     33.195450   \n",
              "std        0.259290      1.038602      0.310931      3.745465    174.829539   \n",
              "min        0.000000      1.040000      0.000000      0.000000     21.000000   \n",
              "25%        0.000000      2.120000      1.000000      0.000000     27.000000   \n",
              "50%        0.000000      2.880000      1.210000      0.000000     28.000000   \n",
              "75%        0.000000      3.890000      1.370000      2.000000     29.000000   \n",
              "max        1.000000      5.000000      1.890000    620.000000   6072.000000   \n",
              "\n",
              "       Percent_known       SUBTLEX  \n",
              "count   39954.000000  3.995400e+04  \n",
              "mean        0.965562  1.077803e+03  \n",
              "std         0.045009  2.242037e+04  \n",
              "min         0.850000  0.000000e+00  \n",
              "25%         0.930000  0.000000e+00  \n",
              "50%         1.000000  1.000000e+01  \n",
              "75%         1.000000  6.700000e+01  \n",
              "max         1.000000  2.134713e+06  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aeee8e36-1bca-4c19-92f8-1bd0810040f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bigram</th>\n",
              "      <th>Conc.M</th>\n",
              "      <th>Conc.SD</th>\n",
              "      <th>Unknown</th>\n",
              "      <th>Total</th>\n",
              "      <th>Percent_known</th>\n",
              "      <th>SUBTLEX</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>39954.000000</td>\n",
              "      <td>39954.000000</td>\n",
              "      <td>39954.000000</td>\n",
              "      <td>39954.000000</td>\n",
              "      <td>39954.000000</td>\n",
              "      <td>39954.000000</td>\n",
              "      <td>3.995400e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.072483</td>\n",
              "      <td>3.036267</td>\n",
              "      <td>1.148359</td>\n",
              "      <td>0.999825</td>\n",
              "      <td>33.195450</td>\n",
              "      <td>0.965562</td>\n",
              "      <td>1.077803e+03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.259290</td>\n",
              "      <td>1.038602</td>\n",
              "      <td>0.310931</td>\n",
              "      <td>3.745465</td>\n",
              "      <td>174.829539</td>\n",
              "      <td>0.045009</td>\n",
              "      <td>2.242037e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.040000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.120000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>0.930000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.880000</td>\n",
              "      <td>1.210000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>28.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.890000</td>\n",
              "      <td>1.370000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.700000e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.890000</td>\n",
              "      <td>620.000000</td>\n",
              "      <td>6072.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.134713e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aeee8e36-1bca-4c19-92f8-1bd0810040f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aeee8e36-1bca-4c19-92f8-1bd0810040f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aeee8e36-1bca-4c19-92f8-1bd0810040f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-02e2e2d7-eca3-4065-b9cc-884624f26497\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-02e2e2d7-eca3-4065-b9cc-884624f26497')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-02e2e2d7-eca3-4065-b9cc-884624f26497 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Bigram\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14125.804907203341,\n        \"min\": 0.0,\n        \"max\": 39954.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.07248335585923812,\n          1.0,\n          0.25928980253335465\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14124.912341152029,\n        \"min\": 1.0386021803079468,\n        \"max\": 39954.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3.0362669570005507,\n          2.88,\n          39954.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.SD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14125.522198255534,\n        \"min\": 0.0,\n        \"max\": 39954.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1.148359363267758,\n          1.21,\n          39954.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unknown\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14095.88047213581,\n        \"min\": 0.0,\n        \"max\": 39954.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          39954.0,\n          0.9998247985182961,\n          620.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13963.281479317293,\n        \"min\": 21.0,\n        \"max\": 39954.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          33.19544976723232,\n          28.0,\n          39954.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Percent_known\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14125.579703465159,\n        \"min\": 0.04500878702071559,\n        \"max\": 39954.0,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          39954.0,\n          0.9655621464684387,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SUBTLEX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 751671.1068634136,\n        \"min\": 0.0,\n        \"max\": 2134713.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          39954.0,\n          1077.8026981028183,\n          67.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Conc.M'].describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNlwn3sBw5Gq",
        "outputId": "bf37988d-dd89-4e28-d977-2654981b9cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    39954.000000\n",
              "mean         3.036267\n",
              "std          1.038602\n",
              "min          1.040000\n",
              "25%          2.120000\n",
              "50%          2.880000\n",
              "75%          3.890000\n",
              "max          5.000000\n",
              "Name: Conc.M, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Conc.M'].value_counts().head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm7YnxVfxDCC",
        "outputId": "f4e09f23-38ad-4323-849c-41e9d71d65cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.00    686\n",
              "2.04    530\n",
              "1.96    492\n",
              "1.93    399\n",
              "3.00    399\n",
              "Name: Conc.M, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "correlations\n",
        "36\n",
        "• corr() can be employed to explore the relationship\n",
        "between variable pairs:"
      ],
      "metadata": {
        "id": "0HupBuvWxUx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.corr()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "plO3mZZVxNR9",
        "outputId": "00c7edf5-6670-418c-bb17-c6ba25ec1f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-101-2f6f6606aa2c>:1: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  df.corr()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Bigram    Conc.M   Conc.SD   Unknown     Total  \\\n",
              "Bigram         1.000000  0.241452 -0.153403 -0.051326 -0.008283   \n",
              "Conc.M         0.241452  1.000000 -0.308361 -0.058191  0.020265   \n",
              "Conc.SD       -0.153403 -0.308361  1.000000  0.038987 -0.021533   \n",
              "Unknown       -0.051326 -0.058191  0.038987  1.000000  0.296640   \n",
              "Total         -0.008283  0.020265 -0.021533  0.296640  1.000000   \n",
              "Percent_known  0.145394  0.195631 -0.128229 -0.341421  0.019381   \n",
              "SUBTLEX       -0.013439 -0.015129  0.014573 -0.010604  0.001033   \n",
              "\n",
              "               Percent_known   SUBTLEX  \n",
              "Bigram              0.145394 -0.013439  \n",
              "Conc.M              0.195631 -0.015129  \n",
              "Conc.SD            -0.128229  0.014573  \n",
              "Unknown            -0.341421 -0.010604  \n",
              "Total               0.019381  0.001033  \n",
              "Percent_known       1.000000  0.030547  \n",
              "SUBTLEX             0.030547  1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-48133bf0-6205-405a-8df6-4219e127a7ff\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bigram</th>\n",
              "      <th>Conc.M</th>\n",
              "      <th>Conc.SD</th>\n",
              "      <th>Unknown</th>\n",
              "      <th>Total</th>\n",
              "      <th>Percent_known</th>\n",
              "      <th>SUBTLEX</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Bigram</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.241452</td>\n",
              "      <td>-0.153403</td>\n",
              "      <td>-0.051326</td>\n",
              "      <td>-0.008283</td>\n",
              "      <td>0.145394</td>\n",
              "      <td>-0.013439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Conc.M</th>\n",
              "      <td>0.241452</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.308361</td>\n",
              "      <td>-0.058191</td>\n",
              "      <td>0.020265</td>\n",
              "      <td>0.195631</td>\n",
              "      <td>-0.015129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Conc.SD</th>\n",
              "      <td>-0.153403</td>\n",
              "      <td>-0.308361</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.038987</td>\n",
              "      <td>-0.021533</td>\n",
              "      <td>-0.128229</td>\n",
              "      <td>0.014573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Unknown</th>\n",
              "      <td>-0.051326</td>\n",
              "      <td>-0.058191</td>\n",
              "      <td>0.038987</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.296640</td>\n",
              "      <td>-0.341421</td>\n",
              "      <td>-0.010604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total</th>\n",
              "      <td>-0.008283</td>\n",
              "      <td>0.020265</td>\n",
              "      <td>-0.021533</td>\n",
              "      <td>0.296640</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.019381</td>\n",
              "      <td>0.001033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Percent_known</th>\n",
              "      <td>0.145394</td>\n",
              "      <td>0.195631</td>\n",
              "      <td>-0.128229</td>\n",
              "      <td>-0.341421</td>\n",
              "      <td>0.019381</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.030547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SUBTLEX</th>\n",
              "      <td>-0.013439</td>\n",
              "      <td>-0.015129</td>\n",
              "      <td>0.014573</td>\n",
              "      <td>-0.010604</td>\n",
              "      <td>0.001033</td>\n",
              "      <td>0.030547</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-48133bf0-6205-405a-8df6-4219e127a7ff')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-48133bf0-6205-405a-8df6-4219e127a7ff button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-48133bf0-6205-405a-8df6-4219e127a7ff');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e2eeac4a-0d32-485d-9489-fda6b23765f0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e2eeac4a-0d32-485d-9489-fda6b23765f0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e2eeac4a-0d32-485d-9489-fda6b23765f0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"Bigram\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.39019115586057845,\n        \"min\": -0.1534027033351289,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1.0,\n          0.2414516392679484,\n          0.14539399107163922\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4144049303931635,\n        \"min\": -0.3083610734485861,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.2414516392679484,\n          1.0,\n          0.19563131330628314\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.SD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.42998921329912027,\n        \"min\": -0.3083610734485861,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          -0.1534027033351289,\n          -0.3083610734485861,\n          -0.12822945604886934\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unknown\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4287715671252441,\n        \"min\": -0.3414212945189038,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          -0.05132608265951335,\n          -0.05819095881642298,\n          -0.3414212945189038\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3752979583737455,\n        \"min\": -0.021532951623823873,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          -0.008283238556093718,\n          0.020264944036769296,\n          0.019381393568111235\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Percent_known\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4227832318704064,\n        \"min\": -0.3414212945189038,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.14539399107163922,\n          0.19563131330628314,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SUBTLEX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.37789096037448816,\n        \"min\": -0.015129151408617982,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          -0.013438788846537418,\n          -0.015129151408617982,\n          0.03054744817654865\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_and_conc_score = df[['Conc.M','Conc.SD']]\n",
        "word_and_conc_score.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "wwp92KtlxS5q",
        "outputId": "d7df2b1d-626d-4b8b-f14b-37d442575a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Conc.M  Conc.SD\n",
              "Word                          \n",
              "roadsweeper      4.85     0.37\n",
              "traindriver      4.54     0.71\n",
              "tush             4.45     1.01\n",
              "hairdress        3.93     1.28\n",
              "pharmaceutics    3.77     1.41"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-38cd6567-3b92-48ee-890f-5c510f542553\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Conc.M</th>\n",
              "      <th>Conc.SD</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>roadsweeper</th>\n",
              "      <td>4.85</td>\n",
              "      <td>0.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>traindriver</th>\n",
              "      <td>4.54</td>\n",
              "      <td>0.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tush</th>\n",
              "      <td>4.45</td>\n",
              "      <td>1.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hairdress</th>\n",
              "      <td>3.93</td>\n",
              "      <td>1.28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pharmaceutics</th>\n",
              "      <td>3.77</td>\n",
              "      <td>1.41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38cd6567-3b92-48ee-890f-5c510f542553')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-38cd6567-3b92-48ee-890f-5c510f542553 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-38cd6567-3b92-48ee-890f-5c510f542553');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-93fdac4f-516e-4f76-8f88-e13e44a3d056\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-93fdac4f-516e-4f76-8f88-e13e44a3d056')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-93fdac4f-516e-4f76-8f88-e13e44a3d056 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "word_and_conc_score",
              "summary": "{\n  \"name\": \"word_and_conc_score\",\n  \"rows\": 39954,\n  \"fields\": [\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39953,\n        \"samples\": [\n          \"sexually\",\n          \"revisionism\",\n          \"compressor\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0386021803079468,\n        \"min\": 1.04,\n        \"max\": 5.0,\n        \"num_unique_values\": 368,\n        \"samples\": [\n          3.16,\n          4.68,\n          1.56\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.SD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.31093059573336734,\n        \"min\": 0.0,\n        \"max\": 1.89,\n        \"num_unique_values\": 165,\n        \"samples\": [\n          0.56,\n          1.63,\n          0.67\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "getting data by rows • we have two ways to retrieve rows:\n",
        "- loc: to locate elements by name\n",
        "- iloc: to locate elements by numerical index"
      ],
      "metadata": {
        "id": "f4ljrB6oxtvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc['hairdress']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qD10tf6xnSC",
        "outputId": "f8bba39f-0ef1-4bb7-88a1-d6aea091ad07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Bigram              0\n",
              "Conc.M           3.93\n",
              "Conc.SD          1.28\n",
              "Unknown             0\n",
              "Total              29\n",
              "Percent_known     1.0\n",
              "SUBTLEX             1\n",
              "Dom_Pos             0\n",
              "Name: hairdress, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3ggUMi_xz5q",
        "outputId": "a2da0b58-a6e9-4c1d-c272-8119f3b8d2ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Bigram              0\n",
              "Conc.M           3.93\n",
              "Conc.SD          1.28\n",
              "Unknown             0\n",
              "Total              29\n",
              "Percent_known     1.0\n",
              "SUBTLEX             1\n",
              "Dom_Pos             0\n",
              "Name: hairdress, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc['hairdress':'human']\n",
        "df.iloc[3:18]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "I-PRDL-Tx2ky",
        "outputId": "71fba598-d8fb-42ad-8a85-82beb2eec64d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                Bigram  Conc.M  Conc.SD  Unknown  Total  Percent_known  \\\n",
              "Word                                                                     \n",
              "hairdress            0    3.93     1.28        0     29           1.00   \n",
              "pharmaceutics        0    3.77     1.41        4     26           0.85   \n",
              "hoover               0    3.76     1.23        4     29           0.86   \n",
              "shopkeeping          0    3.18     1.19        1     29           0.97   \n",
              "pushiness            0    2.48     1.24        1     30           0.97   \n",
              "underdevelop         0    2.37     1.40        0     30           1.00   \n",
              "tirelessness         0    2.28     1.28        1     30           0.97   \n",
              "oldfashioned         0    2.26     1.02        0     27           1.00   \n",
              "wellmannered         0    2.25     1.14        2     30           0.93   \n",
              "dismissiveness       0    1.83     1.00        1     30           0.97   \n",
              "spitefulness         0    1.80     0.76        0     25           1.00   \n",
              "untruthfulness       0    1.73     0.92        4     30           0.87   \n",
              "dispiritedness       0    1.56     0.71        3     28           0.89   \n",
              "sled                 0    5.00     0.00        0     28           1.00   \n",
              "plunger              0    4.96     0.20        0     26           1.00   \n",
              "\n",
              "                SUBTLEX    Dom_Pos  \n",
              "Word                                \n",
              "hairdress             1          0  \n",
              "pharmaceutics         0          0  \n",
              "hoover              162          0  \n",
              "shopkeeping           0          0  \n",
              "pushiness             0          0  \n",
              "underdevelop          0          0  \n",
              "tirelessness          0          0  \n",
              "oldfashioned          0          0  \n",
              "wellmannered          0          0  \n",
              "dismissiveness        0          0  \n",
              "spitefulness          0          0  \n",
              "untruthfulness        0          0  \n",
              "dispiritedness        0          0  \n",
              "sled                149  Adjective  \n",
              "plunger              48  Adjective  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6224ef5d-ecf4-4445-83a5-df5ed98e7b77\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bigram</th>\n",
              "      <th>Conc.M</th>\n",
              "      <th>Conc.SD</th>\n",
              "      <th>Unknown</th>\n",
              "      <th>Total</th>\n",
              "      <th>Percent_known</th>\n",
              "      <th>SUBTLEX</th>\n",
              "      <th>Dom_Pos</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>hairdress</th>\n",
              "      <td>0</td>\n",
              "      <td>3.93</td>\n",
              "      <td>1.28</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pharmaceutics</th>\n",
              "      <td>0</td>\n",
              "      <td>3.77</td>\n",
              "      <td>1.41</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hoover</th>\n",
              "      <td>0</td>\n",
              "      <td>3.76</td>\n",
              "      <td>1.23</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>0.86</td>\n",
              "      <td>162</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>shopkeeping</th>\n",
              "      <td>0</td>\n",
              "      <td>3.18</td>\n",
              "      <td>1.19</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pushiness</th>\n",
              "      <td>0</td>\n",
              "      <td>2.48</td>\n",
              "      <td>1.24</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>underdevelop</th>\n",
              "      <td>0</td>\n",
              "      <td>2.37</td>\n",
              "      <td>1.40</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tirelessness</th>\n",
              "      <td>0</td>\n",
              "      <td>2.28</td>\n",
              "      <td>1.28</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>oldfashioned</th>\n",
              "      <td>0</td>\n",
              "      <td>2.26</td>\n",
              "      <td>1.02</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wellmannered</th>\n",
              "      <td>0</td>\n",
              "      <td>2.25</td>\n",
              "      <td>1.14</td>\n",
              "      <td>2</td>\n",
              "      <td>30</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dismissiveness</th>\n",
              "      <td>0</td>\n",
              "      <td>1.83</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spitefulness</th>\n",
              "      <td>0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>untruthfulness</th>\n",
              "      <td>0</td>\n",
              "      <td>1.73</td>\n",
              "      <td>0.92</td>\n",
              "      <td>4</td>\n",
              "      <td>30</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dispiritedness</th>\n",
              "      <td>0</td>\n",
              "      <td>1.56</td>\n",
              "      <td>0.71</td>\n",
              "      <td>3</td>\n",
              "      <td>28</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sled</th>\n",
              "      <td>0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>1.00</td>\n",
              "      <td>149</td>\n",
              "      <td>Adjective</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>plunger</th>\n",
              "      <td>0</td>\n",
              "      <td>4.96</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>1.00</td>\n",
              "      <td>48</td>\n",
              "      <td>Adjective</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6224ef5d-ecf4-4445-83a5-df5ed98e7b77')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6224ef5d-ecf4-4445-83a5-df5ed98e7b77 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6224ef5d-ecf4-4445-83a5-df5ed98e7b77');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f575fd89-9e50-4a1f-8395-2b35be0afa8b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f575fd89-9e50-4a1f-8395-2b35be0afa8b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f575fd89-9e50-4a1f-8395-2b35be0afa8b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"dismissiveness\",\n          \"untruthfulness\",\n          \"hairdress\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bigram\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1487537760961823,\n        \"min\": 1.56,\n        \"max\": 5.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          1.83\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.SD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.41716503528779425,\n        \"min\": 0.0,\n        \"max\": 1.41,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.76\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unknown\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 25,\n        \"max\": 30,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          29\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Percent_known\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05671986298593163,\n        \"min\": 0.85,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SUBTLEX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 54,\n        \"min\": 0,\n        \"max\": 162,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dom_Pos\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Adjective\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "filtering data"
      ],
      "metadata": {
        "id": "RmcS-PxuyFjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "condition = (df['Dom_Pos']==\"Verb\")\n",
        "condition.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlVekHjcyFDT",
        "outputId": "8cb7b7fa-2c6e-4dac-a4eb-0d9273881062"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Word\n",
              "roadsweeper      False\n",
              "traindriver      False\n",
              "tush             False\n",
              "hairdress        False\n",
              "pharmaceutics    False\n",
              "Name: Dom_Pos, dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['Dom_Pos']=='Verb']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "UNgh4iLjx-Ci",
        "outputId": "9f8ddd50-4b11-4497-d248-290a9aab8012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           Bigram  Conc.M  Conc.SD  Unknown  Total  Percent_known  SUBTLEX  \\\n",
              "Word                                                                         \n",
              "comb            0    5.00     0.00        1     30           0.97      309   \n",
              "escargot        0    5.00     0.00        1     28           0.96       15   \n",
              "tire            0    5.00     0.00        0     30           1.00      631   \n",
              "smoke           0    4.96     0.19        0     27           1.00     3337   \n",
              "elk             0    4.93     0.37        0     29           1.00      306   \n",
              "...           ...     ...      ...      ...    ...            ...      ...   \n",
              "spiriting       0    1.33     0.68        4     31           0.87        3   \n",
              "hope            0    1.25     0.59        0     28           1.00    16352   \n",
              "zing            0    1.23     0.43        4     26           0.85       60   \n",
              "idealize        0    1.19     0.40        0     27           1.00        6   \n",
              "would           0    1.12     0.34        3     27           0.89    90162   \n",
              "\n",
              "          Dom_Pos  \n",
              "Word               \n",
              "comb         Verb  \n",
              "escargot     Verb  \n",
              "tire         Verb  \n",
              "smoke        Verb  \n",
              "elk          Verb  \n",
              "...           ...  \n",
              "spiriting    Verb  \n",
              "hope         Verb  \n",
              "zing         Verb  \n",
              "idealize     Verb  \n",
              "would        Verb  \n",
              "\n",
              "[5369 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c216f59-2cb8-4668-915b-315853121779\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bigram</th>\n",
              "      <th>Conc.M</th>\n",
              "      <th>Conc.SD</th>\n",
              "      <th>Unknown</th>\n",
              "      <th>Total</th>\n",
              "      <th>Percent_known</th>\n",
              "      <th>SUBTLEX</th>\n",
              "      <th>Dom_Pos</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>comb</th>\n",
              "      <td>0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>30</td>\n",
              "      <td>0.97</td>\n",
              "      <td>309</td>\n",
              "      <td>Verb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>escargot</th>\n",
              "      <td>0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>0.96</td>\n",
              "      <td>15</td>\n",
              "      <td>Verb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tire</th>\n",
              "      <td>0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>1.00</td>\n",
              "      <td>631</td>\n",
              "      <td>Verb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoke</th>\n",
              "      <td>0</td>\n",
              "      <td>4.96</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>1.00</td>\n",
              "      <td>3337</td>\n",
              "      <td>Verb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>elk</th>\n",
              "      <td>0</td>\n",
              "      <td>4.93</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>1.00</td>\n",
              "      <td>306</td>\n",
              "      <td>Verb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>spiriting</th>\n",
              "      <td>0</td>\n",
              "      <td>1.33</td>\n",
              "      <td>0.68</td>\n",
              "      <td>4</td>\n",
              "      <td>31</td>\n",
              "      <td>0.87</td>\n",
              "      <td>3</td>\n",
              "      <td>Verb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hope</th>\n",
              "      <td>0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>1.00</td>\n",
              "      <td>16352</td>\n",
              "      <td>Verb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>zing</th>\n",
              "      <td>0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.43</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>0.85</td>\n",
              "      <td>60</td>\n",
              "      <td>Verb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>idealize</th>\n",
              "      <td>0</td>\n",
              "      <td>1.19</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>1.00</td>\n",
              "      <td>6</td>\n",
              "      <td>Verb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>would</th>\n",
              "      <td>0</td>\n",
              "      <td>1.12</td>\n",
              "      <td>0.34</td>\n",
              "      <td>3</td>\n",
              "      <td>27</td>\n",
              "      <td>0.89</td>\n",
              "      <td>90162</td>\n",
              "      <td>Verb</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5369 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c216f59-2cb8-4668-915b-315853121779')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3c216f59-2cb8-4668-915b-315853121779 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3c216f59-2cb8-4668-915b-315853121779');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a5c8f21e-f319-4d01-8018-9ab6d8127ec1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a5c8f21e-f319-4d01-8018-9ab6d8127ec1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a5c8f21e-f319-4d01-8018-9ab6d8127ec1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[df['Dom_Pos']=='Verb']\",\n  \"rows\": 5369,\n  \"fields\": [\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5369,\n        \"samples\": [\n          \"shake\",\n          \"squaring\",\n          \"thump\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bigram\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7601135845226401,\n        \"min\": 1.12,\n        \"max\": 5.0,\n        \"num_unique_values\": 330,\n        \"samples\": [\n          4.81\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.SD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19888193094678194,\n        \"min\": 0.0,\n        \"max\": 1.82,\n        \"num_unique_values\": 137,\n        \"samples\": [\n          1.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unknown\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 22,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 161,\n        \"min\": 22,\n        \"max\": 6064,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Percent_known\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03812950645416269,\n        \"min\": 0.85,\n        \"max\": 1.0,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          0.95\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SUBTLEX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15007,\n        \"min\": 0,\n        \"max\": 459663,\n        \"num_unique_values\": 1134,\n        \"samples\": [\n          486\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dom_Pos\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Verb\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['Conc.M']>=3.5].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "Zi4hRELJyW56",
        "outputId": "c67e11fb-a0be-4d92-9592-8bdba7ea6d64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Bigram  Conc.M  Conc.SD  Unknown  Total  Percent_known  \\\n",
              "Word                                                                    \n",
              "roadsweeper         0    4.85     0.37        1     27           0.96   \n",
              "traindriver         0    4.54     0.71        3     29           0.90   \n",
              "tush                0    4.45     1.01        3     25           0.88   \n",
              "hairdress           0    3.93     1.28        0     29           1.00   \n",
              "pharmaceutics       0    3.77     1.41        4     26           0.85   \n",
              "\n",
              "               SUBTLEX Dom_Pos  \n",
              "Word                            \n",
              "roadsweeper          0       0  \n",
              "traindriver          0       0  \n",
              "tush                66       0  \n",
              "hairdress            1       0  \n",
              "pharmaceutics        0       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f5c996b-ba3e-4d06-b111-f1c96d96ead8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bigram</th>\n",
              "      <th>Conc.M</th>\n",
              "      <th>Conc.SD</th>\n",
              "      <th>Unknown</th>\n",
              "      <th>Total</th>\n",
              "      <th>Percent_known</th>\n",
              "      <th>SUBTLEX</th>\n",
              "      <th>Dom_Pos</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>roadsweeper</th>\n",
              "      <td>0</td>\n",
              "      <td>4.85</td>\n",
              "      <td>0.37</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>traindriver</th>\n",
              "      <td>0</td>\n",
              "      <td>4.54</td>\n",
              "      <td>0.71</td>\n",
              "      <td>3</td>\n",
              "      <td>29</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tush</th>\n",
              "      <td>0</td>\n",
              "      <td>4.45</td>\n",
              "      <td>1.01</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "      <td>0.88</td>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hairdress</th>\n",
              "      <td>0</td>\n",
              "      <td>3.93</td>\n",
              "      <td>1.28</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pharmaceutics</th>\n",
              "      <td>0</td>\n",
              "      <td>3.77</td>\n",
              "      <td>1.41</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f5c996b-ba3e-4d06-b111-f1c96d96ead8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5f5c996b-ba3e-4d06-b111-f1c96d96ead8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5f5c996b-ba3e-4d06-b111-f1c96d96ead8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9eafc18f-4e5d-48e5-bcc2-e526881c62d7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9eafc18f-4e5d-48e5-bcc2-e526881c62d7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9eafc18f-4e5d-48e5-bcc2-e526881c62d7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[df['Conc\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"traindriver\",\n          \"pharmaceutics\",\n          \"tush\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bigram\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.44723595562074375,\n        \"min\": 3.77,\n        \"max\": 4.85,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.54\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.SD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4236507995979708,\n        \"min\": 0.37,\n        \"max\": 1.41,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.71\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unknown\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 25,\n        \"max\": 29,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          29\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Percent_known\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06099180272790762,\n        \"min\": 0.85,\n        \"max\": 1.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SUBTLEX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29,\n        \"min\": 0,\n        \"max\": 66,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dom_Pos\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[(df['Conc.M']>=3.5)&(df['Conc.SD']<1.0)].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "rigM-ymVyiQD",
        "outputId": "c4b29710-1b93-4a88-bbf4-b8d60578eec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Bigram  Conc.M  Conc.SD  Unknown  Total  Percent_known  SUBTLEX  \\\n",
              "Word                                                                           \n",
              "roadsweeper       0    4.85     0.37        1     27           0.96        0   \n",
              "traindriver       0    4.54     0.71        3     29           0.90        0   \n",
              "sled              0    5.00     0.00        0     28           1.00      149   \n",
              "plunger           0    4.96     0.20        0     26           1.00       48   \n",
              "human             0    4.93     0.26        0     28           1.00     6363   \n",
              "\n",
              "               Dom_Pos  \n",
              "Word                    \n",
              "roadsweeper          0  \n",
              "traindriver          0  \n",
              "sled         Adjective  \n",
              "plunger      Adjective  \n",
              "human        Adjective  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-08ee70af-6e17-400e-8667-27b2a12e3474\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bigram</th>\n",
              "      <th>Conc.M</th>\n",
              "      <th>Conc.SD</th>\n",
              "      <th>Unknown</th>\n",
              "      <th>Total</th>\n",
              "      <th>Percent_known</th>\n",
              "      <th>SUBTLEX</th>\n",
              "      <th>Dom_Pos</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>roadsweeper</th>\n",
              "      <td>0</td>\n",
              "      <td>4.85</td>\n",
              "      <td>0.37</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>traindriver</th>\n",
              "      <td>0</td>\n",
              "      <td>4.54</td>\n",
              "      <td>0.71</td>\n",
              "      <td>3</td>\n",
              "      <td>29</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sled</th>\n",
              "      <td>0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>1.00</td>\n",
              "      <td>149</td>\n",
              "      <td>Adjective</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>plunger</th>\n",
              "      <td>0</td>\n",
              "      <td>4.96</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>1.00</td>\n",
              "      <td>48</td>\n",
              "      <td>Adjective</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>human</th>\n",
              "      <td>0</td>\n",
              "      <td>4.93</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>1.00</td>\n",
              "      <td>6363</td>\n",
              "      <td>Adjective</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08ee70af-6e17-400e-8667-27b2a12e3474')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-08ee70af-6e17-400e-8667-27b2a12e3474 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-08ee70af-6e17-400e-8667-27b2a12e3474');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b903349c-c1b0-4b68-a707-8fbc1f0004fa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b903349c-c1b0-4b68-a707-8fbc1f0004fa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b903349c-c1b0-4b68-a707-8fbc1f0004fa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[(df['Conc\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"traindriver\",\n          \"human\",\n          \"sled\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bigram\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18501351301999533,\n        \"min\": 4.54,\n        \"max\": 5.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          4.54\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.SD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.26185874054535585,\n        \"min\": 0.0,\n        \"max\": 0.71,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.71\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unknown\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 26,\n        \"max\": 29,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          29\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Percent_known\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04381780460041328,\n        \"min\": 0.9,\n        \"max\": 1.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.96\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SUBTLEX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2824,\n        \"min\": 0,\n        \"max\": 6363,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          149\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dom_Pos\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Adjective\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "applying functions\n",
        "43\n",
        "• iterating over (large) Series and DataFrames is slow\n",
        "- alternative is to apply() a function to the dataset\n",
        "- for example, we may decide that lexical items with\n",
        "concreteness score ≥ 3 is concrete, and abstract otherwise"
      ],
      "metadata": {
        "id": "dmgW6KH5zHZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def map_concreteness(x):\n",
        "  if x>=3:\n",
        "    return 'concrete'\n",
        "  else:\n",
        "    return \"abstract\"\n",
        "df['concreteness_category'] = df['Conc.M'].apply(map_concreteness)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "bJE2S1j7y_1r",
        "outputId": "4144975b-6e15-4d9d-f474-618bd7ec16a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Bigram  Conc.M  Conc.SD  Unknown  Total  Percent_known  \\\n",
              "Word                                                                    \n",
              "roadsweeper         0    4.85     0.37        1     27           0.96   \n",
              "traindriver         0    4.54     0.71        3     29           0.90   \n",
              "tush                0    4.45     1.01        3     25           0.88   \n",
              "hairdress           0    3.93     1.28        0     29           1.00   \n",
              "pharmaceutics       0    3.77     1.41        4     26           0.85   \n",
              "\n",
              "               SUBTLEX Dom_Pos concreteness_category  \n",
              "Word                                                  \n",
              "roadsweeper          0       0              concrete  \n",
              "traindriver          0       0              concrete  \n",
              "tush                66       0              concrete  \n",
              "hairdress            1       0              concrete  \n",
              "pharmaceutics        0       0              concrete  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dfd18c88-02b7-4052-8051-492a33562d9d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bigram</th>\n",
              "      <th>Conc.M</th>\n",
              "      <th>Conc.SD</th>\n",
              "      <th>Unknown</th>\n",
              "      <th>Total</th>\n",
              "      <th>Percent_known</th>\n",
              "      <th>SUBTLEX</th>\n",
              "      <th>Dom_Pos</th>\n",
              "      <th>concreteness_category</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>roadsweeper</th>\n",
              "      <td>0</td>\n",
              "      <td>4.85</td>\n",
              "      <td>0.37</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>traindriver</th>\n",
              "      <td>0</td>\n",
              "      <td>4.54</td>\n",
              "      <td>0.71</td>\n",
              "      <td>3</td>\n",
              "      <td>29</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tush</th>\n",
              "      <td>0</td>\n",
              "      <td>4.45</td>\n",
              "      <td>1.01</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "      <td>0.88</td>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hairdress</th>\n",
              "      <td>0</td>\n",
              "      <td>3.93</td>\n",
              "      <td>1.28</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pharmaceutics</th>\n",
              "      <td>0</td>\n",
              "      <td>3.77</td>\n",
              "      <td>1.41</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfd18c88-02b7-4052-8051-492a33562d9d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dfd18c88-02b7-4052-8051-492a33562d9d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dfd18c88-02b7-4052-8051-492a33562d9d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3da03230-6b51-4b87-b788-0c30c3d5397f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3da03230-6b51-4b87-b788-0c30c3d5397f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3da03230-6b51-4b87-b788-0c30c3d5397f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 39954,\n  \"fields\": [\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39953,\n        \"samples\": [\n          \"sexually\",\n          \"revisionism\",\n          \"compressor\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bigram\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0386021803079468,\n        \"min\": 1.04,\n        \"max\": 5.0,\n        \"num_unique_values\": 368,\n        \"samples\": [\n          3.16,\n          4.68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.SD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.31093059573336734,\n        \"min\": 0.0,\n        \"max\": 1.89,\n        \"num_unique_values\": 165,\n        \"samples\": [\n          0.56,\n          1.63\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unknown\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 620,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1,\n          19\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 174,\n        \"min\": 21,\n        \"max\": 6072,\n        \"num_unique_values\": 37,\n        \"samples\": [\n          5870,\n          6064\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Percent_known\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04500878702071559,\n        \"min\": 0.85,\n        \"max\": 1.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.96,\n          0.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SUBTLEX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22420,\n        \"min\": 0,\n        \"max\": 2134713,\n        \"num_unique_values\": 2737,\n        \"samples\": [\n          819,\n          3602\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dom_Pos\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"0\",\n          \"Adjective\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"concreteness_category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"abstract\",\n          \"concrete\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "plotting data\n",
        "• pandas is integrated with Matplotlib, so we can plot\n",
        "directly form DataFrames and Series"
      ],
      "metadata": {
        "id": "WTHF5vHXzngh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'font.size':18, \"figure.figsize\":(8,8)})\n",
        "df['Conc.M'].plot(kind='hist',title = 'Concreteness Ratings')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "id": "_UExp8_1zdYq",
        "outputId": "44663a6d-c148-4355-9aa7-bb4b2e26965f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: title={'center': 'Concreteness Ratings'}, ylabel='Frequency'>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuYAAAK9CAYAAABo0KlnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB1L0lEQVR4nO3dd3xUVf7/8fckpDdCM/QEAUFARRQXCSgKBAQ0yoJIFQUiuu6q4C64CAFd6er3uyBKEXHlK0tRRKUaQIpYKIoUWYS0DUhJ4qSHlPn9kUfub0Imk8AEchNez8djHo+bOedz75khwDsnZ8612Gw2mwAAAABUKbeqHgAAAAAAgjkAAABgCgRzAAAAwAQI5gAAAIAJEMwBAAAAEyCYAwAAACZAMAcAAABMgGAOAAAAmADBHAAAADABgjkAAKiwuLg4WSwWWSwWPfnkk1U9HKBGqVXVAwBQPSQlJWndunWKiYnRsWPHdPHiRWVmZiooKEhNmjTR3Xffrb59+6pfv37y9PSs6uHWeL///rvefvttSdIdd9yhyMjIKh0PyvfBBx9o9OjRDtvc3d0VFBSkpk2bqnPnzho2bJjuu+++6za26OhoSVJoaChhG6hCFpvNZqvqQQAwL6vVqilTpmjJkiXKzc0tt3/9+vU1ZcoUjR8/Xh4eHtdhhDemuLg4hYWFSZJGjRqlDz74oGoHhHI5C+aOREZG6qOPPpKfn981HFURi8UiSbrvvvu0c+dOp3353gOuHWbMAZTp119/1YABA/TLL78Yz3Xu3Fm9evVSaGiogoKClJycrFOnTmnz5s06cuSILly4oL/85S+67bbbdP/991fd4AET69Gjh/785z8bXxcUFOi3337TV199pc8++0w2m03r16/X8OHD9emnn1bhSEsLDQ0Vc3rAtUEwB+BQcnKyHnzwQSUkJEiSbrvtNr377rvq0qWLw/5z587V999/r7///e/66quvrudQgWqnWbNmDpcfPffcc1q/fr0GDhyowsJCrV+/Xnv37lXXrl2v/yABXHd8+BOAQ6NGjTJCeZcuXbR79+4yQ3mxzp07a9u2bXrzzTdZxgJcpcjISD322GPG1xs2bKjC0QC4ngjmAErZt2+fvvzyS0lSQECAPv74YwUGBla4/sUXX3Q6w/fdd99p3LhxuuWWWxQQECA/Pz/dfPPNGjVqlLZv317u+Yt3hCheKpOZmal58+bprrvuUnBwsPz8/NSuXTtNnjxZqampFRpz8dKBESNGqFWrVgoMDJSnp6caNmyonj176o033lBcXFypuujoaGM8xWtzY2Ji9MQTTygsLEze3t6yWCwOa48ePaqXXnpJd9xxh+rUqSMvLy81btxYDz/8sFauXKnCwsJSNcU7YhSv8ZWkFStWGGOwfzi6piRdvHhR//jHP9StWzeFhITI09NT9evXV7du3TRnzhxlZGQ4fa9CQ0NlsVgUGhoqScrPz9fixYsVHh6uevXqycfHR61atdKf/vQn/fe//3V6LnubN2/Wk08+qVatWikgIEC+vr66+eab9eSTT2rPnj3l1ufk5Oidd95Rr1691LBhQ3l5ecnf31+hoaG6++679fTTT2vNmjW6dOmSw/qTJ09qwoQJ6tSpk2rXri0PDw/VrVtXt9xyix544AG98sor+vHHHyv8elzRrVs34/g///lPmf0uXLigpUuXavjw4Wrfvr0CAwPl4eGhevXq6Q9/+IOmTp2q3377rcz64u+VYl9//bXD7yX7decV2ZXl/vvvL3XuVatWqVevXgoJCZGXl5eaN2+uJ598ssRSOWfOnTunv/71r7r11lvl5+enOnXqqHPnzpo/f76ysrIklf7edOTMmTOaOnWqunTpojp16sjDw0PBwcFq1aqVunXrppdeekm7d++u0JiASmcDgMsMHjzYJskmyfbnP/+50s6bl5dnGzt2rHHush6DBw+2ZWVllXme4n733Xef7dSpU7Zbb721zHM1b97cFhsb63Rcv/76q+3OO+8sd1yhoaGlaqdNm2a0b9++3fbcc885rLUfQ15enu3Pf/6zzc3Nzen17rnnHtvZs2dLXC82NrbccTq6ZrHly5fbAgICnNbddNNNtm+++abM96t58+bGe3vhwgVb165dyzxXcHCwbf/+/U7f//Pnz9seeOCBcl/P008/bbt06VKZf4YtW7as0Pty6NChUvVLliyxeXp6llt7++23O30tzixfvtw4z6hRo5z2fffdd42+ffr0cdjn1KlTNnd393LH7OfnZ1u3bp3Dc1T0e2nHjh1Gjf33YFmv47777jP6ZGdn2yIjI8s8t5eXl23jxo1O34/t27fbgoODyzxHhw4dbAkJCSW+Nx354osvbP7+/uW+3qCgIKfjAa4V1pgDKMFmsykmJsb4esSIEZV27hEjRmjVqlWSJG9vb40aNUr33nuv3N3dtX//fi1btkzp6elavXq1rFarNm3aVGLG7XJpaWnq16+fTpw4oUceeUR9+vRRnTp1dPr0aS1atEgJCQmKj4/XyJEjtWvXLofn+M9//qMuXbooJSVFktSwYUM9/vjjuv322+Xn56fz589r//79+uKLL8r9wNvcuXO1adMmhYSE6Mknn1T79u2Vn5+v77//Xl5eXpKK3t/BgwcbH+hr2LChhgwZottvv12+vr6Kj4/XqlWrdODAAX333Xd68MEH9cMPP8jX11eS1KBBA3366ac6f/68oqKiJJX+IGGxBg0alPj6f/7nf/TCCy9Iknx9ffXHP/5R9957r+rWrauLFy9q8+bN2rBhg86dO6eePXvqhx9+0K233lrm683Pz9fAgQO1d+9e9ejRQ5GRkWrYsKGSkpK0dOlSHT16VKmpqRoyZIiOHj3qcBvNlJQUdenSRadOnZIk3X777XrsscfUsmVLubm56ciRI/rggw+UlJSkZcuWKT8/v9QuIDabTYMGDdKvv/4qqWj7yD/+8Y9q0aKFPDw8lJqaquPHj2vHjh0OZ7wPHjyoqKgoFRYWqlatWho4cKC6d++uBg0aKC8vT2fPntWhQ4e0devWMt+Lynb06FHjuFmzZg77XLp0SQUFBWrRooUefPBBtW/fXvXr11dhYaESEhL01Vdfafv27crMzNSQIUO0d+9e3X333SXOUfx9+Oijj0qS2rVrp9dff73Utdq3b3/Vr+Wpp57S+vXr1alTJw0ZMkTNmjXTxYsXtXLlSn3zzTfKzc3V8OHDdeLECdWrV69U/bFjx9S/f39jVrxjx44aPny4mjRponPnzunf//639u7dq8cff1z5+flljiMpKUlDhgwxfiPUr18/9erVS40aNVJhYaHOnz+vn376Sdu2bZPVar3q1wu4pGp/LgBgNseOHTNmjXx8fGx5eXmVct5Vq1aVmJE9evRoqT5xcXG2sLAwo9+CBQscnkt2M1uenp62zz//vFSfixcvljjXd999V6pPfn6+rUOHDkafYcOG2TIzMx1e89KlS7YNGzaUet5+xlySLTw83Ga1Wst8H95++22j7/Dhwx1er7Cw0PbKK68Y/f72t7+V6lORWUt7P/zwg61WrVo2SbY77rjDFh8f77Df559/bvPw8DBm7B0pnpUsfrz33nul+mRnZ9vuueceo8+///1vh+cqnkm1WCy2t99+22Gf9PR0W+/evY1zbdq0qdRrK27r37+/LT8/v8z34ejRo7aLFy+WeM7+txxljdNmK/p+2bt3b5nt5anojHliYqKtdu3aRt/ly5c77JecnFzueLZv327z8/OzSbLdf//9ZfYrvtZ9991X7uu40hlzSba///3vtsLCwhJ9CgoKSsykz5492+G5wsPDjT7PPvusraCgoFSfy/8eOpoxnzt3brnXstmK/v7t2rWr7DcAuIYI5gBK2LZtm/GfV5s2bSrtvB07djTO6+zX1t99953NYrEY/7k6Cln2/wHPmDGjzHMtWbLEab+VK1eWCNSO/sMvj30g8PPzsyUlJZXZNzs729agQQObJNvdd99d7vW6detmk2QLDAy0ZWdnl2i70mA+YMAAmyRbQECA7b///a/Tvq+++qpxbkfBzz6YP/XUU2Wex/57yVG/AwcOGO0vvfSS0zGlpKTYgoKCbJJsvXr1KtH28ccfG+f55JNPnJ7HkYiICGP5wuXhsTI5C+b5+fm2pKQk2wcffGBr2rSp0a9p06a23Nxcl647depU43wJCQkO+1zLYP7AAw+Uea6TJ0867Wf/Q1f79u2d/tBlf01HwTwqKspoT0lJKfd1AlWBD38CKCE5Odk4rl27dqWcMy4uTocOHZIkdejQQX379i2zb+fOnfXAAw9IkuLj43XgwIEy+7q7u+tPf/pTme3F55GKfh1+uZUrVxrHr7/+utzcXPsnceDAgWrUqFGZ7Vu2bNH58+clFX1AtrzrDR8+XFLRkp1vv/32qseVmppqfJj3iSeeUOPGjSt0XUnlLt/4y1/+UmZb9+7dVatW0YpJR+//v/71L0lFH0CcMGGC0+sEBwfroYcekiTt2rWrxM2uipf5SCWXgFRUcX16eroSExOvuP5qXP6B3Vq1aqlx48Z68sknjTGEhIRoy5YtLt9J99577zWOv//+e5fOdTWcfY+0bNlSTZs2leT4e+Szzz4zjp977jm5u7tf1XUk179PgOuBNeYArjn7MNC7d+9y+/fu3dtY5/7dd9+pc+fODvu1bt1awcHBZZ7HPoA62p2leKeP2rVrq3v37uWOqzz2O2k4Yr/TQ2pqqtavX++0f1JSknF8/Pjxq75h0969e40dXtzd3cu9bl5eXonrlsXX11cdOnQos93T01P16tXTb7/95vD9L34/ateuXaHAWBzGc3Nzdfr0abVt21aSFB4eLh8fH2VnZ2v69OlKTU3VqFGjdNttt5V7Tknq1auXPv30UxUWFur+++/XK6+8osjISIfrna+XCRMmaOrUqRXaDeno0aNasWKF9u7dq5MnT8pqtZa588yV7JJTWf7whz84bW/cuLESExMdfo/s37/fOO7Ro4fT85T396NXr1566623JEmPPfaYJk+erEGDBqlJkyZO64DriWAOoIS6desax7///nulnPPs2bPGcevWrcvtb9/HvvZy5QWn4g9cSkVb6dlLT09XWlqaJOmWW25x+iHTiipvJtp++8Lnnnvuis5d0W0fy7vuokWLtGjRokq5bt26dct934r/DC5//+3HlZqaanz48GrGVadOHb311lsaP3688vPz9eabb+rNN99UgwYNdO+996pbt27q27evEeQv9/TTT2v16tXauXOnYmNjNXbsWI0bN07t2rXTvffeq/vvv18PPfSQgoKCrmiMzlz+gd2LFy/q8OHD+uCDD5Senq7FixerV69eioiIKPMcNptNkyZN0rx58xxurelI8ff89VTRv6f2vwUpdubMGeO4RYsWTs8THBys2rVrl/nvVt++fTV06FD93//9ny5cuKCXXnpJL730klq1aqV7771X3bt3V//+/Ut9aBq4nljKAqAE+6UY8fHxTnc5qKj09HTj2M/Pr9z+/v7+Dmsv58rSE/uAYn89V/j4+Dhtd2Wnh7JmQCviWl3X1aU/lTmuqKgo7dixQw8++KAxrvPnz2v9+vWaMGGCbr31VnXt2tXhzLynp6e2bNmiuXPnGvtf22w2HTlyRIsXL9bQoUN100036U9/+lOlBdviO38WP8aMGaP//d//1YkTJ9SqVSulp6crMjJShw8fLvMcb7zxhubMmaPCwkK5u7srIiJC06dP1/Lly7V69Wp9+umn+vTTT/Xaa68ZNQUFBZUy/ivhyvdJZmamJKlWrVoVumlZef++fPTRR1q6dKnatWtnPHfy5EmtWLFCTz/9tBo1aqShQ4c6nRAAriVmzAGU0LZtW9WpU0cpKSnKzs7Wjz/+qLvuusulcwYEBBjHxf/ROmN/gxv72spkv0SgvBvqVBb7HwBOnz5d4iZB1+u677//vkaPHn1drlsef39//f7772rWrJni4+NdPt99992n++67T8nJydq9e7f27dunr7/+Wj/88IMKCwv1zTffKDw8XFu3bi217MHT01MTJ07UxIkTdezYMe3du1d79+5VTEyM/vvf/yo3N1cLFy7Unj17tG/fvnJ/CLtaDRs21KpVq9S5c2fl5ORo+PDhOnToUKm11dnZ2Zo5c6akor8jO3bsUKdOnRyeszrfhbc4aOfn5ysvL6/c11Levy8Wi0VPP/20nn76aZ0+fVp79uzRN998o+3bt+vkyZMqKCjQxx9/rD179uiHH37QTTfdVGmvBagIZswBlGCxWNSzZ0/j6+IP6LmiYcOGxvHJkyfL7W/fx9mHKV0REBBgLE04ceJEuXuUVwb7pS7Xc61vVV23PMXjOn/+fIl17a6qW7euIiMjNXv2bH377bdKSEjQ0KFDJRWtn584caLT+ltvvVVjx47VBx98oMTERG3fvt2YSf/pp5+0bNmyShurI3feeadGjRolSfr555+1fPnyUn327dtnhNCoqKgyQ7mkSvmhp6rY//0/ffq0076pqalXtPyuRYsWGjlypN5991395z//0YEDB9SxY0dJUmJioubOnXtVYwZcQTAHUIr97gbLly93+T92+w9vbtu2rdz+9juBlPXBz8oQHh4uqWgtfVk3IKpM9913n3Hs6s1q7JcHlPdDRffu3Y214NfzJjnlKX4/cnJyrun737hxY61YsUIhISGSpAMHDig7O7vC9T169NCCBQuMr4s/NHwt/f3vfzdmyadPn15q6c65c+eM45tvvtnpubZs2VLu9Yq/P67HD6hXwv63dTt27HDad+fOnS5d68477ywxEXE9/pyByxHMAZRy7733GlvTpaen64knnnC61vtyb7/9tr755hvj69DQUN15552SZNxZryz79+/X9u3bJUnNmzd3OhPoKvttAadMmVLhD9BdrYceesj4INw777zj0jpW++Up5f36vkGDBurTp4+korBhlnA+cuRI43j69OnXdP1zrVq1Suy+caWfnSieMb+a2qvRokULPf7445KKfsuxdOnSEu32W/8V3zXVkYMHD+qLL74o93rF308VWWp2PT3yyCPG8cKFC51+j/zP//yPy9e73n/OwOUI5gAcWrFihRFk9u3bp/Dw8HL30v7+++/Vu3dvvfjii6Vm+P72t78Zx6NGjdIvv/xSqj4hIUFDhgwxAvLLL7/sdN9iVw0aNMjYUm/Pnj0aOXKkcdvvy+Xn5xt7gV8tPz8/TZs2TVLRrej79OlT7tKe7777Tn/9619LPV+nTh1jKc6PP/5Y7kzn66+/bqzPHTJkiDZv3uy0f3x8vCZOnGjsu34t3HPPPRo4cKCkoq0Thw0b5vTDlfn5+frkk0+0cOHCEs+vXLlSy5cvdzoL/u233xp76bdo0aLEZxcmTJhQ7ve2/U42t99+u9O+lWXSpEnGTPbMmTNL7FpiP5O8dOlSxcbGlqo/efKkBg4cWKEfOIs/7/DLL79c0W8TrrW77rrL+M3WkSNH9Oc//9nh64mOjtbXX3/t9FwzZszQtm3bnL4f77zzjnF8vf6cAXt8+BOAQ/Xq1VNMTIwGDBig//znPzp8+LC6dOmie+65R7169VJoaKgCAwOVkpKiU6dOafPmzfr555/LPN/gwYP16aefatWqVTp79qzuvPNOPfnkk+rSpYvc3d21f/9+LVu2zAhmvXv31rPPPntNX6O7u7vWrFmjLl26KCUlRStXrtT27ds1ZMgQ3X777fL19dXFixd18OBBff755/L29la/fv1cuuaf/vQn/fDDD/rwww91+PBh3XrrrXr44YfVvXt3NWzYUAUFBbpw4YJ+/vlnxcTEKDY2VjfffLPmzJlT6lwPPPCAPv30U506dUqPP/64HnvssRI3hbrvvvuMDyneeeedWrRokcaOHavU1FT17dtXXbt2Vd++fRUWFiYPDw+lpKTol19+0Z49e4z9o1944QWXXm953n//ff3nP//Rzz//rH//+9/asmWLBg8erLvuukvBwcHKzs5WUlKSDh06pG3btik1NVVPP/10iXOcPHlS06dP1/PPP69evXrp7rvvVtOmTeXl5aXz589r9+7dWr9+vTHb+sorr5SoX7dund58802FhYWpZ8+euu2229SgQQPl5uYqMTFRa9as0Y8//iipaP36uHHjrul7UqxDhw7q16+fvvjiC2PWvHibzcaNG+uxxx7TJ598ot9//1233367oqKidNtttxkfdP3www+Vk5OjkSNH6sMPP3R6rQcffFCHDx9WZmamBgwYoFGjRqlevXrGDwadO3dWnTp1rvlrduS9997T3XffraysLL3zzjvat2+fhg8friZNmujcuXP697//rb1796pLly5KSEhQUlKSw51gtm/frmnTpikkJEQRERG64447FBISosLCQp05c0YbNmww9tb38vLSSy+9dL1fKiBV5W1HAZhfamqqbfz48TZPT0/jdtbOHiEhIbaFCxfa8vLySp0rLy/PNmbMmHLP8cc//tGWlZVV5piK+1Xk9uEV6fuf//zH1qFDh3LHFRYWVqp22rRpRvuOHTvKHY/NZrMVFhbaXnvtNZuXl1eF3tOyxn7o0CGbj49PmXWxsbGlajZs2GC76aabKnTdunXr2i5cuFDqHM2bNy/ztudX09dqtdoef/zxCo1Jku3VV18tUR8dHV2hOg8PD9usWbNKXT80NLRC9c2bN7cdPHiw3NdcluXLl5d7K/vL7d2716hp0qSJLScnx2i7ePGi0+9bNzc322uvvWbbsWOH8dy0adMcXue///2vrX79+mWey/57OzY2ttzXcd999xl9ylORvtu3b7fVrl27zPG1b9/elpCQYGvcuLFNku22224rdY7777+/Qn/O9erVs23ZsqXccQPXAjPmAJyqXbu23nnnHb3yyitau3atYmJidOzYMV28eFFZWVkKCgpSs2bNdPfdd6tfv3566KGHjNuwX65WrVpasmSJnn76aS1dulRff/21zp49q8LCQoWEhKhr164aPXq0Hnjggev6Glu1aqUff/xRa9as0dq1a/X999/rwoULKigoUL169dSuXTv17NmzxJp0V1gsFk2ZMsV4H2JiYnTixAmlpKTIzc1N9erVU5s2bdSlSxc99NBDZd458Y477tCBAwf05ptvavfu3UpMTCxzKU6xAQMGKDY2Vh9++KE2btyoQ4cO6eLFiyooKFBQUJBatmypu+66S71791bv3r1dvh18RQQGBmrVqlX629/+pg8//FBff/21EhISZLVa5e3trYYNG6pdu3bq3r27HnnkkVI3mvn73/+u+++/XzExMfr+++914sQJnTt3Tnl5eQoICFCrVq3Uo0cPjRkzRi1btix1/f3792vLli3avXu3Dh48qNOnT8tqtcrNzU3169fXbbfdpocfflgjR468ZtsklqX4xje7du0qNWtet25dffvtt/rf//1frV69WidOnJBUtAtS9+7dFRUVpXvuuadCH4ps3LixDh48qHnz5ikmJkZxcXHKzMw0zYdBe/TooV9++UXz5s3T559/roSEBHl5eally5YaMmSIxo8fLx8fH6WkpEiSw9n9DRs26KuvvtLXX3+tAwcO6Ndff1VycrIsFovq1Kmjdu3aqW/fvnr66adL/OYJuJ4sNrP8rQMAALhKP//8s/GZkT//+c+V8mFQ4Hrjw58AAKDas9/SskePHlU4EuDqEcwBAICp7d692+luKgsXLtTixYslFS3L6d+///UaGlCpWMoCAABMrWXLlsrJyVHfvn3VsWNH1a9fX3l5eTp16pQ+/fRTYytMSfr8888J5qi2COYAAMDUWrZs6fRGSpLk4+OjJUuWaNiwYddpVEDlI5gDAABT+/bbb7Vu3Tp9++23SkpKUnJysrKyshQcHKzWrVurZ8+eGj9+vG666aaqHirgEoI5AAAAYALsY17NFd+xLCAgwLhDGwAAAMzDZrMpPT1djRo1cnhn2mIE82ruzJkzatq0aVUPAwAAAOVITExUkyZNymwnmFdzAQEBkor+oAMDA6t4NAAAALhcWlqamjZtauS2shDMq7ni5SuBgYEEcwAAABMrb9lxtbnBkMViqfDD2R2/zp07pwkTJuiWW26Rj4+P6tSpo27dumnp0qWqyOdgT506paioKIWFhcnb21v169dXRESE1q1bV6HXcfDgQQ0fPlxNmjSRl5eXGjZsqEcffVTbt2+v8HsBAACAmqfa7MoSEhLitD0vL08pKSmSpJdffllz5swp1efAgQOKiIhQcnKyJMnf3185OTnKz8+XJEVERGjDhg3y9PR0eI2NGzdq0KBBysrKklQ0S52RkWHcjWz06NFatmxZmT8NLV26VOPHjzeuFxQUpLS0NOMHgmnTpik6Otrp67xcWlqagoKCZLVamTEHAAAwoYrmtWozY/7bb785fbzyyitG36effrpUvdVqVf/+/ZWcnKw2bdrohx9+UHp6ujIzM7VgwQJ5eHhoy5YteuGFFxxePzY2VoMHD1ZWVpa6du2qEydOyGq1ymq1aurUqZKk5cuXa+7cuQ7r9+3bp2eeeUb5+fmKjIxUYmKifv/9d124cEFRUVGSpOnTp2v16tUuvlMAAAColmw1RNu2bW2SbOHh4Q7bp0yZYpNk8/HxsZ0+fbpU+xtvvGGTZHN3d7edOHGiVPvw4cNtkmwhISG21NTUUu3jxo2zSbIFBgbaUlJSSrWHh4fbJNk6dOhgu3TpUqn2iIgImyRbaGioLT8/vwKvuIjVarVJslmt1grXAAAA4PqpaF6rNjPmznzzzTc6fvy4JGnMmDEO+3z44YeSpCFDhigsLKxU+/PPPy9/f38VFBRo5cqVJdoyMzONNeTjx49X7dq1S9VPnjxZUtGvKtavX1+i7fTp09qzZ48kaeLEifLw8CizPi4uTrt27SrrpQIAAKCGqhHBfNmyZZKK1mwPGjSoVPuJEyeUkJAgSerbt6/Dc/j7+6tbt26SpK1bt5Zo27Nnj7Kzs53Wh4aGqm3btg7rt23bZhz36dPHYX14eLixhc7l9QAAAKj5qn0wz8jIMNZlP/HEE/L19S3V58iRI8Zx+/btyzxXcduxY8dcqj969KjD+gYNGqhBgwYOa93d3dWmTRuH9QAAAKj5qn0wX7VqlTIyMiSVvYzlzJkzxnHjxo3LPFdxW1pamnFO+/rg4GD5+PiUW29/PfuvnV3bWb293NxcpaWllXgAAACg+qv2wXzp0qWSpNtvv12dOnVy2Cc9Pd04djSj7qjNvqb42Fmtfbt9bWXU25s5c6aCgoKMR9OmTZ2eEwAAANVDtQ7mR48e1XfffSep7Nnymmby5MnGNo1Wq1WJiYlVPSQAAABUglpVPQBXFM+We3t7a/jw4WX2K/5QpSRlZWWVubF78Y2DLq8pPrZvd1ZvX1sZ9fa8vLzk5eXl9DwAAACofqrtjPmlS5f00UcfSZIGDhzocAvDYo0aNTKOk5KSyuxX3BYYGCh/f/9S9ampqcbuLM7q7a9n/7WzazurBwAAQM1XbYP5Z599posXL0oqfxmL/U4q9jusXK647dZbb3Wpvl27dg7rz58/rwsXLjisLSgo0C+//OKwHgAAADVftQ3mxctYWrZsqfvuu89p39atW6tZs2aSpM2bNzvsk5mZqd27d0uSevfuXaItPDzc2I2lrPr4+HjjJkeX1/fq1cs4Lqt+7969xoc+L68HAABAzVctg3lCQoK++uorSdJTTz0li8XitL/FYtHIkSMlFW2vGBcXV6rPwoULlZGRIXd3dw0bNqxEm5+fnwYOHChJWrRokaxWa6n62bNnSypaHx4ZGVmirUWLFgoPD5ckzZ8/X3l5eaXqZ82aJUlq3ry5unfv7vT1AAAAoOaplsH8/fffV2FhoWrVqqUnn3yyQjUTJ05USEiIsrKy1K9fPx04cEBS0Vr1RYsW6dVXX5UkjRs3Tq1bty5VP2PGDPn5+ens2bMaMGCATp48Kalopn3GjBl69913JUlTpkxRcHBwqfrZs2fL3d1dP/30k4YMGWKsJ09JSdGzzz6rTZs2SZLmzJkjd3f3K3tDAAAAUO1ZbDabraoHcSUKCwsVFhamhIQEPfzww/rss88qXHvgwAFFREQoOTlZUtHsdk5OjjGD3bt3b23YsKHMXU82btyoQYMGGbunBAUFKSMjQwUFBZKk0aNHa9myZWXO4C9dulTjx49Xfn6+JKl27dqyWq0q/iOYNm2aoqOjK/x6pKKbIQUFBclqtZa52wwAAACqTkXzWrWbMf/qq6+UkJAg6cr3Lu/UqZOOHj2qF198Ua1atVJeXp78/PwUHh6uJUuWaNOmTU63InzooYd0+PBhjR07VqGhocrJyVFwcLB69eqltWvX6v3333e6rGbMmDH67rvvNHToUDVu3FhZWVlq0KCBIiMjFRMTc8WhHAAAADVHtZsxR0nMmAMAAJhbjZ0xBwAAAGoigjkAAABgAgRzAAAAwAQI5gAAAIAJEMwBAAAAEyCYAwAAACZAMAcAAABMgGAOAAAAmECtqh4AgOsvdNKXVT2EaypuVr+qHgIAAFeMGXMAAADABAjmAAAAgAkQzAEAAAATIJgDAAAAJkAwBwAAAEyAYA4AAACYAMEcAAAAMAGCOQAAAGACBHMAAADABAjmAAAAgAkQzAEAAAATIJgDAAAAJkAwBwAAAEyAYA4AAACYAMEcAAAAMAGCOQAAAGACBHMAAADABAjmAAAAgAkQzAEAAAATIJgDAAAAJkAwBwAAAEyAYA4AAACYAMEcAAAAMAGCOQAAAGACBHMAAADABAjmAAAAgAkQzAEAAAATIJgDAAAAJkAwBwAAAEyAYA4AAACYAMEcAAAAMAGCOQAAAGACBHMAAADABAjmAAAAgAkQzAEAAAATIJgDAAAAJkAwBwAAAEyAYA4AAACYAMEcAAAAMAGCOQAAAGACBHMAAADABAjmAAAAgAkQzAEAAAATIJgDAAAAJkAwBwAAAEyAYA4AAACYAMEcAAAAMAGCOQAAAGACBHMAAADABAjmAAAAgAkQzAEAAAATIJgDAAAAJkAwBwAAAEyAYA4AAACYAMEcAAAAMAGCOQAAAGACBHMAAADABAjmAAAAgAlUy2Celpam2bNn695771X9+vXl5eWlJk2aqEePHoqOjtbvv//usC49PV3R0dHq0KGD/P39FRQUpLvvvlvz58/XpUuXyr3uuXPnNGHCBN1yyy3y8fFRnTp11K1bNy1dulQ2m63c+lOnTikqKkphYWHy9vZW/fr1FRERoXXr1l3pWwAAAIAaxmKrSKI0kR07duiJJ57QuXPnJEmenp7y9fUtEcYPHTqkO+64o0RdfHy87r//fsXFxUmSfH19VVBQoNzcXElSx44dFRMTo+DgYIfXPXDggCIiIpScnCxJ8vf3V05OjvLz8yVJERER2rBhgzw9PR3Wb9y4UYMGDVJWVpYkKTAwUBkZGSosLJQkjR49WsuWLZPFYrmi9yMtLU1BQUGyWq0KDAy8olrcuEInfVnVQ7im4mb1q+ohAABgqGheq1Yz5nv37lW/fv107tw5PfbYY/rhhx+Uk5Oj1NRUZWZm6vvvv9ff//53BQUFlajLz8/XgAEDFBcXp4YNG2rbtm3KzMxUVlaWVq1apYCAAB06dEjDhw93eF2r1ar+/fsrOTlZbdq00Q8//KD09HRlZmZqwYIF8vDw0JYtW/TCCy84rI+NjdXgwYOVlZWlrl276sSJE7JarbJarZo6daokafny5Zo7d26lvl8AAACoPqrNjHlWVpY6dOig06dP6/nnn9f//u//Vrh22bJlGjNmjCTpm2++UZcuXUq0f/zxxxo6dKgk6auvvtKDDz5Yov3VV1/V66+/Lh8fHx09elRhYWEl2mfOnKlXXnlF7u7uOnbsmFq3bl2ifcSIEfroo48UEhKi48ePq3bt2iXao6KitHjxYgUGBiouLq7MWXtHmDHH1WDGHACA66fGzZj/61//0unTpxUSEqI5c+ZcUe2KFSskST169CgVyiVpyJAhRtj+8MMPS7UXP2ffz97zzz8vf39/FRQUaOXKlSXaMjMzjTXk48ePLxXKJWny5MmSiv7Q1q9fX/EXBgAAgBqj2gTz4nA8aNAgeXt7V7guKytLe/fulST17dvXYR+LxaI+ffpIkrZu3Vqi7cSJE0pISHBa7+/vr27dujms37Nnj7Kzs53Wh4aGqm3btg7rAQAAcGOoFsE8NzdX+/fvlyR16tRJCQkJGjdunJo2bSpPT0/ddNNNGjBggL78svSv548fP258wLJ9+/ZlXqO47bffflNKSorx/JEjR0r1cVZ/7NixEs9faf3Ro0fL7AMAAICaq1oE87i4OGM7w9OnT6t9+/ZasmSJzp8/Lz8/P50/f15ffPGF+vfvr7Fjx5bYuvDMmTPGcePGjcu8hn2bfc2V1qelpSkjI6NUfXBwsHx8fMqtt7+eI7m5uUpLSyvxAAAAQPVXLYJ5amqqcfz666/Lw8NDa9asUUZGhlJTUxUfH69BgwZJkpYuXaq33nrL6J+enm4c+/r6lnkN+zb7msqqd1Zr325f68jMmTMVFBRkPJo2beq0PwAAAKqHahHMi5eiFB8vW7ZMf/zjH+Xh4SFJatasmVatWqXbb79dkvTGG28Y+4vXNJMnTza2WrRarUpMTKzqIQEAAKASVItgHhAQYBy3atVKkZGRpfq4ublp4sSJkqTk5GQdOHCgVG3xzX0csW+zr6mseme19u32tY54eXkpMDCwxAMAAADVX7UI5vZru9u0aVNmv1tvvdU4jo+PlyQ1atTIeC4pKanMWvs2+5orrQ8MDJS/v3+p+tTUVGN3Fmf19tcDAADAjaNaBPM6deo4/eBlMfsPfRbf2r5t27Zycyt6mfY7pFyuuC0kJER16tQxnrffSaUi9fY/HFxNfbt27crsAwAAgJqrWgRzSerdu7ekou0Py2K/VWHxjYB8fX3VtWtXSdLmzZsd1tlsNm3ZsqXEdYq1bt1azZo1c1qfmZmp3bt3O6wPDw83dmMpqz4+Pt54XZfXAwAA4MZQbYL56NGjJUm//vqrw7tjFhYWat68eZKKlr7ceeedRtuoUaMkSTt27NB3331XqnbNmjU6ffq0JGnkyJEl2iwWi/HcqlWrFBcXV6p+4cKFysjIkLu7u4YNG1aizc/PTwMHDpQkLVq0SFartVT97NmzJRWtL3e0fh4AAAA1X7UJ5t26ddMf//hHSdKYMWO0bt06Y+eVhIQEPfHEEzp8+LAk6R//+IexfEUqCuYdOnSQzWbTwIEDFRMTI6kozK9Zs0Zjx46VVHRnzgcffLDUtSdOnKiQkBBlZWWpX79+xgdLL126pEWLFunVV1+VJI0bN06tW7cuVT9jxgz5+fnp7NmzGjBggE6ePCmpaKZ9xowZevfddyVJU6ZMUXBwsOtvFgAAAKodi81+YbbJZWZm6qGHHtKuXbskFe1Q4uvrW2Kf82nTpik6OrpUbVxcnHr06GHMePv6+qqwsFA5OTmSpI4dOyomJqbMYHzgwAFFREQoOTlZUtHsdk5OjvLy8iQVLUHZsGGDvLy8HNZv3LhRgwYNMnZfCQoKUkZGhgoKCiQV/UZg2bJlxtr4ikpLS1NQUJCsVis7tKDCQieVvktuTRI3q19VDwEAAENF81q1mTGXipaF7NixQ0uWLFH37t3l5+enjIwMNW7cWEOGDNHevXsdhnJJCg0N1eHDhzV16lS1b99eFotFHh4e6tSpk+bNm6dvv/3W6Wx1p06ddPToUb344otq1aqV8vLy5Ofnp/DwcC1ZskSbNm0qM5RL0kMPPaTDhw9r7NixCg0NVU5OjoKDg9WrVy+tXbtW77///hWHcgAAANQc1WrGHKUxY46rwYw5AADXT42cMQcAAABqKoI5AAAAYAIEcwAAAMAECOYAAACACRDMAQAAABMgmAMAAAAmQDAHAAAATIBgDgAAAJgAwRwAAAAwAYI5AAAAYAIEcwAAAMAECOYAAACACRDMAQAAABMgmAMAAAAmQDAHAAAATIBgDgAAAJgAwRwAAAAwAYI5AAAAYAIEcwAAAMAECOYAAACACRDMAQAAABMgmAMAAAAmQDAHAAAATIBgDgAAAJgAwRwAAAAwAYI5AAAAYAIEcwAAAMAECOYAAACACRDMAQAAABMgmAMAAAAmQDAHAAAATIBgDgAAAJgAwRwAAAAwAYI5AAAAYAIEcwAAAMAECOYAAACACdSq6gEAQGULnfRlVQ/hmoub1a+qhwAAqGTMmAMAAAAmQDAHAAAATIBgDgAAAJgAwRwAAAAwAYI5AAAAYAIEcwAAAMAECOYAAACACRDMAQAAABMgmAMAAAAmQDAHAAAATIBgDgAAAJgAwRwAAAAwAYI5AAAAYAIEcwAAAMAECOYAAACACRDMAQAAABMgmAMAAAAmQDAHAAAATIBgDgAAAJgAwRwAAAAwAYI5AAAAYAIEcwAAAMAECOYAAACACRDMAQAAABMgmAMAAAAmQDAHAAAATIBgDgAAAJgAwRwAAAAwAYI5AAAAYAIEcwAAAMAECOYAAACACVSrYP7BBx/IYrGU+/jqq6/KPMepU6cUFRWlsLAweXt7q379+oqIiNC6desqNIaDBw9q+PDhatKkiby8vNSwYUM9+uij2r59e4Xqd+zYoUcffVQNGzaUl5eXmjRpouHDh+vgwYMVqgcAAEDNVK2CeTE3NzfddNNNZT68vLwc1m3cuFG33XabFi9erLi4OHl5eSklJUVbt27VH//4Rz311FOy2WxlXnfp0qW65557tHLlSiUlJcnHx0fnzp3T+vXr9eCDDyo6OtrpuKOjo/XAAw9o/fr1OnfunHx8fJSUlKSVK1fqnnvu0dKlS115WwAAAFCNVctg3rRpU/32229lPrp161aqJjY2VoMHD1ZWVpa6du2qEydOyGq1ymq1aurUqZKk5cuXa+7cuQ6vuW/fPj3zzDPKz89XZGSkEhMT9fvvv+vChQuKioqSJE2fPl2rV692WL969WpNnz5dkhQVFaULFy7o999/V2JioiIjI5Wfn69nnnlG+/btq4y3CAAAANVMtQzmV2Pq1KnKzMxUSEiIvvjiC7Vu3VqS5O/vr+nTp2vcuHGSpH/84x9KTU0tVf/Xv/5VBQUF6tChg1avXq0mTZpIkurWrat3331XERERkqS//e1vKigoKFFbUFCgv/71r5KkPn366N1331XdunUlSU2aNNG///1vtW/fvkQ/AAAA3FhuiGCemZlprCEfP368ateuXarP5MmTJUlpaWlav359ibbTp09rz549kqSJEyfKw8OjzPq4uDjt2rWrRNvXX3+t+Pj4Ev3seXp6auLEiZKkPXv2KDY29gpeHQAAAGqCGyKY79mzR9nZ2ZKkvn37OuwTGhqqtm3bSpK2bt1aom3btm3GcZ8+fRzWh4eHKyAgwGl9QECAunbt6rDeflyX1wMAAKDmq5bB/MKFC+rUqZP8/f3l4+OjFi1aaPjw4dq5c6fD/keOHDGO27dvX+Z5i9uOHj3qsL5BgwZq0KCBw1p3d3e1adPGaX3btm3l7u7usL5BgwaqX7++w3oAAADUfNUymGdlZengwYPy9PRUYWGhYmNjtXLlSvXo0UNPPfWU8vPzS/Q/c+aMJCk4OFg+Pj5lnrdx48Yl+l9eX9x+vevt5ebmKi0trcQDAAAA1V+1CuaNGjXStGnT9NNPPyknJ0cpKSnKysrS3r171bNnT0lFO6u8+OKLJerS09MlSb6+vk7PX9xe3N8s9fZmzpypoKAg49G0aVOn5wQAAED1UK2Cee/evRUdHa3bbrvN2Kvc3d1d9957r7Zs2aJHHnlEkvTOO+/o5MmTVTnUa2by5MnGNo9Wq1WJiYlVPSQAAABUgmoVzJ1xc3PTvHnzJEmFhYX6/PPPjbbiD2VmZWU5PUdxe3F/s9Tb8/LyUmBgYIkHAAAAqr8aE8wlqWXLlqpXr56koi0OizVq1EiSlJqaauzO4khSUlKJ/pfXF7df73oAAADUfDUqmJfFficW+x1aLlfc1q5dO4f158+f14ULFxzWFhQU6JdffnFaf/z48VI3Hypmf+7L6wEAAFDz1ahgfurUKV28eFGSFBYWZjwfHh5u7MayefNmh7Xx8fE6fvy4pKK17PZ69eplHJdVv3fvXuNDm2XVp6en65tvvnFYb3/ey+sBAABQ81WbYG6z2cptf/nllyUVrTfv37+/0ebn56eBAwdKkhYtWiSr1Vqqfvbs2ZKK1ndHRkaWaGvRooXCw8MlSfPnz1deXl6p+lmzZkmSmjdvru7du5dou++++9S8efMS/ezl5eVp/vz5kop+iLD/oQIAAAA3hmoTzOPj49W5c2e99957On36tBHUCwsL9e2336pv37769NNPJUlRUVG65ZZbStTPmDFDfn5+Onv2rAYMGGDs2pKZmakZM2bo3XfflSRNmTJFwcHBpa4/e/Zsubu766efftKQIUOM9eApKSl69tlntWnTJknSnDlzSt1EyN3dXXPmzJEkbdy4Uc8++6xSUlIkFa0rHzJkiA4fPlyiHwAAAG4sFlt5U9EmERcXV2Im2cvLSwEBAUpPT1dubq7x/OjRo7V48WLVqlWr1Dk2btyoQYMGGbufBAUFKSMjw1j3PXr0aC1btkwWi8XhGJYuXarx48cbNzCqXbu2rFar8UPCtGnTFB0dXeZriI6O1vTp0yVJFotFQUFB+v333yVJtWrV0qJFizRmzJgKviNF0tLSFBQUJKvVyg4tqLDQSV9W9RDgorhZ/ap6CACACqpoXqs2wTw7O1vLli3Tvn379OOPP+rChQtKTU2Vt7e3mjRponvvvVdPPfWUunbt6vQ8p06d0uzZs7Vt2zadPXtWAQEB6tixo6KioozlLs4cPHhQ8+fP19dff60LFy4oODhYXbp00fPPP68HHnig3Prt27frn//8p/bt26fU1FTVr19f9913n1566SV16tSpwu9HMYI5rgbBvPojmANA9VHjgjkcI5jjahDMqz+COQBUHxXNa9VmjTkAAABQkxHMAQAAABMgmAMAAAAmQDAHAAAATIBgDgAAAJgAwRwAAAAwAYI5AAAAYAIEcwAAAMAECOYAAACACRDMAQAAABMgmAMAAAAmQDAHAAAATIBgDgAAAJgAwRwAAAAwAYI5AAAAYAIEcwAAAMAECOYAAACACRDMAQAAABMgmAMAAAAmQDAHAAAATIBgDgAAAJgAwRwAAAAwAYI5AAAAYAIEcwAAAMAECOYAAACACRDMAQAAABMgmAMAAAAmQDAHAAAATIBgDgAAAJgAwRwAAAAwAYI5AAAAYAIEcwAAAMAECOYAAACACRDMAQAAABOoVdUDAABcudBJX1b1EK6puFn9qnoIAHDdMWMOAAAAmADBHAAAADABgjkAAABgAgRzAAAAwAT48CdwmZr+oToAAGBOzJgDAAAAJkAwBwAAAEyAYA4AAACYAMEcAAAAMAGCOQAAAGACBHMAAADABAjmAAAAgAmwjzkAAABKuBHu6RE3q19VD6EUZswBAAAAEyCYAwAAACZAMAcAAABMgGAOAAAAmADBHAAAADABl4P5jBkzlJSUVBljAQAAAG5YLgfz6OhohYWFKTIyUhs3bpTNZquMcQEAAAA3FJeDebNmzZSfn68NGzZowIABCg0N1WuvvaYzZ85UxvgAAACAG4LLwTw2NlabNm3So48+qlq1aikxMVHR0dEKDQ1VZGSkNm3axCw6AAAAUA6Xg7nFYlFERITWrVunxMREvfHGG2rRooUxi96/f3+FhYUxiw4AAAA4Uam7sjRo0ECTJk3SyZMn9dVXX2nw4MHy8PBQQkICs+gAAACAE9dsu8QHHnhAq1atUlJSkubPn6/WrVsrPz9fn3/+uTGL/sYbbyg5OflaDQEAAACoNq75PuZWq1Xnz59XamqqLBaLbDabbDabEhIS9OqrryosLExvv/32tR4GAAAAYGq1rsVJ8/Pz9cknn2jx4sXauXOnEcZDQkI0ZswYDRo0SFu3btW7776rU6dOacKECfL29tYzzzxzLYYDAAAAmF6lzpifPHlSL7/8sho3bqwnnnhC27dvl81m0wMPPKA1a9YoMTFRM2bMUIcOHTRhwgSdOHFCr7zyimw2m/75z39W5lAAAACAasXlGfNLly5p7dq1WrJkiXbt2iVJstlsqlOnjp588klFRUWpVatWDmvd3Nz02muv6Z///KdOnTrl6lAAAACAasvlYN6oUSOlpqYau6x06dJFzzzzjAYPHiwvL69y6y0Wi4KDg5WYmOjqUAAAAIBqy+VgnpKSIn9/fw0fPlzPPPOMbrvttis+x/z585WRkeHqUAAAAIBqy+VgvmjRIg0bNkz+/v5XfY6BAwe6OgwAAACgWnP5w59RUVEuhXJXzZo1SxaLxXg4k56erujoaHXo0EH+/v4KCgrS3Xffrfnz5+vSpUvlXuvcuXOaMGGCbrnlFvn4+KhOnTrq1q2bli5dWqEbJp06dUpRUVEKCwuTt7e36tevb9w1FQAAADc2i60SbsGZlpYmNze3cgN6RkaGCgsLFRgY6OolJUknTpzQHXfcoZycHOO5sl5OfHy87r//fsXFxUmSfH19VVBQoNzcXElSx44dFRMTo+DgYIf1Bw4cUEREhHFDJH9/f+Xk5Cg/P1+SFBERoQ0bNsjT09Nh/caNGzVo0CBlZWVJkgIDA433Q5JGjx6tZcuWlfvDxeXS0tIUFBQkq9Vaae/rjS500pdVPQQANVzcrH5VPQTAqRvh/8Lr+fewonnN5RnzTz75RMHBwRo3bly5fYcPH67g4GBt2LDB1cuqsLBQTz31lHJyctSlSxenffPz8zVgwADFxcWpYcOG2rZtmzIzM5WVlaVVq1YpICBAhw4d0vDhwx3WW61W9e/fX8nJyWrTpo1++OEHpaenKzMzUwsWLJCHh4e2bNmiF154wWF9bGysBg8erKysLHXt2lUnTpyQ1WqV1WrV1KlTJUnLly/X3LlzXXpPAAAAUH25HMzXrFkjSXr66afL7Tt27FjZbDatXr3a1cvqn//8p7755hsNGzZMvXv3dtp3xYoV+vnnnyVJ69atU8+ePSUVbdf4+OOP67333pNUNKsdExNTqn7evHn67bff5OPjo40bN+quu+6SJHl6euq5557T9OnTJUmLFy/Wf/7zn1L1U6dOVWZmpkJCQvTFF1+odevWkopm3adPn278UPOPf/xDqampV/N2AAAAoJpzOZgfOnRIbm5u6tq1a7l9H3jgAbm5uengwYMuXTM2NlZ///vfVbduXb311lvl9l+xYoUkqUePHg5n14cMGaKwsDBJ0ocffliqvfg5+372nn/+efn7+6ugoEArV64s0ZaZmWmsIR8/frxq165dqn7y5MmSin7NsX79+nJfDwAAAGoel4N5UlKSateuLW9v73L7+vj4qHbt2kpKSnLpmmPHjlVmZqbefPNN1a9f32nfrKws7d27V5LUt29fh30sFov69OkjSdq6dWuJthMnTighIcFpvb+/v7p16+awfs+ePcrOznZaHxoaqrZt2zqsBwAAwI3B5WBusViMDzRWRHZ2tgoKCq76ekuWLFFMTIx69uypkSNHltv/+PHjxgcs27dvX2a/4rbffvtNKSkpxvNHjhwp1cdZ/bFjx0o8f6X1R48eLbMPAAAAai6Xg3nTpk2Vk5NjrOF25qefflJ2drYaN258VddKSkrSyy+/LB8fH2NdeHnOnDljHDu7rn2bfc2V1qelpZW4WVJxfXBwsHx8fMqtt7+eI7m5uUpLSyvxAAAAQPXncjC///77ZbPZNG3atHL7RkdHy2KxqEePHld1raioKFmtVkVHR6tFixYVqklPTzeOfX19y+xn32ZfU1n1zmrt2+1rHZk5c6aCgoKMR9OmTZ32BwAAQPXgcjB//vnn5ebmps8++0zDhw/XuXPnSvU5d+6chg4dqs8++0xubm7685//fMXX+eijj/Tll1/qjjvu0EsvveTqsKutyZMnG1stWq1WJSYmVvWQAAAAUAlquXqCNm3a6B//+IcmT56sjz/+WGvXrlWnTp3UvHlzSUU39tm/f79xI57XX39dt9566xVd49y5c3rhhRfk7u6uJUuWqFatig87ICDAOHa2Ft6+zb7m8vqyNoUvr768dfjF7fa1jnh5ecnLy8tpHwAAAFQ/LgdzSfrb3/6mwMBATZo0Senp6dq3b5++/fZbSf//TpyBgYGaM2dOhW5EdLlJkyYpOTlZ48ePV5s2bUqs4ZakS5cuGcfFbZ6envL09FSjRo2MtqSkJN12220Or2G/U4x9zeX1ZQXz4vrAwMASd0Atrk9NTVV2dnaZ68yL6+2vBwAAgBtHpQRzqWiP7ieeeEJr167VN998o99++00Wi0UhISG69957NWjQoKu+ZXxsbKwkadGiRVq0aJHTvsUzzn/5y1/09ttvq23btnJzc1NhYaGOHDlS5paFxbunhISEqE6dOsbz9jupHDlyxNjWsKz6y38bcHn93Xff7bS+Xbt2Tl8fAAAAaqZKC+aSVLt2bY0ZM0ZjxoypzNO6xNfXV127dtXu3bu1efNmvfzyy6X62Gw2bdmyRZJK3UW0devWatasmRISErR582YNGjSoVH1mZqZ2797tsD48PFw+Pj7Kzs7W5s2bHQbz+Ph4HT9+3GE9AAAAbgwuf/jzeti5c6dsNluZD/sdYYqfe/vtt43nRo0aJUnasWOHvvvuu1LnX7NmjU6fPi1JpfZGt1gsxnOrVq1SXFxcqfqFCxcqIyND7u7uGjZsWIk2Pz8/DRw4UFLRjL/Vai1VP3v2bElFs/2RkZHlvBsAAACoiapFMHfVqFGj1KFDB9lsNg0cOFAxMTGSpMLCQq1Zs0Zjx46VVHRnzgcffLBU/cSJExUSEqKsrCz169dPBw4ckFS0tn3RokV69dVXJUnjxo1T69atS9XPmDFDfn5+Onv2rAYMGKCTJ09KKpppnzFjht59911J0pQpUxQcHFz5bwAAAABMr9KWspw6dUqrV6/W4cOHlZKSory8vDL7WiwWIxxfD7Vq1dKGDRvUo0cPxcXFqWfPnvL19VVhYaFycnIkSR07dtTKlSsd1gcFBemLL75QRESEjh07prvuuksBAQHKyckxXmfv3r311ltvOawPCwvT6tWrNWjQIO3evVutW7dWUFCQMjIyjLugjh492uEyGwAAANwYKiWYT58+Xa+//roKCwuNXVicsVgslXHZKxIaGqrDhw9r3rx5+uSTTxQbGysPDw+1a9dOTzzxhJ5//nl5enqWWd+pUycdPXpUs2fP1hdffKHExET5+fmpffv2GjVqlJ566im5uZX9C4iHHnpIhw8f1uzZs7Vt2zadPXtWwcHB6tixo6KioozlLgAAALgxWWwVSdJOrFy5UiNGjJBUtNVfRESEGjVqVO5e4xW5UyjKl5aWpqCgIFmt1qve9QYlhU76sqqHAKCGi5vVr6qHADh1I/xfeD3/HlY0r7k8Y75w4UJJ0sMPP6zVq1c7nXUGAAAA4JjLH/48cuSILBaL3nnnHUI5AAAAcJVcDuYWi0WBgYHcsRIAAABwgcvBvE2bNsrKylJubm5ljAcAAAC4IbkczMeMGaO8vDytWbOmMsYDAAAA3JBcDuZjx47Vww8/rD//+c/atWtXZYwJAAAAuOG4vCvLjBkzdPvtt2v37t3q0aOHunbtqnvuuUcBAQFO66ZOnerqpQEAAIAaw+VgHh0dbdwwyGazac+ePdq7d2+5dQRzAAAA4P9zOZh37969Su7kCQAAANQkLgfznTt3VsIwAAAAgBubyx/+BAAAAOA6gjkAAABgAi4vZbF3+PBhbdmyRfHx8crOztayZcuMtry8PF24cEEWi0UNGzaszMsCAAAA1V6lBHOr1aqnnnpK69evl1S0O4vFYikVzG+//Xalpqbqp59+Urt27Srj0gAAAECN4PJSlry8PPXt21fr16+Xr6+v+vXrJ29v71L9fH19NXr0aBUWFmrt2rWuXhYAAACoUVwO5suWLdO3336rFi1a6MSJE9qwYYOCgoIc9h04cKAkcYdQAAAA4DIuB/OPP/5YFotFb731lho1auS0b8eOHeXm5qZffvnF1csCAAAANYrLwfznn3+WxWJR7969y+3r6empoKAgJScnu3pZAAAAoEZxOZhnZWUpICBAnp6eFeqfl5enWrUqdTMYAAAAoNpzOZjXq1dPaWlpysjIKLdvbGysMjIyyl3yAgAAANxoXA7m99xzjyTpyy+/LLfvP//5T0lSt27dXL0sAAAAUKO4HMyfeuop2Ww2vfrqqzpz5kyZ/d577z39z//8jywWi8aNG+fqZQEAAIAaxeXF3v369dPAgQO1bt063XXXXRo6dKiys7MlSYsXL1Z8fLy++OILHTlyRDabTWPHjjVm2QEAAAAUqZRPYf7rX/+St7e3Vq5cqbfeest4fvz48ZKK7gQqFc2uL1y4sDIuCQAAANQoLi9lkSRvb2/961//0q5duzRixAjdfPPN8vHxkaenp5o1a6ahQ4dq586dWrp0KTuyAAAAAA5UakoODw9XeHh4ZZ4SAIAaJ3RS+RsmVHdxs/pV9RCAaqdSZswBAAAAuIZgDgAAAJiAy0tZPvzww6uqGzlypKuXBgAAAGoMl4P5k08+KYvFckU1FouFYA4AAADYcTmYN2vWzGkwt1qt+v333yVJfn5+qlevnquXBAAAAGocl4N5XFxcuX1Onjyp119/XWvWrNHs2bM1ePBgVy8LAAAA1CjXZVPxVq1aacWKFfLw8NDIkSPVunVr3XHHHdfj0gAAAEC1cF13ZYmOjtalS5c0c+bM63lZAAAAwPSuazBv0qSJateura+//vp6XhYAAAAwveuylKVYTk6O0tLS5OHhcT0vCwAAAJjedZ0xX758uQoLC9W4cePreVkAAADA9FyeMU9ISHDanpOTo8TERK1bt07vv/++LBaLHn30UVcvCwAAANQoLgfzsLCwCve12Wxq166dpkyZ4uplAQAAgBrF5aUsNputQo8WLVpoypQp+vbbbxUUFFQZYwcAAABqDJdnzGNjY51foFYtBQcHy9fX19VLAQAAADWWy8G8efPmlTEOAAAA4IZ2XXdlAQAAAOAYwRwAAAAwAZeXssyYMaMyxiFJmjp1aqWdCwAAAKhOXA7m0dHRslgslTEWgjkAAABuWC4H8+7du8tisejHH3+U1WqVJDVu3FhNmjSRJCUlJem///2vJKl27dq6/fbbXb0kAAAAUOO4HMx37typyZMn6+uvv9YTTzyh6OhotWrVqkSfX3/9VdOnT9fKlSvVpUsXvfHGG65eFgAAAKhRXA7m69at05w5c/Tss89qwYIFDvu0bNlS//rXvxQUFKTZs2frrrvu0mOPPebqpQEAAIAaw+VdWRYsWCCLxaLo6Ohy+xb3KSvAAwAAADcql4P54cOHFRQUpHr16pXbt169eqpdu7Z++uknVy8LAAAA1CguB/Pc3FylpaUpIyOj3L4ZGRlKS0tTbm6uq5cFAAAAahSX15jfcsst+vHHH7VgwQJNmjTJad8FCxaooKBAt9xyi6uXBQAAqDKhk76s6iGgBnJ5xvzJJ5+UzWbTlClTNH36dIcz51lZWZoxY4amTJkii8Wi0aNHu3pZAAAAoEZxecb8ueee05dffqmtW7dqxowZmjt3ru666y41btxYUtE+5vv371d2drZsNpt69eqlZ5991uWBAwAAADWJy8Hczc1NGzZs0KRJk7RgwQJlZWVp165dxt1AbTabJMnd3V3PPfecZs+eLTc3lyfqAQAAgBrF5WAuSZ6ennrzzTf18ssva+3atdq/f7/Onz8vSWrQoIHuuusuDRw4UI0aNaqMywEAAAA1TqUE82INGzbU888/X5mnBAAAAG4IrCkBAAAATKBSZ8wvXryoHTt2KD4+XllZWZo6dWplnh4AAACosSolmOfn5+tvf/ub3nnnHV26dMl43j6Yp6amqkWLFsrOztYvv/yi0NDQyrg0AAAAUCNUylKWQYMG6e2339alS5fUrl071apVOu8HBwdr6NChunTpklavXl0ZlwUAAABqDJeD+apVq/TZZ5+pQYMG2r9/vw4fPqw6deo47Dto0CBJ0o4dO1y9LAAAAFCjuBzMly9fLovForlz56pjx45O+3bu3FkWi0XHjh1z9bIAAABAjeJyMD906JAkaeDAgeX29fX1VVBQkLHHOQAAAIAiLgdzq9WqoKAg+fj4VKh/YWGhcVdQAAAAAEVcDubBwcGyWq3Kyckpt+/Zs2eVlpamm266ydXLAgAAADWKy8H8zjvvlFSxD3S+//77kqQuXbpc1bUOHjyo6dOn6+GHH1abNm1Ut25deXh4qG7duuratav+8Y9/KCUlxek5zp07pwkTJuiWW26Rj4+P6tSpo27dumnp0qWy2WzljuHUqVOKiopSWFiYvL29Vb9+fUVERGjdunUVfg3Dhw9XkyZN5OXlpYYNG+rRRx/V9u3bK1QPAACAmsliq0gadWLlypUaMWKE7rzzTu3cuVP+/v5q2LChzp8/r4KCAqPf5s2bFRkZqby8PG3cuFERERFXfK0//elPWrhwofG1t7e3PDw8lJ6ebjxXr149bdiwwWH4P3DggCIiIpScnCxJ8vf3V05OjvLz8yVJERER2rBhgzw9PR1ef+PGjRo0aJCysrIkSYGBgcrIyFBhYaEkafTo0Vq2bFmZS3WWLl2q8ePHG9cLCgpSWlqa8QPBtGnTFB0dfSVvidLS0hQUFCSr1arAwMArqoVjoZO+rOohAACAayxuVr/rdq2K5jWXZ8yHDh2qbt266eDBg/rDH/6gBQsWGDcZ2rZtm5YsWaKHH35Y/fv316VLl9S/f/+rCuVS0a4uc+fO1b59+5Samqrs7GylpaUpPT1dK1asUP369XXx4kVFRkbKarWWqLVarerfv7+Sk5PVpk0b/fDDD0pPT1dmZqYWLFggDw8PbdmyRS+88ILDa8fGxmrw4MHKyspS165ddeLECVmtVlmtVuNGSsuXL9fcuXMd1u/bt0/PPPOM8vPzFRkZqcTERP3++++6cOGCoqKiJEnTp09nj3cAAIAblMsz5lLRXT0fffRR7dq1q8zZYpvNpp49e+qTTz6Rv7+/q5d0aOvWrUbo/+ijjzRs2DCj7dVXX9Xrr78uHx8fHT16VGFhYSVqZ86cqVdeeUXu7u46duyYWrduXaJ9xIgR+uijjxQSEqLjx4+rdu3aJdqjoqK0ePFiBQYGKi4uTsHBwSXau3Xrpj179qhDhw46cOCAPDw8SrT36dNHW7ZsUWhoqH799Ve5u7tX6DUzY175mDEHAKDmq5Ez5lLRB0C3b9+uFStWqFu3bvL09JTNZpPNZpO7u7u6dOmiDz74QJs3b75moVyS/vCHPxjH//3vf0u0ffjhh5KkIUOGlArlkvT888/L399fBQUFWrlyZYm2zMxMYw35+PHjS4VySZo8ebKkojd+/fr1JdpOnz6tPXv2SJImTpxYKpTb18fFxWnXrl3OXiYAAABqoEoJ5pLk5uamESNGaOfOncrMzNT58+d19uxZZWVlac+ePRo5cqTc3Crtcg7t3r3bOL755puN4xMnTighIUGS1LdvX4e1/v7+6tatm6SimXd7e/bsUXZ2ttP60NBQtW3b1mH9tm3bjOM+ffo4rA8PD1dAQIDDegAAANR8LiflsLAw3Xzzzfr111///0nd3FSvXj3ddNNNqlWrlquXcCo3N1dxcXFasGCBRowYIUlq2bKlBgwYYPQ5cuSIcdy+ffsyz1XcdvmdSa+0/ujRow7rGzRooAYNGjisdXd3V5s2bRzWAwAAoOZzOTWfPXtWnp6eatmyZWWMp8K8vb2Vm5tb6vmuXbvq//7v/+Tl5WU8d+bMGeO4cePGZZ6zuC0tLU0ZGRnGspvi+uDgYKc3Uiqut7+e/dfOrl3c/sMPP5SqBwAAQM3n8ox5o0aNKrT/d2ULCQnRTTfdJD8/P+O5Hj166O2331azZs1K9LXfTtHX17fMc9q32dcUHzurtW+3r62Menu5ublKS0sr8QAAAED153Iw79mzp7KysnTo0KHKGE+FxcXF6bffflNGRobOnTunefPm6ccff1Tnzp2N7QtropkzZyooKMh4NG3atKqHBAAAgErgcjCfNGmS/Pz89Kc//cm48c711qBBA02YMEGbN2+WxWLRa6+9pi+++MJoL/5QpSSnY7Rvs68pPi7v9RW329dWRr29yZMnG/unW61WJSYmOj0nAAAAqgeX15jXqlVL7733nqKiotS+fXs9//zzuvfee9WgQQOne3FfvtykMnTu3Fnh4eHatWuXFi9erP79+0sqWm5TLCkpqcz9I5OSkiQV3dHTflvH4vrimxqVtc68uN7+evZfF7eXpax6e15eXiXWzwMAAKBmcDmY2+8JnpmZqYkTJ5ZbY7FYjNvSV7biD1ja7xJjv5PKkSNHjG0NL1e8e8qtt95a4vnL6++++26n9e3atXNYf/78eV24cEH169cvVVtQUKBffvnFYT0AAABqPpeXshTfSOhKHoWFhZUxdodOnz4tqeRykNatWxsz9Js3b3ZYl5mZaeyD3rt37xJt4eHhxix5WfXx8fE6fvy4w/pevXoZx2XV79271/jQ5+X1AAAAqPlcDuaxsbFX9bhSBQUF5e7+EhMTo++//16SdP/99xvPWywWjRw5UpK0atUqxcXFlapduHChMjIy5O7urmHDhpVo8/Pz08CBAyVJixYtktVqLVU/e/ZsSUU/EERGRpZoa9GihcLDwyVJ8+fPV15eXqn6WbNmSZKaN2+u7t27O32dAAAAqHmuOJi7ubmV2I+7efPmxiMrK0tWq7XEc2U9rlRiYqI6duyo9957T6dPny4R0hMTEzVr1iw98sgjstlsqlOnjl588cUS9RMnTlRISIiysrLUr18/HThwQJJ06dIlLVq0SK+++qokady4cWrdunWp68+YMUN+fn46e/asBgwYoJMnT0oqmmmfMWOG3n33XUnSlClTFBwcXKp+9uzZcnd3108//aQhQ4YY68lTUlL07LPPatOmTZKkOXPmOF2bDwAAgJrJYrvCTcjd3NwUEhLi8CY4DRs21IULF67J+vG4uLgS69k9PT0VGBio7OxsZWZmGs+HhYVp3bp16tixY6lzHDhwQBEREUpOTpZUNLudk5NjzGD37t1bGzZsKPPDlRs3btSgQYOM3VOCgoKUkZGhgoICSdLo0aO1bNkyWSwWh/VLly7V+PHjjfendu3aslqtxg8Z06ZNU3R09JW8LUpLS1NQUJCsVmuZH2rFlQmd9GVVDwEAAFxjcbP6XbdrVTSvubyU5XLX6mZDjRo10po1a/Tcc8/prrvuUr169ZSWlqbCwkI1a9ZMAwYM0NKlS3X06FGHoVySOnXqpKNHj+rFF19Uq1atlJeXJz8/P4WHh2vJkiXatGmT0x1PHnroIR0+fFhjx45VaGiocnJyFBwcrF69emnt2rV6//33ywzlkjRmzBh99913Gjp0qBo3bqysrCw1aNBAkZGRiomJueJQDgAAgJqj0mfMz58/b8wg49pjxrzyMWMOAEDNd0PMmAMAAAC4cgRzAAAAwAQI5gAAAIAJEMwBAAAAE6h1NUXnzp1zutd2eftwWyyWa7KlIgAAAFBdXVUwv1ZbIgIAAAA3qisO5tOmTbsW4wAAAABuaARzAAAAwAT48CcAAABgAgRzAAAAwAQI5gAAAIAJEMwBAAAAEyCYAwAAACZAMAcAAABMgGAOAAAAmADBHAAAADABgjkAAABgAgRzAAAAwAQI5gAAAIAJEMwBAAAAEyCYAwAAACZAMAcAAABMgGAOAAAAmADBHAAAADABgjkAAABgAgRzAAAAwAQI5gAAAIAJEMwBAAAAEyCYAwAAACZAMAcAAABMgGAOAAAAmADBHAAAADABgjkAAABgAgRzAAAAwAQI5gAAAIAJEMwBAAAAEyCYAwAAACZAMAcAAABMgGAOAAAAmADBHAAAADABgjkAAABgAgRzAAAAwAQI5gAAAIAJEMwBAAAAEyCYAwAAACZAMAcAAABMgGAOAAAAmADBHAAAADABgjkAAABgAgRzAAAAwAQI5gAAAIAJEMwBAAAAEyCYAwAAACZAMAcAAABMgGAOAAAAmADBHAAAADABgjkAAABgAgRzAAAAwAQI5gAAAIAJEMwBAAAAEyCYAwAAACZAMAcAAABMgGAOAAAAmADBHAAAADABgjkAAABgAgRzAAAAwAQI5gAAAIAJEMwBAAAAE6g2wTw5OVnLly/X8OHDdeutt8rPz09eXl5q0qSJIiMj9emnn5Z7jvT0dEVHR6tDhw7y9/dXUFCQ7r77bs2fP1+XLl0qt/7cuXOaMGGCbrnlFvn4+KhOnTrq1q2bli5dKpvNVm79qVOnFBUVpbCwMHl7e6t+/fqKiIjQunXrKvQeAAAAoOay2CqSKE3Aw8ND+fn5xtfe3t5yd3dXZmam8Vzfvn21du1a+fr6lqqPj4/X/fffr7i4OEmSr6+vCgoKlJubK0nq2LGjYmJiFBwc7PD6Bw4cUEREhJKTkyVJ/v7+ysnJMcYUERGhDRs2yNPT02H9xo0bNWjQIGVlZUmSAgMDlZGRocLCQknS6NGjtWzZMlkslit5W5SWlqagoCBZrVYFBgZeUS0cC530ZVUPAQAAXGNxs/pdt2tVNK9Vmxnz/Px8de7cWe+8845OnTql7OxsZWRkKDY2Vk8//bQkadOmTYqKinJYO2DAAMXFxalhw4batm2bMjMzlZWVpVWrVikgIECHDh3S8OHDHV7barWqf//+Sk5OVps2bfTDDz8oPT1dmZmZWrBggTw8PLRlyxa98MILDutjY2M1ePBgZWVlqWvXrjpx4oSsVqusVqumTp0qSVq+fLnmzp1bOW8WAAAAqp1qM2O+Y8cO9ejRo8z2Z555Ru+9954kKSEhQU2bNjXali1bpjFjxkiSvvnmG3Xp0qVE7ccff6yhQ4dKkr766is9+OCDJdpfffVVvf766/Lx8dHRo0cVFhZWon3mzJl65ZVX5O7urmPHjql169Yl2keMGKGPPvpIISEhOn78uGrXrl2iPSoqSosXL1ZgYKDi4uLKnLV3hBnzyseMOQAANR8z5i5wFsolGbPmkrR///4SbStWrDDOcXkol6QhQ4YYYfvDDz8s1V78nH0/e88//7z8/f1VUFCglStXlmjLzMw01pCPHz++VCiXpMmTJ0sq+kNbv359WS8RAAAANVi1Cebl8fb2No4LCgqM46ysLO3du1dS0Rp0RywWi/r06SNJ2rp1a4m2EydOKCEhwWm9v7+/unXr5rB+z549ys7OdlofGhqqtm3bOqwHAADAjaHGBPOdO3caxx06dDCOjx8/bnzAsn379mXWF7f99ttvSklJMZ4/cuRIqT7O6o8dO1bi+SutP3r0aJl9AAAAUHPVquoBVIbff/9dM2fOlCR169ZNt9xyi9F25swZ47hx48ZlnsO+7cyZM6pTp85V1aelpSkjI0P+/v4l6oODg+Xj41Nuvf31HMnNzTV2kim+HgAAAKq/aj9jXlhYqBEjRujs2bPy9vbWggULSrSnp6cbx462UXTUZl9TWfXOau3b7WsdmTlzpoKCgoyH/YdcAQAAUH1V+2D+l7/8RV988YUkaeHChbrtttuqeETX1uTJk42tFq1WqxITE6t6SAAAAKgE1Xopy8SJE40Z8rfeektPPfVUqT4BAQHGcfHNfRyxb7Ovuby+rC1uyqt3dm37dvtaR7y8vOTl5eW0DwAAAKqfajtj/te//lXz58+XJM2bN6/Mm/s0atTIOE5KSirzfPZt9jVXWh8YGGisL7evT01NNXZncVZvfz0AAADcOKplMH/55ZeNu2TOmTNHEyZMKLNv27Zt5eZW9DLtd0i5XHFbSEiI8cFPqeROKhWpv/XWW0s8f6X17dq1K7MPAAAAaq5qF8wnTpyoefPmSSoK5S+//LLT/r6+vurataskafPmzQ772Gw2bdmyRZLUu3fvEm2tW7dWs2bNnNZnZmZq9+7dDuvDw8ON3VjKqo+Pj9fx48cd1gMAAODGUK2C+cSJE0ssXykvlBcbNWqUJGnHjh367rvvSrWvWbNGp0+fliSNHDmyRJvFYjGeW7VqleLi4krVL1y4UBkZGXJ3d9ewYcNKtPn5+WngwIGSpEWLFslqtZaqnz17tqSi9eWRkZEVek0AAACoWapNMLdfU/7mm286Xb5yuVGjRqlDhw6y2WwaOHCgYmJiJBVttbhmzRqNHTtWUtGdOR988MFS9RMnTlRISIiysrLUr18/HThwQJJ06dIlLVq0SK+++qokady4cWrdunWp+hkzZsjPz09nz57VgAEDdPLkSUlFM+0zZszQu+++K0maMmWKgoODK/y6AAAAUHNYbDabraoHUZ6EhAQ1b95ckuTm5qb69es77T9x4kRNnDixxHNxcXHq0aOHMePt6+urwsJC5eTkSJI6duyomJiYMoPxgQMHFBERoeTkZElFs9s5OTnKy8uTVLQEZcOGDWXumLJx40YNGjTI2H0lKChIGRkZKigokCSNHj1ay5Ytk8ViKe/tKCEtLU1BQUGyWq1l7hiDKxM66cuqHgIAALjG4mb1u27XqmheqxYz5oWFhSWOz5075/SRkZFR6hyhoaE6fPiwpk6dqvbt28tiscjDw0OdOnXSvHnz9O233zqdre7UqZOOHj2qF198Ua1atVJeXp78/PwUHh6uJUuWaNOmTU63MXzooYd0+PBhjR07VqGhocrJyVFwcLB69eqltWvX6v3337/iUA4AAICao1rMmKNszJhXPmbMAQCo+ZgxBwAAAOAQwRwAAAAwAYI5AAAAYAIEcwAAAMAECOYAAACACRDMAQAAABMgmAMAAAAmQDAHAAAATIBgDgAAAJgAwRwAAAAwAYI5AAAAYAIEcwAAAMAECOYAAACACRDMAQAAABMgmAMAAAAmQDAHAAAATIBgDgAAAJgAwRwAAAAwAYI5AAAAYAIEcwAAAMAECOYAAACACRDMAQAAABMgmAMAAAAmQDAHAAAATIBgDgAAAJgAwRwAAAAwAYI5AAAAYAIEcwAAAMAECOYAAACACRDMAQAAABMgmAMAAAAmQDAHAAAATIBgDgAAAJgAwRwAAAAwAYI5AAAAYAIEcwAAAMAECOYAAACACRDMAQAAABMgmAMAAAAmQDAHAAAATIBgDgAAAJgAwRwAAAAwAYI5AAAAYAIEcwAAAMAECOYAAACACRDMAQAAABMgmAMAAAAmQDAHAAAATIBgDgAAAJgAwRwAAAAwAYI5AAAAYAIEcwAAAMAECOYAAACACRDMAQAAABMgmAMAAAAmQDAHAAAATIBgDgAAAJgAwRwAAAAwAYI5AAAAYAIEcwAAAMAECOYAAACACRDMAQAAABMgmAMAAAAmQDAHAAAATIBgDgAAAJgAwRwAAAAwAYI5AAAAYALVJphnZWVp06ZNev311/XYY4+pefPmslgsslgsio6OrtA5zp07pwkTJuiWW26Rj4+P6tSpo27dumnp0qWy2Wzl1p86dUpRUVEKCwuTt7e36tevr4iICK1bt65C1z948KCGDx+uJk2ayMvLSw0bNtSjjz6q7du3V6geAAAANVetqh5ARX3//fd66KGHrrr+wIEDioiIUHJysiTJ399f6enp2rNnj/bs2aO1a9dqw4YN8vT0dFi/ceNGDRo0SFlZWZKkwMBApaSkaOvWrdq6datGjx6tZcuWyWKxOKxfunSpxo8fr/z8fElSUFCQzp07p/Xr12v9+vWaNm1ahX/AAAAAQM1TbWbMJSk4OFgPPvigXn75ZX388ccKCQmpUJ3ValX//v2VnJysNm3a6IcfflB6eroyMzO1YMECeXh4aMuWLXrhhRcc1sfGxmrw4MHKyspS165ddeLECVmtVlmtVk2dOlWStHz5cs2dO9dh/b59+/TMM88oPz9fkZGRSkxM1O+//64LFy4oKipKkjR9+nStXr36yt8UAAAA1AgWW0XWcJhAQUGB3N3dSzwXGhqq+Pj4cmebX331Vb3++uvy8fHR0aNHFRYWVqJ95syZeuWVV+Tu7q5jx46pdevWJdpHjBihjz76SCEhITp+/Lhq165doj0qKkqLFy9WYGCg4uLiFBwcXKK9W7du2rNnjzp06KADBw7Iw8OjRHufPn20ZcsWhYaG6tdffy31Op1JS0tTUFCQrFarAgMDK1yHsoVO+rKqhwAAAK6xuFn9rtu1KprXqs2M+ZWE1ct9+OGHkqQhQ4aUCuWS9Pzzz8vf318FBQVauXJlibbMzExjDfn48eNLhXJJmjx5sqSiN339+vUl2k6fPq09e/ZIkiZOnFgqlNvXx8XFadeuXVf24gAAAFAjVJtgfrVOnDihhIQESVLfvn0d9vH391e3bt0kSVu3bi3RtmfPHmVnZzutDw0NVdu2bR3Wb9u2zTju06ePw/rw8HAFBAQ4rAcAAMCNocYH8yNHjhjH7du3L7NfcduxY8dcqj969KjD+gYNGqhBgwYOa93d3dWmTRuH9QAAALgx1PhgfubMGeO4cePGZfYrbktLS1NGRkap+uDgYPn4+JRbb389+6+dXdtZPQAAAG4M1Wa7xKuVnp5uHPv6+pbZz74tPT1d/v7+Jeqd1dq321+vMuovl5ubq9zcXOPrtLQ0p/0BAABQPdT4GfOaZubMmQoKCjIeTZs2reohAQAAoBLU+GBe/KFKScbNgRyxb7OvKT52Vmvfbl9bGfWXmzx5srGHutVqVWJiotP+AAAAqB5q/FKWRo0aGcdJSUll7h2ZlJQkqeiOnsXLWOzrU1NTlZ2dXeY68+J6++vZf13cXpay6i/n5eUlLy8vp30AAABQ/dT4GXP7nVTsd1i5XHHbrbfe6lJ9u3btHNafP39eFy5ccFhbUFCgX375xWE9AAAAbgw1Ppi3bt1azZo1kyRt3rzZYZ/MzEzt3r1bktS7d+8SbeHh4cYseVn18fHxOn78uMP6Xr16Gcdl1e/du9f40Ofl9QAAALgx1PhgbrFYNHLkSEnSqlWrFBcXV6rPwoULlZGRIXd3dw0bNqxEm5+fnwYOHChJWrRokaxWa6n62bNnSypaHx4ZGVmirUWLFgoPD5ckzZ8/X3l5eaXqZ82aJUlq3ry5unfvfmUvEAAAADVCtQrmqampunjxovEoLCyUVPTBSfvn7fchl6SJEycqJCREWVlZ6tevnw4cOCBJunTpkhYtWqRXX31VkjRu3Di1bt261HVnzJghPz8/nT17VgMGDNDJkyclFc20z5gxQ++++64kacqUKQoODi5VP3v2bLm7u+unn37SkCFDjPXkKSkpevbZZ7Vp0yZJ0pw5c+Tu7l4ZbxUAAACqGYvNZrNV9SAqKjQ0VPHx8eX2GzVqlD744IMSzx04cEARERFKTk6WVDS7nZOTY8xg9+7dWxs2bCjzg5UbN27UoEGDjN1TgoKClJGRoYKCAknS6NGjtWzZMlksFof1S5cu1fjx45Wfny9Jql27tqxWq4rf/mnTpik6Orrc13a5tLQ0BQUFyWq1lvnBVlyZ0ElfVvUQAADANRY3q991u1ZF81q1mjF3RadOnXT06FG9+OKLatWqlfLy8uTn56fw8HAtWbJEmzZtcrrbyUMPPaTDhw9r7NixCg0NVU5OjoKDg9WrVy+tXbtW77//fpmhXJLGjBmj7777TkOHDlXjxo2VlZWlBg0aKDIyUjExMVcVygEAAFBzVKsZc5TGjHnlY8YcAICajxlzAAAAAA4RzAEAAAATIJgDAAAAJkAwBwAAAEyAYA4AAACYAMEcAAAAMAGCOQAAAGACBHMAAADABAjmAAAAgAkQzAEAAAATIJgDAAAAJkAwBwAAAEyAYA4AAACYAMEcAAAAMAGCOQAAAGACBHMAAADABAjmAAAAgAkQzAEAAAATIJgDAAAAJkAwBwAAAEyAYA4AAACYAMEcAAAAMAGCOQAAAGACBHMAAADABAjmAAAAgAkQzAEAAAATIJgDAAAAJkAwBwAAAEyAYA4AAACYAMEcAAAAMAGCOQAAAGACBHMAAADABAjmAAAAgAkQzAEAAAATIJgDAAAAJkAwBwAAAEyAYA4AAACYAMEcAAAAMAGCOQAAAGACtap6AKh+Qid9WdVDAAAAqHGYMQcAAABMgGAOAAAAmADBHAAAADABgjkAAABgAgRzAAAAwAQI5gAAAIAJEMwBAAAAEyCYAwAAACZAMAcAAABMgGAOAAAAmADBHAAAADABgjkAAABgAgRzAAAAwAQI5gAAAIAJEMwBAAAAEyCYAwAAACZAMAcAAABMgGAOAAAAmADBHAAAADABgjkAAABgAgRzAAAAwAQI5gAAAIAJEMwBAAAAEyCYAwAAACZAMAcAAABMgGAOAAAAmADBHAAAADABgjkAAABgAgTz6yw9PV3R0dHq0KGD/P39FRQUpLvvvlvz58/XpUuXqnp4AAAAqCK1qnoAN5L4+Hjdf//9iouLkyT5+voqNzdX+/fv1/79+7Vy5UrFxMQoODi4agcKAACA644Z8+skPz9fAwYMUFxcnBo2bKht27YpMzNTWVlZWrVqlQICAnTo0CENHz68qocKAACAKkAwv05WrFihn3/+WZK0bt069ezZU5Lk5uamxx9/XO+9954kaePGjYqJiamycQIAAKBqEMyvkxUrVkiSevTooS5dupRqHzJkiMLCwiRJH3744XUdGwAAAKoewfw6yMrK0t69eyVJffv2ddjHYrGoT58+kqStW7det7EBAADAHAjm18Hx48dVWFgoSWrfvn2Z/YrbfvvtN6WkpFyXsQEAAMAc2JXlOjhz5oxx3Lhx4zL72bedOXNGderUKdUnNzdXubm5xtdWq1WSlJaWVhlDrZDC3Kzrdi0AAIBr4Xpmp+Jr2Ww2p/0I5tdBenq6cezr61tmP/s2+xp7M2fO1PTp00s937RpUxdGCAAAcGMJevv6XzM9PV1BQUFlthPMq5nJkyfrpZdeMr4uLCxUSkqK6tatK4vFUmnXSUtLU9OmTZWYmKjAwMBKOy9qPr53cDX4vsHV4PsGV+t6f+/YbDalp6erUaNGTvsRzK+DgIAA4zgrq+xlIPZt9jX2vLy85OXlVeK52rVruzZAJwIDA/nHDleF7x1cDb5vcDX4vsHVup7fO85myovx4c/rwP6no6SkpDL72beV9xMVAAAAahaC+XXQtm1bubkVvdVHjhwps19xW0hIiMMPfgIAAKDmIphfB76+vurataskafPmzQ772Gw2bdmyRZLUu3fv6za2snh5eWnatGmlls0A5eF7B1eD7xtcDb5vcLXM+r1jsZW3bwsqxbJlyzRmzBhZLBbt27dP99xzT4n21atX6/HHH5ckffXVV3rwwQerYpgAAACoIsyYXyejRo1Shw4dZLPZNHDgQMXExEgq2lVlzZo1Gjt2rKSiO4MSygEAAG48zJhfR3FxcerRo4fi4uIkFS1xKSwsVE5OjiSpY8eOiomJUXBwcBWOEgAAAFWBYH6dpaena968efrkk08UGxsrNzc3tW7dWk888YSef/55eXp6VvUQAQAAUAUI5gAAAIAJsMYckopubrRp0ya9/vrreuyxx9S8eXNZLBZZLBZFR0dX9fBgYsnJyVq+fLmGDx+uW2+9VX5+fvLy8lKTJk0UGRmpTz/9tKqHCBM6ePCgpk+frocfflht2rRR3bp15eHhobp166pr1676xz/+oZSUlKoeJqqJWbNmGf9nVeZdsFFzfPDBByW+R8p6fPXVV1U6Tu78CUnS999/r4ceeqiqh4FqKCQkRPn5+cbX3t7e8vDwUFJSkpKSkvTZZ5+pb9++Wrt2rXx9fatwpDCT999/XwsXLjS+9vb2lo+Pj1JSUvTNN9/om2++0dtvv60NGzaoS5cuVThSmN2JEyc0ffr0qh4Gqgk3NzfVr1+/zPaq3j6RGXMYgoOD9eCDD+rll1/Wxx9/rJCQkKoeEqqB/Px8de7cWe+8845OnTql7OxsZWRkKDY2Vk8//bQkadOmTYqKiqrikcJMOnfurLlz52rfvn1KTU1Vdna20tLSlJ6erhUrVqh+/fq6ePGiIiMjZbVaq3q4MKnCwkI99dRTysnJ4Qc4VEjTpk3122+/lfno1q1blY6PGXNIkrp161bq18aTJk2qotGgOtm+fbt69OhR6vnQ0FAtXbpUtWrV0nvvvaePPvpIb7zxhpo2bVoFo4TZjBw50uHz/v7+GjlypEJCQhQREaHz58/riy++0LBhw67zCFEd/POf/9Q333yjYcOGqWXLltq3b19VDwlwCTPmkCS5u7tX9RBQTTkK5faKZ80laf/+/dd6OKgh/vCHPxjH//3vf6twJDCr2NhY/f3vf1fdunX11ltvVfVwgErBjDmAa8rb29s4LigoqMKRoDrZvXu3cXzzzTdX4UhgVmPHjlVmZqbeeecdp2uGgeqEGXMA19TOnTuN4w4dOlTdQGB6ubm5iouL04IFCzRixAhJUsuWLTVgwIAqHhnMZsmSJYqJiVHPnj3LXBYFOHLhwgV16tRJ/v7+8vHxUYsWLTR8+PAS/1dVJWbMAVwzv//+u2bOnCmp6HMMt9xySxWPCGbk7e2t3NzcUs937dpV//d//1fluyTAXJKSkvTyyy/Lx8dH7733XlUPB9VMVlaWDh48qODgYGVmZio2NlaxsbFauXKlRo8ercWLF6tWraqLx8yYA7gmCgsLNWLECJ09e1be3t5asGBBVQ8JJhUSEqKbbrpJfn5+xnM9evTQ22+/rWbNmlXhyGBGUVFRslqtio6OVosWLap6OKgmGjVqpGnTpumnn35STk6OUlJSlJWVpb1796pnz56SpOXLl+vFF1+s0nESzAFcE3/5y1/0xRdfSJIWLlyo2267rYpHBLOKi4vTb7/9poyMDJ07d07z5s3Tjz/+qM6dO2vq1KlVPTyYyEcffaQvv/xSd9xxh1566aWqHg6qkd69eys6Olq33Xab8Vs4d3d33XvvvdqyZYseeeQRSdI777yjkydPVtk4CeYAKt3EiRONGfK33npLTz31VBWPCNVFgwYNNGHCBG3evFkWi0Wvvfaa8QMebmznzp3TCy+8IHd3dy1ZsqRKlxugZnFzc9O8efMkFf229/PPP6+6sVTZlQHUSH/96181f/58SdK8efP0wgsvVO2AUC117txZ4eHhkqTFixdX8WhgBpMmTVJycrLGjRunNm3aKCMjo8Tj0qVLRl9HzwHOtGzZUvXq1ZMknT59usrGQTAHUGlefvllzZ07V5I0Z84cTZgwoYpHhOqscePGkqRff/21ikcCM4iNjZUkLVq0SAEBAaUexR80l2Q899e//rWqhgtcFX4PBKBSTJw40ZgpnzNnjl5++eUqHhGqu+JZq4CAgCoeCYCa7tSpU7p48aIkKSwsrMrGwYw5AJfZh/J58+YRyuFUQUGBbDab0z4xMTH6/vvvJUn333//dRgVzG7nzp2y2WxlPqZNm2b0LX7u7bffrroBwzTK+/fGZrMZ/2+5ubmpf//+12NYDhHMYUhNTdXFixeNR2FhoaSiPT/tn8/IyKjikcJM7NeUv/nmmyxfQbkSExPVsWNHvffeezp9+nSJ/zQTExM1a9YsPfLII7LZbKpTp06Vb18GoHqLj49X586dS/2bU1hYqG+//VZ9+/bVp59+KqloO86qvOeGxVbejxG4YYSGhio+Pr7cfqNGjdIHH3xw7QcE00tISFDz5s0lFc0ylHdb7IkTJ2rixInXY2gwsbi4uBK/Kvb09FRgYKCys7OVmZlpPB8WFqZ169apY8eOVTFMVDPR0dGaPn26pPJnSHFjufzfHC8vLwUEBCg9Pb3Ezc3McIMh1pgDuGrFv1UpPj537pzT/vy2BVLRjT7WrFmjnTt36rvvvtOZM2d08eJFubu7q1mzZrr99tv1yCOPaOjQofLx8anq4QKo5m666Sb985//1L59+/Tjjz/qwoULSk1Nlbe3t8LCwnTvvffqqaeeUteuXat6qMyYAwAAAGbAGnMAAADABAjmAAAAgAkQzAEAAAATIJgDAAAAJkAwBwAAAEyAYA4AAACYAMEcAAAAMAGCOQAAAGACBHMAAADABAjmAAAAgAkQzAEAAAATIJgDAAAAJkAwBwAAAEyAYA4AAACYwP8DQfRce3S91qwAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "plotting data\n",
        "• Boxplot: graphical representation\n",
        "summarizing a sample data using\n",
        "25th, 50th and 75th percentiles\n",
        "(lower quartile, median and\n",
        "upper quartile)"
      ],
      "metadata": {
        "id": "GusIntnIz8Rr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Conc.M'].describe()\n",
        "df['Conc.M'].plot(kind='box')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "cbKOU-doz5YL",
        "outputId": "21cccb2c-4b6e-43dd-8992-2261837ee8b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 113
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "assignment\n",
        "- get the record corresponding to the word 'bend'\n",
        "- select elements from 'home' to 'inside'\n",
        "- how many elements are included herein?\n",
        "- select (and count) items whose concreteness score is\n",
        "higher than 4, whose std is less than 1.5, and whose POS\n",
        "is 'Noun'\n",
        "- add a column ('robustly_concrete') to the DataFrame,\n",
        "where items selected in the former step are marked with 1\n",
        "if above conditions are met, and 0 otherwise. verify that\n",
        "the set of results has same size as at the previous step"
      ],
      "metadata": {
        "id": "ZprXT_Kx0JWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc['bend']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJwuTJJw0ETK",
        "outputId": "f69db1e9-bcb7-4b49-b857-696c4d3f8ead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Bigram                          0\n",
              "Conc.M                       3.88\n",
              "Conc.SD                       1.3\n",
              "Unknown                         0\n",
              "Total                          25\n",
              "Percent_known                 1.0\n",
              "SUBTLEX                       768\n",
              "Dom_Pos                      Verb\n",
              "concreteness_category    concrete\n",
              "Name: bend, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc['home':'inside']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "T_OORgyD0V_k",
        "outputId": "aba842e7-1a75-4f9f-83fc-94499e44472b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                  Bigram  Conc.M  Conc.SD  Unknown  Total  Percent_known  \\\n",
              "Word                                                                       \n",
              "home                   0    4.11     1.25        0     27           1.00   \n",
              "inland                 0    4.10     1.04        0     31           1.00   \n",
              "downstage              0    4.07     1.12        1     29           0.97   \n",
              "freckly                0    4.00     1.31        2     25           0.92   \n",
              "aboard                 0    3.97     1.30        0     30           1.00   \n",
              "downhill               0    3.97     1.09        0     29           1.00   \n",
              "bareback               0    3.96     1.32        0     28           1.00   \n",
              "offstage               0    3.96     1.20        0     28           1.00   \n",
              "horizontally           0    3.90     1.32        0     29           1.00   \n",
              "tight                  0    3.87     1.22        0     30           1.00   \n",
              "headfirst              0    3.83     1.40        1     24           0.96   \n",
              "up                     0    3.83     1.44        0     29           1.00   \n",
              "course                 0    3.82     1.12        0     28           1.00   \n",
              "underwater             0    3.78     1.15        0     27           1.00   \n",
              "upstream               0    3.77     1.22        0     30           1.00   \n",
              "alphabetically         0    3.74     1.43        0     27           1.00   \n",
              "loud                   0    3.73     1.22        0     26           1.00   \n",
              "crackly                0    3.69     1.32        3     29           0.90   \n",
              "plumb                  0    3.68     1.28        0     28           1.00   \n",
              "westward               0    3.68     1.22        0     28           1.00   \n",
              "counterclockwise       0    3.67     1.44        0     27           1.00   \n",
              "inside                 0    3.67     1.07        0     27           1.00   \n",
              "\n",
              "                  SUBTLEX Dom_Pos concreteness_category  \n",
              "Word                                                     \n",
              "home                39491  Adverb              concrete  \n",
              "inland                 69  Adverb              concrete  \n",
              "downstage               7  Adverb              concrete  \n",
              "freckly                 1  Adverb              concrete  \n",
              "aboard               1358  Adverb              concrete  \n",
              "downhill              126  Adverb              concrete  \n",
              "bareback               23  Adverb              concrete  \n",
              "offstage               22  Adverb              concrete  \n",
              "horizontally           24  Adverb              concrete  \n",
              "tight                2597  Adverb              concrete  \n",
              "headfirst              16  Adverb              concrete  \n",
              "up                 187170  Adverb              concrete  \n",
              "course              24848  Adverb              concrete  \n",
              "underwater            323  Adverb              concrete  \n",
              "upstream               51  Adverb              concrete  \n",
              "alphabetically         30  Adverb              concrete  \n",
              "loud                 2031  Adverb              concrete  \n",
              "crackly                 2  Adverb              concrete  \n",
              "plumb                  86  Adverb              concrete  \n",
              "westward               24  Adverb              concrete  \n",
              "counterclockwise       22  Adverb              concrete  \n",
              "inside              10775  Adverb              concrete  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bad09e45-f8ff-41ee-84ed-96702bffaf17\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bigram</th>\n",
              "      <th>Conc.M</th>\n",
              "      <th>Conc.SD</th>\n",
              "      <th>Unknown</th>\n",
              "      <th>Total</th>\n",
              "      <th>Percent_known</th>\n",
              "      <th>SUBTLEX</th>\n",
              "      <th>Dom_Pos</th>\n",
              "      <th>concreteness_category</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>home</th>\n",
              "      <td>0</td>\n",
              "      <td>4.11</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>1.00</td>\n",
              "      <td>39491</td>\n",
              "      <td>Adverb</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>inland</th>\n",
              "      <td>0</td>\n",
              "      <td>4.10</td>\n",
              "      <td>1.04</td>\n",
              "      <td>0</td>\n",
              "      <td>31</td>\n",
              "      <td>1.00</td>\n",
              "      <td>69</td>\n",
              "      <td>Adverb</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>downstage</th>\n",
              "      <td>0</td>\n",
              "      <td>4.07</td>\n",
              "      <td>1.12</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>0.97</td>\n",
              "      <td>7</td>\n",
              "      <td>Adverb</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freckly</th>\n",
              "      <td>0</td>\n",
              "      <td>4.00</td>\n",
              "      <td>1.31</td>\n",
              "      <td>2</td>\n",
              "      <td>25</td>\n",
              "      <td>0.92</td>\n",
              "      <td>1</td>\n",
              "      <td>Adverb</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aboard</th>\n",
              "      <td>0</td>\n",
              "      <td>3.97</td>\n",
              "      <td>1.30</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1358</td>\n",
              "      <td>Adverb</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>downhill</th>\n",
              "      <td>0</td>\n",
              "      <td>3.97</td>\n",
              "      <td>1.09</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>1.00</td>\n",
              "      <td>126</td>\n",
              "      <td>Adverb</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bareback</th>\n",
              "      <td>0</td>\n",
              "      <td>3.96</td>\n",
              "      <td>1.32</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>1.00</td>\n",
              "      <td>23</td>\n",
              "      <td>Adverb</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>offstage</th>\n",
              "      <td>0</td>\n",
              "      <td>3.96</td>\n",
              "      <td>1.20</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>1.00</td>\n",
              "      <td>22</td>\n",
              "      <td>Adverb</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>horizontally</th>\n",
              "      <td>0</td>\n",
              "      <td>3.90</td>\n",
              "      <td>1.32</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>1.00</td>\n",
              "      <td>24</td>\n",
              "      <td>Adverb</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tight</th>\n",
              "      <td>0</td>\n",
              "      <td>3.87</td>\n",
              "      <td>1.22</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>1.00</td>\n",
              "      <td>2597</td>\n",
              "      <td>Adverb</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>headfirst</th>\n",
              "      <td>0</td>\n",
              "      <td>3.83</td>\n",
              "      <td>1.40</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>0.96</td>\n",
              "      <td>16</td>\n",
              "      <td>Adverb</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>up</th>\n",
              "      <td>0</td>\n",
              "      <td>3.83</td>\n",
              "      <td>1.44</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>1.00</td>\n",
              "      <td>187170</td>\n",
              "      <td>Adverb</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>course</th>\n",
              "      <td>0</td>\n",
              "      <td>3.82</td>\n",
              "      <td>1.12</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>1.00</td>\n",
              "      <td>24848</td>\n",
              "      <td>Adverb</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>underwater</th>\n",
              "      <td>0</td>\n",
              "      <td>3.78</td>\n",
              "      <td>1.15</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>1.00</td>\n",
              "      <td>323</td>\n",
              "      <td>Adverb</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>upstream</th>\n",
              "      <td>0</td>\n",
              "      <td>3.77</td>\n",
              "      <td>1.22</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>1.00</td>\n",
              "      <td>51</td>\n",
              "      <td>Adverb</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alphabetically</th>\n",
              "      <td>0</td>\n",
              "      <td>3.74</td>\n",
              "      <td>1.43</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>1.00</td>\n",
              "      <td>30</td>\n",
              "      <td>Adverb</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>loud</th>\n",
              "      <td>0</td>\n",
              "      <td>3.73</td>\n",
              "      <td>1.22</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>1.00</td>\n",
              "      <td>2031</td>\n",
              "      <td>Adverb</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>crackly</th>\n",
              "      <td>0</td>\n",
              "      <td>3.69</td>\n",
              "      <td>1.32</td>\n",
              "      <td>3</td>\n",
              "      <td>29</td>\n",
              "      <td>0.90</td>\n",
              "      <td>2</td>\n",
              "      <td>Adverb</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>plumb</th>\n",
              "      <td>0</td>\n",
              "      <td>3.68</td>\n",
              "      <td>1.28</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>1.00</td>\n",
              "      <td>86</td>\n",
              "      <td>Adverb</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>westward</th>\n",
              "      <td>0</td>\n",
              "      <td>3.68</td>\n",
              "      <td>1.22</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>1.00</td>\n",
              "      <td>24</td>\n",
              "      <td>Adverb</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>counterclockwise</th>\n",
              "      <td>0</td>\n",
              "      <td>3.67</td>\n",
              "      <td>1.44</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>1.00</td>\n",
              "      <td>22</td>\n",
              "      <td>Adverb</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>inside</th>\n",
              "      <td>0</td>\n",
              "      <td>3.67</td>\n",
              "      <td>1.07</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>1.00</td>\n",
              "      <td>10775</td>\n",
              "      <td>Adverb</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bad09e45-f8ff-41ee-84ed-96702bffaf17')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bad09e45-f8ff-41ee-84ed-96702bffaf17 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bad09e45-f8ff-41ee-84ed-96702bffaf17');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ab661607-1961-4a59-a505-7b3284a38662\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ab661607-1961-4a59-a505-7b3284a38662')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ab661607-1961-4a59-a505-7b3284a38662 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 22,\n  \"fields\": [\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 22,\n        \"samples\": [\n          \"home\",\n          \"underwater\",\n          \"horizontally\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bigram\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14542965154941256,\n        \"min\": 3.67,\n        \"max\": 4.11,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          4.11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.SD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11967850150692777,\n        \"min\": 1.04,\n        \"max\": 1.44,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          1.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unknown\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 3,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 24,\n        \"max\": 31,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          31\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Percent_known\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02765354615087574,\n        \"min\": 0.9,\n        \"max\": 1.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.97\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SUBTLEX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 40265,\n        \"min\": 1,\n        \"max\": 187170,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          39491\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dom_Pos\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Adverb\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"concreteness_category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"concrete\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df.loc['home':'inside'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaXOp2Bx0jW7",
        "outputId": "0b7bb81c-b7ea-4b47-9781-fbdb25e627c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[(df['Conc.M']>4)&(df['Conc.SD']<1.5)&(df['Dom_Pos']==\"Noun\")]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "k1xdSBOL0nE7",
        "outputId": "8d875e98-8053-423a-aef8-e77af9482920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Bigram  Conc.M  Conc.SD  Unknown  Total  Percent_known  SUBTLEX  \\\n",
              "Word                                                                           \n",
              "angelfish         0    5.00     0.00        0     27            1.0        5   \n",
              "antelope          0    5.00     0.00        0     28            1.0       50   \n",
              "apple             0    5.00     0.00        0     30            1.0     1207   \n",
              "armchair          0    5.00     0.00        0     29            1.0       21   \n",
              "axe               0    5.00     0.00        0     27            1.0      249   \n",
              "...             ...     ...      ...      ...    ...            ...      ...   \n",
              "slum              0    4.03     0.98        0     29            1.0       65   \n",
              "sportscast        0    4.03     1.12        0     29            1.0        2   \n",
              "structure         0    4.03     1.43        0     29            1.0      519   \n",
              "twine             0    4.03     1.38        0     30            1.0       29   \n",
              "wintergreen       0    4.03     1.12        0     29            1.0        4   \n",
              "\n",
              "            Dom_Pos concreteness_category  \n",
              "Word                                       \n",
              "angelfish      Noun              concrete  \n",
              "antelope       Noun              concrete  \n",
              "apple          Noun              concrete  \n",
              "armchair       Noun              concrete  \n",
              "axe            Noun              concrete  \n",
              "...             ...                   ...  \n",
              "slum           Noun              concrete  \n",
              "sportscast     Noun              concrete  \n",
              "structure      Noun              concrete  \n",
              "twine          Noun              concrete  \n",
              "wintergreen    Noun              concrete  \n",
              "\n",
              "[5758 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-82e9be86-461c-42b1-a28b-1490fbd746b3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bigram</th>\n",
              "      <th>Conc.M</th>\n",
              "      <th>Conc.SD</th>\n",
              "      <th>Unknown</th>\n",
              "      <th>Total</th>\n",
              "      <th>Percent_known</th>\n",
              "      <th>SUBTLEX</th>\n",
              "      <th>Dom_Pos</th>\n",
              "      <th>concreteness_category</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>angelfish</th>\n",
              "      <td>0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5</td>\n",
              "      <td>Noun</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>antelope</th>\n",
              "      <td>0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50</td>\n",
              "      <td>Noun</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>apple</th>\n",
              "      <td>0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1207</td>\n",
              "      <td>Noun</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>armchair</th>\n",
              "      <td>0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>1.0</td>\n",
              "      <td>21</td>\n",
              "      <td>Noun</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>axe</th>\n",
              "      <td>0</td>\n",
              "      <td>5.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>27</td>\n",
              "      <td>1.0</td>\n",
              "      <td>249</td>\n",
              "      <td>Noun</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>slum</th>\n",
              "      <td>0</td>\n",
              "      <td>4.03</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>1.0</td>\n",
              "      <td>65</td>\n",
              "      <td>Noun</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sportscast</th>\n",
              "      <td>0</td>\n",
              "      <td>4.03</td>\n",
              "      <td>1.12</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2</td>\n",
              "      <td>Noun</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>structure</th>\n",
              "      <td>0</td>\n",
              "      <td>4.03</td>\n",
              "      <td>1.43</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>1.0</td>\n",
              "      <td>519</td>\n",
              "      <td>Noun</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>twine</th>\n",
              "      <td>0</td>\n",
              "      <td>4.03</td>\n",
              "      <td>1.38</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>1.0</td>\n",
              "      <td>29</td>\n",
              "      <td>Noun</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>wintergreen</th>\n",
              "      <td>0</td>\n",
              "      <td>4.03</td>\n",
              "      <td>1.12</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4</td>\n",
              "      <td>Noun</td>\n",
              "      <td>concrete</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5758 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82e9be86-461c-42b1-a28b-1490fbd746b3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-82e9be86-461c-42b1-a28b-1490fbd746b3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-82e9be86-461c-42b1-a28b-1490fbd746b3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-867c4f2b-0ab2-44a7-a6e6-859836f74935\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-867c4f2b-0ab2-44a7-a6e6-859836f74935')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-867c4f2b-0ab2-44a7-a6e6-859836f74935 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df[(df['Conc\",\n  \"rows\": 5758,\n  \"fields\": [\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5758,\n        \"samples\": [\n          \"bayou\",\n          \"bong\",\n          \"kit\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bigram\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.27693993077524337,\n        \"min\": 4.03,\n        \"max\": 5.0,\n        \"num_unique_values\": 94,\n        \"samples\": [\n          4.57\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.SD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.34311777136320837,\n        \"min\": 0.0,\n        \"max\": 1.48,\n        \"num_unique_values\": 129,\n        \"samples\": [\n          0.49\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unknown\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 0,\n        \"max\": 620,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          127\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 320,\n        \"min\": 22,\n        \"max\": 6072,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          31\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Percent_known\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03580493389326031,\n        \"min\": 0.85,\n        \"max\": 1.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          0.86\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SUBTLEX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2446,\n        \"min\": 0,\n        \"max\": 94133,\n        \"num_unique_values\": 1171,\n        \"samples\": [\n          56252\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dom_Pos\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Noun\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"concreteness_category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"concrete\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def robustly_M(x):\n",
        "  if x>4:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "def robustly_SD(x):\n",
        "  if x<1.5:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "def rosbustly_Pos(x):\n",
        "  if x=='Noun':\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "Conc_M = df['Conc.M'].apply(robustly_M)\n",
        "Conc_SD = df['Conc.SD'].apply(robustly_SD)\n",
        "Dom_Pos = df['Dom_Pos'].apply(rosbustly_Pos)\n",
        "df['robustly_concrete'] = Conc_M&Conc_SD&Dom_Pos\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "HxJXEQKH1xy8",
        "outputId": "5baf931d-5126-47af-9238-80e596896480"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Bigram  Conc.M  Conc.SD  Unknown  Total  Percent_known  \\\n",
              "Word                                                                    \n",
              "roadsweeper         0    4.85     0.37        1     27           0.96   \n",
              "traindriver         0    4.54     0.71        3     29           0.90   \n",
              "tush                0    4.45     1.01        3     25           0.88   \n",
              "hairdress           0    3.93     1.28        0     29           1.00   \n",
              "pharmaceutics       0    3.77     1.41        4     26           0.85   \n",
              "\n",
              "               SUBTLEX Dom_Pos concreteness_category  robustly_concrete  \n",
              "Word                                                                     \n",
              "roadsweeper          0       0              concrete                  0  \n",
              "traindriver          0       0              concrete                  0  \n",
              "tush                66       0              concrete                  0  \n",
              "hairdress            1       0              concrete                  0  \n",
              "pharmaceutics        0       0              concrete                  0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-67fd6af8-4724-4a8c-aa67-59720faa4bc9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Bigram</th>\n",
              "      <th>Conc.M</th>\n",
              "      <th>Conc.SD</th>\n",
              "      <th>Unknown</th>\n",
              "      <th>Total</th>\n",
              "      <th>Percent_known</th>\n",
              "      <th>SUBTLEX</th>\n",
              "      <th>Dom_Pos</th>\n",
              "      <th>concreteness_category</th>\n",
              "      <th>robustly_concrete</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>roadsweeper</th>\n",
              "      <td>0</td>\n",
              "      <td>4.85</td>\n",
              "      <td>0.37</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>concrete</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>traindriver</th>\n",
              "      <td>0</td>\n",
              "      <td>4.54</td>\n",
              "      <td>0.71</td>\n",
              "      <td>3</td>\n",
              "      <td>29</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>concrete</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tush</th>\n",
              "      <td>0</td>\n",
              "      <td>4.45</td>\n",
              "      <td>1.01</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "      <td>0.88</td>\n",
              "      <td>66</td>\n",
              "      <td>0</td>\n",
              "      <td>concrete</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hairdress</th>\n",
              "      <td>0</td>\n",
              "      <td>3.93</td>\n",
              "      <td>1.28</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>concrete</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pharmaceutics</th>\n",
              "      <td>0</td>\n",
              "      <td>3.77</td>\n",
              "      <td>1.41</td>\n",
              "      <td>4</td>\n",
              "      <td>26</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>concrete</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67fd6af8-4724-4a8c-aa67-59720faa4bc9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-67fd6af8-4724-4a8c-aa67-59720faa4bc9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-67fd6af8-4724-4a8c-aa67-59720faa4bc9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ff23f1cb-8e2e-4ad6-b313-25b920d2f397\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ff23f1cb-8e2e-4ad6-b313-25b920d2f397')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ff23f1cb-8e2e-4ad6-b313-25b920d2f397 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 39954,\n  \"fields\": [\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39953,\n        \"samples\": [\n          \"sexually\",\n          \"revisionism\",\n          \"compressor\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Bigram\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.M\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0386021803079468,\n        \"min\": 1.04,\n        \"max\": 5.0,\n        \"num_unique_values\": 368,\n        \"samples\": [\n          3.16,\n          4.68\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conc.SD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.31093059573336734,\n        \"min\": 0.0,\n        \"max\": 1.89,\n        \"num_unique_values\": 165,\n        \"samples\": [\n          0.56,\n          1.63\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Unknown\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 620,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          1,\n          19\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 174,\n        \"min\": 21,\n        \"max\": 6072,\n        \"num_unique_values\": 37,\n        \"samples\": [\n          5870,\n          6064\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Percent_known\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04500878702071559,\n        \"min\": 0.85,\n        \"max\": 1.0,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          0.96,\n          0.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SUBTLEX\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22420,\n        \"min\": 0,\n        \"max\": 2134713,\n        \"num_unique_values\": 2737,\n        \"samples\": [\n          819,\n          3602\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dom_Pos\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"0\",\n          \"Adjective\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"concreteness_category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"abstract\",\n          \"concrete\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"robustly_concrete\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. consider a CSV file (student_marks.csv) containing data about student grades\n",
        "and performs statistical analysis on the data using pandas. The CSV file contains the\n",
        "following columns:\n",
        "- StudentID: Unique identifier for each student.\n",
        "- Name: Name of the student.\n",
        "- Math: Math score of the student.\n",
        "- Science: Science score of the student.\n",
        "- English: English score of the student."
      ],
      "metadata": {
        "id": "m82loABo4ABW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def csv(file_path):\n",
        "  df = pd.read_csv(file_path)\n",
        "  calculate_min = df[['Math','Science','English']].describe()\n",
        "  df['calculate_avg'] = df[['Math','Science','English']].mean(axis=1)\n",
        "  highest_overall_average = df.loc[df['calculate_avg'].idxmax()]\n",
        "  return df,calculate_min,df['calculate_avg'],highest_overall_average[[\"Name\",'calculate_avg']]\n",
        "file_path = \"student_marks.csv\"\n",
        "print(csv(file_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhPFcmdf2avU",
        "outputId": "a99ff245-5f9d-4ad3-a1af-6aa7b22aebef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(   StudentID           Name  Math  Science  English  calculate_avg\n",
            "0          1  'Mario Rossi'    30       28       24      27.333333\n",
            "1          2     'John Bos'    27       28       27      27.333333\n",
            "2          3    'Ann Green'    30       25       30      28.333333\n",
            "3          4   'Tess Black'    22       25       28      25.000000\n",
            "4          5   'Laura Blue'    24       28       28      26.666667\n",
            "5          6    'Daisy Sun'    30       28       28      28.666667\n",
            "6          7   'Tom Donkey'    21       22       23      22.000000,             Math    Science    English\n",
            "count   7.000000   7.000000   7.000000\n",
            "mean   26.285714  26.285714  26.857143\n",
            "std     3.946065   2.360387   2.478479\n",
            "min    21.000000  22.000000  23.000000\n",
            "25%    23.000000  25.000000  25.500000\n",
            "50%    27.000000  28.000000  28.000000\n",
            "75%    30.000000  28.000000  28.000000\n",
            "max    30.000000  28.000000  30.000000, 0    27.333333\n",
            "1    27.333333\n",
            "2    28.333333\n",
            "3    25.000000\n",
            "4    26.666667\n",
            "5    28.666667\n",
            "6    22.000000\n",
            "Name: calculate_avg, dtype: float64, Name             'Daisy Sun'\n",
            "calculate_avg      28.666667\n",
            "Name: 5, dtype: object)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write a function that takes in input the file path to the CSV file. the function should\n",
        "read the CSV file using pandas, perform the following analyses, and return the\n",
        "results:\n",
        "- calculate the mean, median, minimum, and maximum scores for each subject\n",
        "(Math, Science, English).\n",
        "- calculate the overall average score for each student (average of Math, Science,\n",
        "and English scores).\n",
        "- identify the student with the highest overall average score and return their name\n",
        "and average score"
      ],
      "metadata": {
        "id": "PNeAY2R57w5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def analyze_student_grades(csv_file):\n",
        "    # Read the CSV file into a pandas DataFrame\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Calculate mean, median, minimum, and maximum scores for each subject\n",
        "    subject_stats = df[['Math', 'Science', 'English']].describe().loc[['mean', '50%', 'min', 'max']]\n",
        "\n",
        "    # Calculate overall average score for each student\n",
        "    df['Overall Average'] = df[['Math', 'Science', 'English']].mean(axis=1)\n",
        "\n",
        "    # Identify the student with the highest overall average score\n",
        "    highest_avg_student = df.loc[df['Overall Average'].idxmax()]\n",
        "\n",
        "    return subject_stats, df, highest_avg_student[['Name', 'Overall Average']]\n",
        "\n",
        "# Example usage:\n",
        "csv_file = 'student_marks.csv'\n",
        "subject_stats, student_grades, highest_avg_student = analyze_student_grades(csv_file)\n",
        "\n",
        "print(\"Subject-wise statistics:\")\n",
        "print(subject_stats)\n",
        "\n",
        "print(\"\\nStudent grades:\")\n",
        "print(student_grades)\n",
        "\n",
        "print(\"\\nStudent with the highest overall average score:\")\n",
        "print(highest_avg_student)\n"
      ],
      "metadata": {
        "id": "Ae2QdZvw4wQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vector Space Model\n",
        "and document similarity"
      ],
      "metadata": {
        "id": "0a9IMqhekCvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "import gensim\n",
        "import numpy as np"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Dfj3hMFkEZk",
        "outputId": "59105dd9-0ad8-48c2-a196-6cd083e3a28f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# tokenize words"
      ],
      "metadata": {
        "id": "v2ltAWAK2hU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_docs = []\n",
        "file_docs.append('An Operating System is a special piece of software that manages the computer hardware and the software resources.')\n",
        "file_docs.append('The operating system acts as an intermediary between programs and the computer hardware.')\n",
        "file_docs.append('A distributed operating system manages a group of distinct computers and makes them appear to be a single computer.')\n",
        "print(file_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aq6V4NJL1pQb",
        "outputId": "11098187-0658-4f56-d94e-ebd42f7412fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['An Operating System is a special piece of software that manages the computer hardware and the software resources.', 'The operating system acts as an intermediary between programs and the computer hardware.', 'A distributed operating system manages a group of distinct computers and makes them appear to be a single computer.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gen_docs = [[w.lower() for w in word_tokenize(text)] for text in file_docs]\n",
        "print(gen_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TTh8RjR14jr",
        "outputId": "ccf5860c-8fa1-48a1-a9f7-ed53180ea66a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['an', 'operating', 'system', 'is', 'a', 'special', 'piece', 'of', 'software', 'that', 'manages', 'the', 'computer', 'hardware', 'and', 'the', 'software', 'resources', '.'], ['the', 'operating', 'system', 'acts', 'as', 'an', 'intermediary', 'between', 'programs', 'and', 'the', 'computer', 'hardware', '.'], ['a', 'distributed', 'operating', 'system', 'manages', 'a', 'group', 'of', 'distinct', 'computers', 'and', 'makes', 'them', 'appear', 'to', 'be', 'a', 'single', 'computer', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# a dictionary is built to map each word to a number"
      ],
      "metadata": {
        "id": "pC2L8Ums239M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = gensim.corpora.Dictionary(gen_docs)\n",
        "print(dictionary.token2id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyCKS_zf2Jnj",
        "outputId": "8e460229-9618-4e53-8fad-6bed3740a034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'.': 0, 'a': 1, 'an': 2, 'and': 3, 'computer': 4, 'hardware': 5, 'is': 6, 'manages': 7, 'of': 8, 'operating': 9, 'piece': 10, 'resources': 11, 'software': 12, 'special': 13, 'system': 14, 'that': 15, 'the': 16, 'acts': 17, 'as': 18, 'between': 19, 'intermediary': 20, 'programs': 21, 'appear': 22, 'be': 23, 'computers': 24, 'distinct': 25, 'distributed': 26, 'group': 27, 'makes': 28, 'single': 29, 'them': 30, 'to': 31}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "create the vector, which we call bag of words (more later on)"
      ],
      "metadata": {
        "id": "L8Uxct4J3Joi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_bag_of_words = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]\n",
        "print(corpus_bag_of_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_ZF6l1S2_wE",
        "outputId": "88d5de2c-ff68-42c9-b7e5-11765506044d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 2), (13, 1), (14, 1), (15, 1), (16, 2)], [(0, 1), (2, 1), (3, 1), (4, 1), (5, 1), (9, 1), (14, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1)], [(0, 1), (1, 3), (3, 1), (4, 1), (7, 1), (8, 1), (9, 1), (14, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1)]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " TF-IDF: one step only"
      ],
      "metadata": {
        "id": "Ezbe7lGJ9jEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_idf = gensim.models.TfidfModel(corpus_bag_of_words)\n",
        "print('\\nTF-IDF representation: ')\n",
        "for doc in tf_idf[corpus_bag_of_words]:\n",
        "  print([[dictionary[id], np.around(freq, decimals=2)] for id, freq in doc])\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sye78A719iRk",
        "outputId": "4aec6013-ec9e-450d-ac9b-4964a108a95f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "TF-IDF representation: \n",
            "[['a', 0.12], ['an', 0.12], ['hardware', 0.12], ['is', 0.31], ['manages', 0.12], ['of', 0.12], ['piece', 0.31], ['resources', 0.31], ['software', 0.63], ['special', 0.31], ['that', 0.31], ['the', 0.23]]\n",
            "\n",
            "[['an', 0.15], ['hardware', 0.15], ['the', 0.31], ['acts', 0.41], ['as', 0.41], ['between', 0.41], ['intermediary', 0.41], ['programs', 0.41]]\n",
            "\n",
            "[['a', 0.33], ['manages', 0.11], ['of', 0.11], ['appear', 0.29], ['be', 0.29], ['computers', 0.29], ['distinct', 0.29], ['distributed', 0.29], ['group', 0.29], ['makes', 0.29], ['single', 0.29], ['them', 0.29], ['to', 0.29]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "cosine similarity cos(v, w) =\n",
        "v ⋅ w\n",
        "∥v∥∥w∥\n",
        "=\n",
        "∑N i=1 viwi\n",
        "∑N i=1 vi2 ∑N i=1 wi"
      ],
      "metadata": {
        "id": "kPJg4dQs5UUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import math\n",
        "from numpy.linalg import norm\n",
        "v = np.array([10, 1])\n",
        "u = np.array([10, 2])\n",
        "z = np.array([ 2, 23])\n",
        "# compute norm by hand vs the norm() function\n",
        "v_norm = round(math.sqrt(sum(pow(elem, 2) for elem in v)),2)\n",
        "u_norm = round(math.sqrt(sum(pow(elem, 2) for elem in u)),2)\n",
        "z_norm = round(math.sqrt(sum(pow(elem, 2) for elem in z)),2)\n",
        "print(f'v_norm: {v_norm}; u_norm: {u_norm}; z_norm: {z_norm}')\n",
        "print(f'v_norm: {norm(v)}; u_norm: {norm(u)}; z_norm: {norm(z)}')\n",
        "# dotproduct\n",
        "print(f'v@u = {v @ u}; v@z = {v @ z}')\n",
        "# cosine\n",
        "cos_vu = (v @ u)/(v_norm * u_norm)\n",
        "cos_vz = (v @ z)/(v_norm * z_norm)\n",
        "print(f'cos_vu = {cos_vu}; cos_vz = {cos_vz}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8CqWqQv3hCT",
        "outputId": "9f6ec112-f81b-4182-f3f8-0458bbe9cfbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "v_norm: 10.05; u_norm: 10.2; z_norm: 23.09\n",
            "v_norm: 10.04987562112089; u_norm: 10.198039027185569; z_norm: 23.08679276123039\n",
            "v@u = 102; v@z = 43\n",
            "cos_vu = 0.9950248756218905; cos_vz = 0.18530129775548415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Space Model and document similarity"
      ],
      "metadata": {
        "id": "lv2p3eYYGb2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### collecting the data"
      ],
      "metadata": {
        "id": "fPdIXMuGGeSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import gensim\n",
        "import numpy as np\n",
        "\n",
        "file_docs = []\n",
        "with open('data/doc1.txt') as f:\n",
        "    # extract sentences from text\n",
        "    tokens = sent_tokenize(f.read()) # take the entire text and return sentences\n",
        "    for line in tokens:\n",
        "        file_docs.append(line)\n",
        "print(\"Number of documents: \", len(file_docs))\n",
        "file_docs"
      ],
      "metadata": {
        "id": "wliWR_Jt5XoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tokenization"
      ],
      "metadata": {
        "id": "fbXmCmMtGhSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize words\n",
        "gen_docs = [[w.lower() for w in word_tokenize(text)] for text in file_docs]\n",
        "print(gen_docs)"
      ],
      "metadata": {
        "id": "jU0FGukTGi3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dictionary creation"
      ],
      "metadata": {
        "id": "FvrNXqb6GlgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = gensim.corpora.Dictionary(gen_docs)\n",
        "# Gensim lets you read the text and update the dictionary,\n",
        "# one line at a time, without loading the entire text file\n",
        "# into system memory.\n",
        "\n",
        "# each term is associated to a number in the dictionary:\n",
        "print('\\nDictionary: ')\n",
        "print(dictionary.token2id)\n",
        "print()"
      ],
      "metadata": {
        "id": "L8W-ev3WGnRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### building a bag of words"
      ],
      "metadata": {
        "id": "LPTUd8euGr-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a bag of words\n",
        "corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]\n",
        "\n",
        "# print the number of times each token occurs in the corpus.\n",
        "# please note that each line is (for simplicity) associated\n",
        "# to a document, such that the whole document can be seen as\n",
        "# a corpus\n",
        "print('\\nBag of words representation: ')\n",
        "print(corpus)"
      ],
      "metadata": {
        "id": "s-0vclHDGszQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### TF-IDF weighting\n",
        "\n",
        "We then compute the **TF-IDF** score (term frequency, inverse document frequency), which is a descriptive statistics of terms in a document collection.\n",
        "TF-IDF is a metric that allows estimating the relevance of terms based on its frequency in a given document, and its low-frequency (therefore more discriminative) within the whole collection of documents.\n",
        "\n",
        "For example, the term 'Bible', if considered within a corpus of religious documents might be quite common (and poorly discriminative): it should then obtain lower score than that featuring 'Bible' in a computer programming setting (where 'Bible' is used to denote a book featured by wide and in-depth coverage of arguments), where the same term is expected to be more discriminative.\n",
        "\n",
        "In the next block we compute and print TF-IDF scores for all terms in the dictionary."
      ],
      "metadata": {
        "id": "0ZK6XgBBGwQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Term Frequency – Inverse Document Frequency(TF-IDF) is also a bag-of-words model but unlike\n",
        "# the regular corpus, TFIDF down weights tokens (words) that appear frequently across documents.\n",
        "# Term frequency is how often the word shows up in the document and inverse document frequency\n",
        "# scales the value by how rare the word is in the corpus.\n",
        "# In simple terms, words that occur more frequently across the documents get smaller weights.\n",
        "#\n",
        "tf_idf = gensim.models.TfidfModel(corpus)\n",
        "print('\\nTF-IDF representation: ')\n",
        "for doc in tf_idf[corpus]:\n",
        "    print([[dictionary[id], np.around(freq, decimals=2)] for id, freq in doc])\n",
        "    print()"
      ],
      "metadata": {
        "id": "JvVyurxnGyFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next block is used to create the index (which, in turn, is done through a Similarity object: not that relevant for present).\n",
        "The index is then used to compute the similarity between vector pairs."
      ],
      "metadata": {
        "id": "uMnkNZ95G2jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# creating similarity measure object\n",
        "# building the index\n",
        "sims = gensim.similarities.Similarity(\n",
        "    'data/', tf_idf[corpus], num_features=len(dictionary))"
      ],
      "metadata": {
        "id": "AKeEODQBG3D5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## similarity between queries and documents Once we have built the TF-IDF representation for documents in the collection, we still have to 'vectorize' the query/queries, in order to be able **to retrieve documents that best suit our query/queries**.\n",
        "\n",
        "Comparing two text documents amounts to comparing their corresponding vectors, and this is done through cosine similarity. By switching to the geometric view on our vectors, cosine similarity computes their angular distance.\n",
        "\n",
        "Let us assume we have already computed the vectors for documents _d1_ and _d2_ and for the query _q_ (here mapped onto a bidimensional space, as in previous example, which is easier to represent than a general n-dimensional space), like in the figure below.\n",
        "To estimate the similarity between documents we compute the cosine of their intervening angles: as it can be directly seen in this example, the alpha angle is narrower than theta, so document _d1_ is more similar to the query _q_ than _d2_.\n",
        "\n",
        "![vector space model](https://upload.wikimedia.org/wikipedia/commons/f/ff/Vector_space_model.jpg)\n",
        "\n",
        "---\n",
        "\n",
        "Code in the cell below opens the file `doc2.txt`, takes sentences herein and adds them to the list (`file2_docs`); it then plots how many queries were found. As we did before, we are now assuming that a sentence directly corresponds to a single query."
      ],
      "metadata": {
        "id": "lKXecp1cG50p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file2_docs = []\n",
        "with open ('data/doc2.txt') as f:\n",
        "    tokens = sent_tokenize(f.read())\n",
        "    for line in tokens:\n",
        "        file2_docs.append(line)\n",
        "\n",
        "print(\"\\nNumber of query documents: \", len(file2_docs))\n",
        "print('\\nThe queries in the file are:')\n",
        "counter = 0\n",
        "for l in file2_docs:\n",
        "    counter += 1\n",
        "    print('\\n[Query number {}]: {}'.format(counter, l))"
      ],
      "metadata": {
        "id": "uFi-1_N3G9pZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Same vectorization operations as done for documents in the collection are performed in the cell below (that is, tokenization, creation of the dictionary, creation of the bag-of-words, computation of the tf-idf score for each element).\n",
        "\n",
        "It additionally computes the similarity between each query and each document, printing out the obtained scores."
      ],
      "metadata": {
        "id": "kBGEvkfkHAyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_sims = [] # array for average scores\n",
        "\n",
        "# for each line in the document containing the queries\n",
        "for line in file2_docs: # loop on queries\n",
        "    # tokenize words\n",
        "    query_doc = [w.lower() for w in word_tokenize(line)]\n",
        "    print('\\nquery: ' + str(query_doc))\n",
        "    # create bag of words\n",
        "    query_doc_bow = dictionary.doc2bow(query_doc)\n",
        "    # to find the similarity for each document we compute tfidf for terms\n",
        "    query_doc_tf_idf = tf_idf[query_doc_bow]\n",
        "    # print (document_number, document_similarity)\n",
        "    print('\\nsimilarity between query and each document in the collection:', sims[query_doc_tf_idf])\n",
        "    # calculate sum of similarities for each query doc\n",
        "    sum_of_sims =(np.sum(sims[query_doc_tf_idf], dtype=np.float64))\n",
        "    # calculate average of similarity for each query doc\n",
        "    avg = sum_of_sims / len(file_docs)\n",
        "    # print average of similarity for each query doc\n",
        "    print(f'average similarity between query and collection documents: {sum_of_sims / len(file_docs)}')\n",
        "    # add average values into array\n",
        "    avg_sims.append(avg)\n",
        "    # calculate total average\n",
        "    total_avg = np.sum(avg_sims, dtype=np.float64)\n",
        "    # round the value and multiply by 100 to format it as percentage\n",
        "    percentage_of_similarity = round(float(total_avg) * 100)\n",
        "    # if percentage is greater than 100\n",
        "    # that means documents are almost same\n",
        "    if percentage_of_similarity >= 100:\n",
        "        percentage_of_similarity = 100\n"
      ],
      "metadata": {
        "id": "JYNmeQZfHCpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "building the collection\n",
        "• in the utils/ directory (Moodle page of the course,\n",
        "lesson 18) you will find five files:\n",
        "- cajun_chicken_pasta.txt\n",
        "- computer_architecture.txt\n",
        "- databases.txt\n",
        "- operating_systems.txt\n",
        "- theoretical_cs.txt\n",
        "querying the collection\n",
        "• based on the notebook\n",
        "17_VSM_doc_similarity_PUBLIC.ipynb (available in the\n",
        "bundle of lesson 17) write a program that takes in input\n",
        "a query and returns the name of one of the above files\n",
        "along with the score characterizing that pair\n",
        "⟨query, doc⟩\n",
        "testing the system\n",
        "• test the output of your program with the following query\n",
        "strings:\n",
        "- 'use shrimp or sliced andouille sausage'\n",
        "- 'polynomial factorization, indefinite integration'\n",
        "- 'data warehouses archive data'\n",
        "- 'scheduling algorithms'\n",
        "- 'gates, multiplexers, latches'"
      ],
      "metadata": {
        "id": "9xM4wkLhIBWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import defaultdict\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Function to read documents and build the document-term matrix\n",
        "def build_document_term_matrix(directory):\n",
        "    documents = []\n",
        "    filenames = []\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        with open(os.path.join(directory, filename), 'r', encoding='utf-8') as file:\n",
        "            documents.append(file.read())\n",
        "            filenames.append(filename)\n",
        "\n",
        "    vectorizer = CountVectorizer()\n",
        "    X = vectorizer.fit_transform(documents)\n",
        "\n",
        "    return X, vectorizer, filenames\n",
        "\n",
        "# Function to perform cosine similarity between query and documents\n",
        "def query_document_similarity(query, X_query, X_documents, filenames):\n",
        "    vectorizer = CountVectorizer(vocabulary=X_query.columns)\n",
        "    query_vector = vectorizer.fit_transform([query])\n",
        "\n",
        "    cosine_similarities = cosine_similarity(query_vector, X_documents).flatten()\n",
        "    similarity_scores = defaultdict(float)\n",
        "\n",
        "    for idx, score in enumerate(cosine_similarities):\n",
        "        similarity_scores[filenames[idx]] = score\n",
        "\n",
        "    return similarity_scores\n",
        "\n",
        "# Function to perform the search\n",
        "def search(query):\n",
        "    directory = 'utils'\n",
        "    X_documents, vectorizer, filenames = build_document_term_matrix(directory)\n",
        "    X_query = vectorizer.transform([query])\n",
        "\n",
        "    similarity_scores = query_document_similarity(query, X_query, X_documents, filenames)\n",
        "\n",
        "    max_score_doc = max(similarity_scores, key=similarity_scores.get)\n",
        "    max_score = similarity_scores[max_score_doc]\n",
        "\n",
        "    return max_score_doc, max_score\n",
        "\n",
        "# Test the program with given query strings\n",
        "queries = [\n",
        "    'use shrimp or sliced andouille sausage',\n",
        "    'polynomial factorization, indefinite integration',\n",
        "    'data warehouses archive data',\n",
        "    'scheduling algorithms',\n",
        "    'gates, multiplexers, latches'\n",
        "]\n",
        "\n",
        "for query in queries:\n",
        "    doc, score = search(query)\n",
        "    print(f\"Query: {query}\")\n",
        "    print(f\"Document: {doc}, Score: {score}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "3HxBJ_0PIB2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From Pattern Matching\n",
        "to Lexical Semantics regular expressions, REs"
      ],
      "metadata": {
        "id": "kXejDcpwILMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "string = 'an example word:perceptron!!!'\n",
        "pattern ='word:\\w+'\n",
        "match = re.search(pattern, string)\n",
        "if match:\n",
        "  print('found', match.group()) # 'found word:perceptron'\n",
        "else:\n",
        "  print('did not find')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn9MUEXcIMaJ",
        "outputId": "643329f3-1cb5-4580-aba6-b782c671c67e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "found word:perceptron\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "baa = \"baa!\"\n",
        "baaaa = \"baaaa!\"\n",
        "match = re.search(r\"a.*\",baaaa)\n",
        "if match:\n",
        "  print(f\"found: {match.group()}\")\n",
        "else:\n",
        "  print(\"not found\")\n",
        "match = re.search(r\"a.*?\",baaaa)\n",
        "if match:\n",
        "  print(f\"found: {match.group()}\")\n",
        "else:\n",
        "  print(\"not found\")"
      ],
      "metadata": {
        "id": "qUkrhKkDIteK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8110505c-ad47-40b8-d81c-2758f94d3239"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "found: aaaa!\n",
            "found: a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emails_list = [\"marta.verdi@unito.it\",\n",
        "\"mario.rossi@unimi.it\",\n",
        "\"gianna.gialli@unibo.it\",\n",
        "\"joe.black@polito.it\",\n",
        "\"angie.green@unical.it\",\n",
        "\"tom.blue@cs.mit.edu\",\n",
        "\"pat.cyan@ai.mit.edu\",\n",
        "\"jackie.brown@stanford.edu\",\n",
        "\"jackie.brown@unito.it\",\n",
        "\"JACKIE.BROWN@UNITO.IT\"]\n",
        "print('# select email(s) from .edu domain')\n",
        "for email in emails_list:\n",
        "  match = re.search(r'^.*\\.edu',email)\n",
        "  if match:\n",
        "    print(match.group())\n",
        "print()\n",
        "print('# select email(s) from either unito or unibo')\n",
        "for email in emails_list:\n",
        "  match = re.search(r'^.*uni[bt]o',email)\n",
        "  if match:\n",
        "    print(match.group())\n",
        "print()\n",
        "print('# select group with name.surname, but not host')\n",
        "for email in emails_list:\n",
        "  match = re.search(r'(.*)@(.*)',email)\n",
        "  if match:\n",
        "    print(match.group(1))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfYQmu7lo2SF",
        "outputId": "7ba4b615-a629-415e-8e7d-bd423dbb432b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# select email(s) from .edu domain\n",
            "tom.blue@cs.mit.edu\n",
            "pat.cyan@ai.mit.edu\n",
            "jackie.brown@stanford.edu\n",
            "\n",
            "# select email(s) from either unito or unibo\n",
            "marta.verdi@unito\n",
            "gianna.gialli@unibo\n",
            "jackie.brown@unito\n",
            "\n",
            "# select group with name.surname, but not host\n",
            "marta.verdi\n",
            "mario.rossi\n",
            "gianna.gialli\n",
            "joe.black\n",
            "angie.green\n",
            "tom.blue\n",
            "pat.cyan\n",
            "jackie.brown\n",
            "jackie.brown\n",
            "JACKIE.BROWN\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "re.findall"
      ],
      "metadata": {
        "id": "cyrJP95spzGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('# select group with host, but not name.surname')\n",
        "for email in emails_list:\n",
        "  match = re.search(r'(.*)@(.*)',email)\n",
        "  if match:\n",
        "    print(match.group(2))\n",
        "print()\n",
        "print('# find all emails from unito')\n",
        "emails_string = ', '.join(emails_list)\n",
        "unito_emails = re.findall(r'\\w+\\.\\w+@unito.it', emails_string)\n",
        "print(unito_emails)\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-bOFyUJpihF",
        "outputId": "c492cc03-72d9-44aa-8667-0246019a3075"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# select group with host, but not name.surname\n",
            "unito.it\n",
            "unimi.it\n",
            "unibo.it\n",
            "polito.it\n",
            "unical.it\n",
            "cs.mit.edu\n",
            "ai.mit.edu\n",
            "stanford.edu\n",
            "unito.it\n",
            "UNITO.IT\n",
            "\n",
            "# find all emails from unito\n",
            "['marta.verdi@unito.it', 'jackie.brown@unito.it']\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('# select email(s) from either unito or unibo, IGNORECASE')\n",
        "for email in emails_list:\n",
        "  match = re.search(r'^.*uni[bt]o',email, re.IGNORECASE)\n",
        "  if match:\n",
        "    print(match.group())\n",
        "print()\n",
        "print('# select email(s) from an italian university, IGNORECASE')\n",
        "for email in emails_list:\n",
        "  match = re.search(r'.*\\.it',email, re.IGNORECASE)\n",
        "  if match:\n",
        "    print(match.group())\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qY56Pntop5Re",
        "outputId": "386f3ac7-fed1-4530-af58-33700f089a56"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# select email(s) from either unito or unibo, IGNORECASE\n",
            "marta.verdi@unito\n",
            "gianna.gialli@unibo\n",
            "jackie.brown@unito\n",
            "JACKIE.BROWN@UNITO\n",
            "\n",
            "# select email(s) from an italian university, IGNORECASE\n",
            "marta.verdi@unito.it\n",
            "mario.rossi@unimi.it\n",
            "gianna.gialli@unibo.it\n",
            "joe.black@polito.it\n",
            "angie.green@unical.it\n",
            "jackie.brown@unito.it\n",
            "JACKIE.BROWN@UNITO.IT\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. take the file 'moby_dick_melville.txt'.\n",
        "2. count how many times the token 'whale' occurs in the book\n",
        "3. collect (through REs) blocks of four words occurring along with the\n",
        "token 'whale' according to the pattern: 'word1 word2 whale\n",
        "word3', and print the results\n",
        "4. remove stop-words from the previous set of tokens and compare\n",
        "this value count with the previous one"
      ],
      "metadata": {
        "id": "Iflio8wPrKYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZENMa73q1Tv",
        "outputId": "574e0799-b598-4fee-908e-6cc2f36a2903"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"moby_dick_melville.txt\",'r')\n",
        "book_text = f.read()\n",
        "# feed the file text into findall(); it returns a list of all the found strings\n",
        "strings = re.findall(r\"whale\",book_text)\n",
        "print(f\"the term whale occurs {len(strings)} times in the whole book\")\n",
        "# look for 4-grams\n",
        "four_grams = re.findall(r'\\w+ \\w+ whale \\w+',book_text)\n",
        "#take non unique 4-grams\n",
        "print(f\" the term whale occurs in {len(four_grams)} 4-grams (e.g., \\'chasing the whale and \\' counted as many times as it really occurs in the book)\")\n",
        "#take unique 4-grams\n",
        "print(f\"the term whale occurs in {len(set(four_grams))} unique 4-grams (e.g., \\'chasing the whale and \\' counted once only)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4lERbtTrmWn",
        "outputId": "1f8e10e2-978c-4a30-f826-ef1eb7b4b69b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the term whale occurs 1334 times in the whole book\n",
            " the term whale occurs in 252 4-grams (e.g., 'chasing the whale and ' counted as many times as it really occurs in the book)\n",
            "the term whale occurs in 235 unique 4-grams (e.g., 'chasing the whale and ' counted once only)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " filter stopwords and re-compute 4-grams"
      ],
      "metadata": {
        "id": "WLoCNW4OuXfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filter stopwords and re-compute 4-grams\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "stopwords = stopwords.words('english')\n",
        "book_tokens = nltk.word_tokenize(book_text)\n",
        "\n",
        "filtered_tokens = [el for el in book_tokens if el.casefold() not in stopwords]\n",
        "filtered_book_text = ' '.join(filtered_tokens)\n",
        "\n",
        "srch_pattern = r'\\w+ \\w+ whale \\w+'\n",
        "\n",
        "match_list = re.findall(srch_pattern, filtered_book_text)\n",
        "print(f'{match_list}')\n",
        "\n",
        "print(f'4-grams with whale and without stopwords are {len(match_list)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Rmom8qau_bQ",
        "outputId": "4f9b56ac-8c75-4d19-9e10-d9cb598f9e5f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['monstrous bulk whale ork', 'Like wounded whale shore', 'told caught whale Spitzbergen', 'a great whale stranded', 'known species whale tribe', 'dead American whale stranded', 'spose one whale eye', 'scouts us whale hunters', 'employed American whale fishery', 'Herein American whale fishery', 'systematized exhibition whale broad', 'names list whale authors', 'compared Greenland whale almost', 'the Greenland whale deposed', 'great sperm whale reigneth', 'touching sperm whale found', 'point whether whale fish', 'fashioned ground whale fish', 'internal respect whale differ', 'hitherto identified whale best', 'divisions entire whale host', 'bestowed upon whale spermaceti', 'difference Greenland whale English', 'sea commonly whale whose', 'since sperm whale also', 'terms definition whale is', 'great Sperm whale miniature', 'exception American whale captains', 'early times whale fishery', 'heads southern whale ship', 'hast raised whale yet', 'accursed white whale razed', 'chase white whale sides', 'encounter Ahab whale hitherto', 'much invested whale natural', 'things Albino whale symbol', 'voyage entire whale fleet', 'migrations sperm whale would', 'taken one whale straight', 'encounters white whale taken', 'instances particular whale ocean', 'respect chance whale may', 'prestige perilousness whale Rinaldo', 'indefinite idea whale enormous', 's interview whale providential', 'caused unseen whale vertically', 'fancied sperm whale always', 'presence sperm whale Mediterranean', 'hence sperm whale could', 'subsequently encountered whale would', 'catching turns whale line', 'plump flying whale sail', 'backing water whale face', 'instant going whale must', 's driving whale almost', 'obscurely involve whale certain', 'first sighting whale mast', 'perceiving snowy whale within', 'awful white whale destroyed', 'true form whale actually', 'absolute body whale moored', 'proving pictures whale wrong', 'made representing whale perpendicular', 'make eye whale bow', 'scientific systemized whale book', 'mistakes depicting whale surprising', 'young sucking whale full', 'mere skeleton whale bears', 'However recklessly whale may', 'finding precisely whale really', 's drawings whale good', 'idea living whale seen', 'crew scattered whale contrasting', 'real spirit whale hunt', 'English American whale draughtsmen', 'torments boiling whale going', 'could mount whale leap', 'sight particular whale pursued', 'furnish sperm whale food', 'case stricken whale sound', 'till length whale somewhat', 'gold watch whale might', 'much speed whale described', 'convulsive running whale upon', 'possible secure whale fairly', 'eyeing heaving whale moment', 'ship upon whale moored', 'intemperately fond whale flavorish', 'globular pieces whale bigness', 'blubber envelopes whale precisely', 'continually keeps whale rolling', 'skin tremendous whale thinner', 'seems scratches whale probably', 'blood Polar whale warmer', 'body beheaded whale flashes', 'upon experienced whale surgeons', 'belong small whale hoisted', 'shall remain whale till', 'while jerked whale ship', 'poor Queequeg whale ship', 'except hit whale something', 'll eat whale one', 's get whale alongside', 'observed sperm whale right', 'Moreover observe whale external', 'longer stricken whale stays', 'grown sperm whale something', 'appalling wounded whale must', 'true form whale unknown', 'story Hercules whale considered', 'story Jonah whale preceding', 'exegetists opined whale mentioned', 'Jonah swallowed whale Mediterranean', 'close enough whale get', 'precise nature whale spout', 'force whole whale seems', 'one sperm whale fights', 'another sperm whale head', 'maidenly gentleness whale certain', 'unawares upon whale fancied', 'general bulk whale elephant', 'much respect whale dog', 'wanting motions whale general', 'one lone whale outskirts', 'movement part whale struck', 'moisture thrown whale quiet', 'parts nursing whale cut', 'custom fast whale commonly', 'isolation schoolmaster whale betakes', 'laws regulations whale fishery', 'claim possession whale previously', 'hard chase whale Northern', 'remained attached whale time', 'contended examples whale lady', 'beaching fine whale originally', 'ruefully glancing whale stranger', 'right Duke whale delegated', 'Greenland Right whale largely', 'betokened sort whale must', 'Frenchman second whale alongside', 'caught blasted whale brought', 'pulling lighter whale two', 'towed away whale way', 'unloading one whale cemeteries', 'blubber Dutch whale fleet', 'part slack whale line', 'instant stricken whale started', 'preparing sperm whale try', 'adhesiveness back whale remains', 'arm sperm whale bone', 'noble great whale was', 't know whale served', 'digestive organs whale inscrutably', 'fitted discovery whale ship', 'sparing historical whale research', 'English preceded whale fishery', 'interesting account whale fishery', 'Greenland Spitzbergen whale fishery', 'sized Greenland whale sixty', 'body particular whale must', 'fully invested whale truly', 'mighty bulk whale affords', 'lexicon used whale author', 'admit animals whale alone', 'show hunted whale escape', 'may great whale outlast', 'beams sperm whale ivory', 'something stick whale like', 'jaw last whale slain', 'noon dead whale brought', 'concluded stricken whale must', 'indifference white whale tore', 'behold famous whale long', 'parted white whale victim', 'simple observation whale last', 'hours hence whale gone', 'would take whale head', 'though moment whale drew', 'Ahab knew whale sounded', 'swim feast whale Ahab']\n",
            "4-grams with whale and without stopwords are 180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "search the number of occurrences for 'whale' by employing a\n",
        "dictionary resulting from employing the Counter object"
      ],
      "metadata": {
        "id": "GvVzfoV8v45c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from collections import Counter\n",
        "\n",
        "# using Counter to build a dictionary\n",
        "ddcounter = Counter(word_tokenize(book_text))\n",
        "print(f'ddcounter[\"whale\"]: {ddcounter[\"whale\"]}')\n",
        "\n",
        "# using count() on lists\n",
        "print(f'whale occurs {word_tokenize(book_text).count(\"whale\")} times in the book')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkZbBCmcvS_H",
        "outputId": "98431bf9-9020-4b17-b119-e2383b547816"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ddcounter[\"whale\"]: 765\n",
            "whale occurs 765 times in the book\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wagner-Fischer algorithm\n",
        "39\n",
        "D[i, j] = min\n",
        "D[i − 1,j] + del-cost(source[i])\n",
        "D[i, j − 1] + ins-cost(target[j])\n",
        "D[i − 1,j − 1] + sub-cost(source[i], target[j])"
      ],
      "metadata": {
        "id": "v6_4BACCx7og"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Using raw string format\n",
        "pattern_raw = r'\\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,}\\b'\n",
        "text = \"Contact me at john.red@example.us or daniele@example.it\"\n",
        "matches_raw = re.findall(pattern_raw, text, re.IGNORECASE)\n",
        "print(\"Matches using raw string format:\", matches_raw)\n",
        "\n",
        "# Using simple string format\n",
        "# pattern_simple = '\\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,}\\b'\n",
        "pattern_simple = '\\\\b[A-Z0-9._%+-]+@[A-Z0-9.-]+\\\\.[A-Z]{2,}\\\\b'\n",
        "matches_simple = re.findall(pattern_simple, text, re.IGNORECASE)\n",
        "print(\"Matches using simple string format:\", matches_simple)"
      ],
      "metadata": {
        "id": "o6bWv2_ev9zQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " implement the minimum edit distance algorithm"
      ],
      "metadata": {
        "id": "ji4n6TPAysSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def min_edit_distance(str1, str2):\n",
        "    m = len(str1)\n",
        "    n = len(str2)\n",
        "\n",
        "    # Create a matrix to store the minimum edit distances\n",
        "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "\n",
        "    # Initialize the first row and column\n",
        "    for i in range(m + 1):\n",
        "        dp[i][0] = i\n",
        "    for j in range(n + 1):\n",
        "        dp[0][j] = j\n",
        "\n",
        "    # Fill in the matrix\n",
        "    for i in range(1, m + 1):\n",
        "        for j in range(1, n + 1):\n",
        "            if str1[i - 1] == str2[j - 1]:\n",
        "                dp[i][j] = dp[i - 1][j - 1]\n",
        "            else:\n",
        "                dp[i][j] = 1 + min(dp[i - 1][j],        # Deletion\n",
        "                                   dp[i][j - 1],        # Insertion\n",
        "                                   dp[i - 1][j - 1])   # Substitution\n",
        "\n",
        "    return dp[m][n]\n",
        "\n",
        "# Example usage:\n",
        "str1 = \"kitten\"\n",
        "str2 = \"sitting\"\n",
        "distance = min_edit_distance(str1, str2)\n",
        "print(f\"The minimum edit distance between '{str1}' and '{str2}' is {distance}.\")\n"
      ],
      "metadata": {
        "id": "OPdK-rQ6yrZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "WordNet\n",
        "• WordNet is a large lexical database of English.\n",
        "• Nouns, verbs, adjectives and adverbs are grouped into sets of\n",
        "cognitive synonyms (synsets), each expressing a distinct concept.\n",
        "• Synsets are interlinked by means of conceptual-semantic and\n",
        "lexical relations.\n",
        "• The resulting network of meaningfully related words and\n",
        "concepts can be navigated with the browser"
      ],
      "metadata": {
        "id": "FRllTRt94i7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import wordnet as wn\n",
        "term = 'board'\n",
        "print('\\nExploring senses for term \"{}\"\\n'.format(term))\n",
        "for ss in wn.synsets(term):\n",
        "  print('\\n' + str(ss))\n",
        "  print(ss.name(), ss.lemma_names())\n",
        "  offset = str(ss.offset()).zfill(8) + '-' + ss.pos()\n",
        "  print(f'offset: {offset}\\n')\n",
        "  print('def : ' + ss.definition())\n",
        "  print('ex : ' + str(ss.examples()))\n",
        "  print('\\n\\t ** Hyponyms **')\n",
        "  for hyp in ss.hyponyms():\n",
        "    print('\\thypon: ' + str(hyp))\n",
        "  print('\\n\\t ** Hypernyms **')\n",
        "  for hyp in ss.hypernyms():\n",
        "    print('\\thyper: ' + str(hyp))\n",
        "print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MAMdwb_4jQt",
        "outputId": "8ea47734-367f-4a87-b90d-305c14589397"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Exploring senses for term \"board\"\n",
            "\n",
            "\n",
            "Synset('board.n.01')\n",
            "board.n.01 ['board']\n",
            "offset: 08322981-n\n",
            "\n",
            "def : a committee having supervisory powers\n",
            "ex : ['the board has seven members']\n",
            "\n",
            "\t ** Hyponyms **\n",
            "\thypon: Synset('advisory_board.n.01')\n",
            "\thypon: Synset('appeal_board.n.01')\n",
            "\thypon: Synset('board_of_selectmen.n.01')\n",
            "\thypon: Synset('directorate.n.01')\n",
            "\thypon: Synset('draft_board.n.01')\n",
            "\thypon: Synset('federal_reserve_board.n.01')\n",
            "\thypon: Synset('governing_board.n.01')\n",
            "\thypon: Synset('school_board.n.01')\n",
            "\thypon: Synset('zoning_board.n.01')\n",
            "\n",
            "\t ** Hypernyms **\n",
            "\thyper: Synset('committee.n.01')\n",
            "\n",
            "Synset('board.n.02')\n",
            "board.n.02 ['board', 'plank']\n",
            "offset: 15101854-n\n",
            "\n",
            "def : a stout length of sawn timber; made in a wide variety of sizes and used for many purposes\n",
            "ex : []\n",
            "\n",
            "\t ** Hyponyms **\n",
            "\thypon: Synset('chipboard.n.01')\n",
            "\thypon: Synset('deal.n.04')\n",
            "\thypon: Synset('matchboard.n.01')\n",
            "\thypon: Synset('skid.n.01')\n",
            "\thypon: Synset('wale.n.02')\n",
            "\n",
            "\t ** Hypernyms **\n",
            "\thyper: Synset('lumber.n.01')\n",
            "\n",
            "Synset('board.n.03')\n",
            "board.n.03 ['board']\n",
            "offset: 02856463-n\n",
            "\n",
            "def : a flat piece of material designed for a special purpose\n",
            "ex : ['he nailed boards across the windows']\n",
            "\n",
            "\t ** Hyponyms **\n",
            "\thypon: Synset('aquaplane.n.01')\n",
            "\thypon: Synset('breadboard.n.01')\n",
            "\thypon: Synset('bulletin_board.n.02')\n",
            "\thypon: Synset('chopping_board.n.01')\n",
            "\thypon: Synset('drafting_board.n.01')\n",
            "\thypon: Synset('drainboard.n.01')\n",
            "\thypon: Synset('floorboard.n.01')\n",
            "\thypon: Synset('ironing_board.n.01')\n",
            "\thypon: Synset('kneeler.n.02')\n",
            "\thypon: Synset('mortarboard.n.01')\n",
            "\thypon: Synset('palette.n.02')\n",
            "\thypon: Synset('planchette.n.01')\n",
            "\thypon: Synset('scoreboard.n.01')\n",
            "\thypon: Synset('sideboard.n.01')\n",
            "\thypon: Synset('sideboard.n.02')\n",
            "\thypon: Synset('skateboard.n.01')\n",
            "\thypon: Synset('snowboard.n.01')\n",
            "\thypon: Synset('springboard.n.01')\n",
            "\thypon: Synset('surfboard.n.01')\n",
            "\thypon: Synset('trencher.n.02')\n",
            "\thypon: Synset('wake_board.n.01')\n",
            "\thypon: Synset('wallboard.n.01')\n",
            "\thypon: Synset('workboard.n.01')\n",
            "\n",
            "\t ** Hypernyms **\n",
            "\thyper: Synset('sheet.n.06')\n",
            "\n",
            "Synset('board.n.04')\n",
            "board.n.04 ['board', 'table']\n",
            "offset: 07565259-n\n",
            "\n",
            "def : food or meals in general\n",
            "ex : ['she sets a fine table', 'room and board']\n",
            "\n",
            "\t ** Hyponyms **\n",
            "\thypon: Synset('training_table.n.01')\n",
            "\n",
            "\t ** Hypernyms **\n",
            "\thyper: Synset('fare.n.04')\n",
            "\n",
            "Synset('display_panel.n.01')\n",
            "display_panel.n.01 ['display_panel', 'display_board', 'board']\n",
            "offset: 03211616-n\n",
            "\n",
            "def : a vertical surface on which information can be displayed to public view\n",
            "ex : []\n",
            "\n",
            "\t ** Hyponyms **\n",
            "\thypon: Synset('big_board.n.02')\n",
            "\n",
            "\t ** Hypernyms **\n",
            "\thyper: Synset('display.n.06')\n",
            "\n",
            "Synset('dining_table.n.01')\n",
            "dining_table.n.01 ['dining_table', 'board']\n",
            "offset: 03201208-n\n",
            "\n",
            "def : a table at which meals are served\n",
            "ex : ['he helped her clear the dining table', 'a feast was spread upon the board']\n",
            "\n",
            "\t ** Hyponyms **\n",
            "\thypon: Synset('dining-room_table.n.01')\n",
            "\thypon: Synset('dinner_table.n.01')\n",
            "\thypon: Synset('high_table.n.01')\n",
            "\thypon: Synset('refectory_table.n.01')\n",
            "\thypon: Synset('triclinium.n.02')\n",
            "\n",
            "\t ** Hypernyms **\n",
            "\thyper: Synset('table.n.03')\n",
            "\n",
            "Synset('control_panel.n.01')\n",
            "control_panel.n.01 ['control_panel', 'instrument_panel', 'control_board', 'board', 'panel']\n",
            "offset: 03098140-n\n",
            "\n",
            "def : electrical device consisting of a flat insulated surface that contains switches and dials and meters for controlling other electrical devices\n",
            "ex : ['he checked the instrument panel', 'suddenly the board lit up like a Christmas tree']\n",
            "\n",
            "\t ** Hyponyms **\n",
            "\thypon: Synset('dashboard.n.02')\n",
            "\n",
            "\t ** Hypernyms **\n",
            "\thyper: Synset('electrical_device.n.01')\n",
            "\n",
            "Synset('circuit_board.n.01')\n",
            "circuit_board.n.01 ['circuit_board', 'circuit_card', 'board', 'card', 'plug-in', 'add-in']\n",
            "offset: 03033986-n\n",
            "\n",
            "def : a printed circuit that can be inserted into expansion slots in a computer to increase the computer's capabilities\n",
            "ex : []\n",
            "\n",
            "\t ** Hyponyms **\n",
            "\thypon: Synset('cpu_board.n.01')\n",
            "\thypon: Synset('pc_board.n.01')\n",
            "\n",
            "\t ** Hypernyms **\n",
            "\thyper: Synset('printed_circuit.n.01')\n",
            "\n",
            "Synset('board.n.09')\n",
            "board.n.09 ['board', 'gameboard']\n",
            "offset: 02857023-n\n",
            "\n",
            "def : a flat portable surface (usually rectangular) designed for board games\n",
            "ex : ['he got out the board and set up the pieces']\n",
            "\n",
            "\t ** Hyponyms **\n",
            "\thypon: Synset('backgammon_board.n.01')\n",
            "\thypon: Synset('checkerboard.n.01')\n",
            "\thypon: Synset('cribbage_board.n.01')\n",
            "\thypon: Synset('dartboard.n.01')\n",
            "\thypon: Synset('go_board.n.01')\n",
            "\thypon: Synset('monopoly_board.n.01')\n",
            "\thypon: Synset('ouija.n.01')\n",
            "\thypon: Synset('pegboard.n.01')\n",
            "\thypon: Synset('punchboard.n.01')\n",
            "\n",
            "\t ** Hypernyms **\n",
            "\thyper: Synset('surface.n.01')\n",
            "\n",
            "Synset('board.v.01')\n",
            "board.v.01 ['board', 'get_on']\n",
            "offset: 02018049-v\n",
            "\n",
            "def : get on board of (trains, buses, ships, aircraft, etc.)\n",
            "ex : []\n",
            "\n",
            "\t ** Hyponyms **\n",
            "\thypon: Synset('catch.v.09')\n",
            "\thypon: Synset('embark.v.01')\n",
            "\thypon: Synset('entrain.v.01')\n",
            "\n",
            "\t ** Hypernyms **\n",
            "\thyper: Synset('enter.v.01')\n",
            "\n",
            "Synset('board.v.02')\n",
            "board.v.02 ['board', 'room']\n",
            "offset: 02656763-v\n",
            "\n",
            "def : live and take one's meals at or in\n",
            "ex : ['she rooms in an old boarding house']\n",
            "\n",
            "\t ** Hyponyms **\n",
            "\n",
            "\t ** Hypernyms **\n",
            "\thyper: Synset('populate.v.01')\n",
            "\n",
            "Synset('board.v.03')\n",
            "board.v.03 ['board']\n",
            "offset: 01177118-v\n",
            "\n",
            "def : lodge and take meals (at)\n",
            "ex : []\n",
            "\n",
            "\t ** Hyponyms **\n",
            "\n",
            "\t ** Hypernyms **\n",
            "\thyper: Synset('use.v.02')\n",
            "\n",
            "Synset('board.v.04')\n",
            "board.v.04 ['board']\n",
            "offset: 01176897-v\n",
            "\n",
            "def : provide food and lodging (for)\n",
            "ex : ['The old lady is boarding three men']\n",
            "\n",
            "\t ** Hyponyms **\n",
            "\thypon: Synset('live_in.v.01')\n",
            "\n",
            "\t ** Hypernyms **\n",
            "\thyper: Synset('provide.v.02')\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "the Lesk Algorithm\n",
        "74\n",
        "P(fj|s) = count(fj, s)\n",
        "count(s)\n",
        "sˆ = arg max\n",
        "s2S\n",
        "0@\n",
        "log P(s)\n",
        "nX j\n",
        "=1\n",
        "log P(fj|s)\n",
        "1A\n",
        "function SimplifiedLesk(word,sentence)\n",
        "returns best sense of word\n",
        "best-sense ⇥ most frequent sense for word\n",
        "max-overlap ⇥ 0\n",
        "context ⇥ set of words in sentence\n",
        "for all senses of word do\n",
        "signature ⇥ set of words in the gloss and examples of sense\n",
        "overlap ⇥ ComputeOverlap(signature,context)\n",
        "if overlap > max-overlap then\n",
        "max-overlap ⇥ overlap\n",
        "best-sense ⇥ sense\n",
        "end if\n",
        "end for\n",
        "return best-sense\n",
        "1\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "6\n",
        "7\n",
        "8\n",
        "9\n",
        "10\n",
        "11\n",
        "12\n",
        "13\n",
        "14"
      ],
      "metadata": {
        "id": "HGwGb7WR7IY6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "implement the Lesk algorithm (!= using existing\n",
        "implementations such as, e.g., that in nltk…)."
      ],
      "metadata": {
        "id": "du89GTXF79GT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def compute_overlap(signature, context):\n",
        "    \"\"\"\n",
        "    Computes the overlap between two sets of words.\n",
        "    \"\"\"\n",
        "    return len(signature.intersection(context))\n",
        "\n",
        "def simplified_lesk(word, sentence):\n",
        "    \"\"\"\n",
        "    Returns the best sense of a word using the Simplified Lesk algorithm.\n",
        "    \"\"\"\n",
        "    best_sense = None\n",
        "    max_overlap = 0\n",
        "\n",
        "    # Tokenize the input sentence\n",
        "    context = set(word_tokenize(sentence))\n",
        "\n",
        "    # Iterate over all senses of the word\n",
        "    for sense in wn.synsets(word):\n",
        "        # Construct the signature using gloss and examples\n",
        "        signature = set(word_tokenize(sense.definition()))\n",
        "        for example in sense.examples():\n",
        "            signature.update(word_tokenize(example))\n",
        "\n",
        "        # Compute the overlap\n",
        "        overlap = compute_overlap(signature, context)\n",
        "\n",
        "        # Update the best sense if overlap is higher\n",
        "        if overlap > max_overlap:\n",
        "            max_overlap = overlap\n",
        "            best_sense = sense\n",
        "\n",
        "    return best_sense\n",
        "\n",
        "# Example usage:\n",
        "word = 'board'\n",
        "sentence = 'The board meeting was postponed.'\n",
        "best_sense = simplified_lesk(word, sentence)\n",
        "print(f\"The best sense of '{word}' in the context of the sentence is:\")\n",
        "print(best_sense)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlK9ReZu4lVb",
        "outputId": "06499394-9b00-43eb-c4ff-0effe99636f6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best sense of 'board' in the context of the sentence is:\n",
            "Synset('dining_table.n.01')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test the implemented function on the sentences\n",
        "- \"The house was burnt to ashes while the owner returned\"\n",
        "- \"This table is made of ash wood\"\n",
        "where the term ash should be disambiguated\n",
        "- find further polysemic terms and context sentences, and test\n",
        "the Lesk algorithm on these"
      ],
      "metadata": {
        "id": "IKV2lnkm8Vn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "def compute_overlap(signature, context):\n",
        "    \"\"\"\n",
        "    Computes the overlap between two sets of words.\n",
        "    \"\"\"\n",
        "    return len(signature.intersection(context))\n",
        "\n",
        "def simplified_lesk(word, sentence):\n",
        "    \"\"\"\n",
        "    Returns the best sense of a word using the Simplified Lesk algorithm.\n",
        "    \"\"\"\n",
        "    best_sense = None\n",
        "    max_overlap = 0\n",
        "\n",
        "    # Tokenize the input sentence\n",
        "    context = set(sentence.split())\n",
        "\n",
        "    # Iterate over all senses of the word\n",
        "    for sense in wn.synsets(word):\n",
        "        # Construct the signature using gloss and examples\n",
        "        signature = set(sense.definition().split())\n",
        "        signature.update([example for example in sense.examples() for example in example.split()])\n",
        "\n",
        "        # Compute the overlap\n",
        "        overlap = compute_overlap(signature, context)\n",
        "\n",
        "        # Update the best sense if overlap is higher\n",
        "        if overlap > max_overlap:\n",
        "            max_overlap = overlap\n",
        "            best_sense = sense\n",
        "\n",
        "    return best_sense\n",
        "\n",
        "# Test sentences\n",
        "sentences = [\n",
        "    \"The house was burnt to ashes while the owner returned.\",\n",
        "    \"This table is made of ash wood.\"\n",
        "]\n",
        "\n",
        "# Test the algorithm on each sentence\n",
        "for sentence in sentences:\n",
        "    term = 'ash'\n",
        "    best_sense = simplified_lesk(term, sentence)\n",
        "    print(f\"For the sentence: '{sentence}',\")\n",
        "    print(f\"The best sense of '{term}' is:\")\n",
        "    print(best_sense)\n",
        "    print()\n",
        "\n",
        "# Additional test cases\n",
        "additional_sentences = [\n",
        "    \"The fly is buzzing around the table in the room.\",\n",
        "    \"She felt a sharp pain in her arm as she lifted the heavy box.\",\n",
        "    \"He caught a fish in the river while waiting for the sunset.\"\n",
        "]\n",
        "\n",
        "# Test the algorithm on additional sentences\n",
        "for sentence in additional_sentences:\n",
        "    for term in sentence.split():\n",
        "        best_sense = simplified_lesk(term, sentence)\n",
        "        if best_sense:\n",
        "            print(f\"For the sentence: '{sentence}',\")\n",
        "            print(f\"The best sense of '{term}' is:\")\n",
        "            print(best_sense)\n",
        "            print()\n"
      ],
      "metadata": {
        "id": "B8Jgyjuw7_g7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code will test the Simplified Lesk algorithm on the provided sentences with the word \"ash\" to be disambiguated. It will print out the best sense of the word in the context of each sentence.\n",
        "\n",
        "If you have further polysemic terms and context sentences, you can add them to the sentences list and then use the same disambiguate_word function to test the algorithm on those sentences as well."
      ],
      "metadata": {
        "id": "v-CMdonK8cZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to disambiguate a word in a sentence\n",
        "def disambiguate_word(word, sentence):\n",
        "    best_sense = simplified_lesk(word, sentence)\n",
        "    print(f\"The best sense of '{word}' in the context of the sentence is:\")\n",
        "    print(best_sense)\n",
        "    print()\n",
        "\n",
        "# Test sentences\n",
        "sentences = [\n",
        "    \"The house was burnt to ashes while the owner returned.\",\n",
        "    \"This table is made of ash wood.\"\n",
        "]\n",
        "\n",
        "# Word to disambiguate\n",
        "word_to_disambiguate = \"ash\"\n",
        "\n",
        "# Test the algorithm on each sentence\n",
        "for sentence in sentences:\n",
        "    disambiguate_word(word_to_disambiguate, sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqaaggUO8ZPa",
        "outputId": "04d8139c-7934-44b7-831b-c2013005162a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best sense of 'ash' in the context of the sentence is:\n",
            "Synset('ash.n.01')\n",
            "\n",
            "The best sense of 'ash' in the context of the sentence is:\n",
            "Synset('ash.n.03')\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "modify the solution to exercise 7: the function must return the\n",
        "matrix;"
      ],
      "metadata": {
        "id": "MugduO0b_pyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def min_edit_distance_with_matrix(str1, str2):\n",
        "    m = len(str1)\n",
        "    n = len(str2)\n",
        "\n",
        "    # Create a matrix to store the minimum edit distances\n",
        "    dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "\n",
        "    # Initialize the first row and column\n",
        "    for i in range(m + 1):\n",
        "        dp[i][0] = i\n",
        "    for j in range(n + 1):\n",
        "        dp[0][j] = j\n",
        "\n",
        "    # Fill in the matrix\n",
        "    for i in range(1, m + 1):\n",
        "        for j in range(1, n + 1):\n",
        "            if str1[i - 1] == str2[j - 1]:\n",
        "                dp[i][j] = dp[i - 1][j - 1]\n",
        "            else:\n",
        "                dp[i][j] = 1 + min(dp[i - 1][j],        # Deletion\n",
        "                                   dp[i][j - 1],        # Insertion\n",
        "                                   dp[i - 1][j - 1])   # Substitution\n",
        "\n",
        "    return dp, dp[m][n]\n",
        "\n",
        "# Example usage:\n",
        "str1 = \"kitten\"\n",
        "str2 = \"sitting\"\n",
        "matrix, distance = min_edit_distance_with_matrix(str1, str2)\n",
        "print(f\"The minimum edit distance between '{str1}' and '{str2}' is {distance}.\")\n",
        "print(\"The dynamic programming matrix is:\")\n",
        "for row in matrix:\n",
        "    print(row)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9z1IdL28qM1",
        "outputId": "1decd2a0-582a-45a3-a77e-a85353bf81ad"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The minimum edit distance between 'kitten' and 'sitting' is 3.\n",
            "The dynamic programming matrix is:\n",
            "[0, 1, 2, 3, 4, 5, 6, 7]\n",
            "[1, 1, 2, 3, 4, 5, 6, 7]\n",
            "[2, 2, 1, 2, 3, 4, 5, 6]\n",
            "[3, 3, 2, 1, 2, 3, 4, 5]\n",
            "[4, 4, 3, 2, 1, 2, 3, 4]\n",
            "[5, 5, 4, 3, 2, 2, 3, 4]\n",
            "[6, 6, 5, 4, 3, 3, 2, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "write another function that takes in input the final matrix and returns\n",
        "the final score\n",
        "such functions must be tested (invoked) on two strings:\n",
        "\"#Cooks cook cupcakes quickly\" and \"#Cook cooks cupcakes sadly\""
      ],
      "metadata": {
        "id": "qR5wLRMP_8jZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def final_score(matrix):\n",
        "    \"\"\"\n",
        "    Returns the final score (minimum edit distance) from the given matrix.\n",
        "    \"\"\"\n",
        "    return matrix[-1][-1]\n",
        "\n",
        "# Example usage:\n",
        "def test_min_edit_distance(str1, str2):\n",
        "    matrix, distance = min_edit_distance_with_matrix(str1, str2)\n",
        "    print(f\"The minimum edit distance between '{str1}' and '{str2}' is {distance}.\")\n",
        "    print(\"The dynamic programming matrix is:\")\n",
        "    for row in matrix:\n",
        "        print(row)\n",
        "    print(\"The final score is:\", final_score(matrix))\n",
        "    print()\n",
        "\n",
        "# Test cases\n",
        "test_min_edit_distance(\"#Cooks cook cupcakes quickly\", \"#Cook cooks cupcakes sadly\")\n",
        "test_min_edit_distance(\"kitten\", \"sitting\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2gaRZtP_x1u",
        "outputId": "ec3480d1-0f24-4392-c80f-125d33c7b68e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The minimum edit distance between '#Cooks cook cupcakes quickly' and '#Cook cooks cupcakes sadly' is 7.\n",
            "The dynamic programming matrix is:\n",
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n",
            "[1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]\n",
            "[2, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n",
            "[3, 2, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
            "[4, 3, 2, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]\n",
            "[5, 4, 3, 2, 1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21]\n",
            "[6, 5, 4, 3, 2, 1, 1, 2, 3, 4, 5, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
            "[7, 6, 5, 4, 3, 2, 1, 2, 3, 4, 5, 6, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
            "[8, 7, 6, 5, 4, 3, 2, 1, 2, 3, 4, 5, 6, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
            "[9, 8, 7, 6, 5, 4, 3, 2, 1, 2, 3, 4, 5, 6, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
            "[10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
            "[11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
            "[12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 2, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
            "[13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 3, 3, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
            "[14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 4, 4, 3, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
            "[15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 5, 5, 4, 3, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
            "[16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 6, 6, 5, 4, 3, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
            "[17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 7, 7, 6, 5, 4, 3, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
            "[18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 8, 8, 8, 7, 6, 5, 4, 3, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
            "[19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 9, 9, 8, 7, 6, 5, 4, 3, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "[20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 10, 9, 8, 7, 6, 5, 4, 3, 2, 3, 4, 5, 6, 7, 8]\n",
            "[21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 9, 10, 9, 8, 7, 6, 5, 4, 3, 2, 3, 4, 5, 6, 7]\n",
            "[22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 10, 10, 10, 9, 8, 7, 6, 5, 4, 3, 3, 4, 5, 6, 7]\n",
            "[23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 11, 11, 10, 10, 9, 8, 7, 6, 5, 4, 4, 4, 5, 6, 7]\n",
            "[24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 12, 11, 11, 10, 9, 8, 7, 6, 5, 5, 5, 5, 6, 7]\n",
            "[25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 12, 12, 12, 11, 10, 9, 8, 7, 6, 6, 6, 6, 6, 7]\n",
            "[26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 13, 13, 13, 12, 11, 10, 9, 8, 7, 7, 7, 7, 7, 7]\n",
            "[27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 14, 14, 14, 13, 12, 11, 10, 9, 8, 8, 8, 8, 7, 8]\n",
            "[28, 27, 26, 25, 24, 23, 22, 21, 20, 19, 18, 17, 16, 15, 15, 15, 14, 13, 12, 11, 10, 9, 9, 9, 9, 8, 7]\n",
            "The final score is: 7\n",
            "\n",
            "The minimum edit distance between 'kitten' and 'sitting' is 3.\n",
            "The dynamic programming matrix is:\n",
            "[0, 1, 2, 3, 4, 5, 6, 7]\n",
            "[1, 1, 2, 3, 4, 5, 6, 7]\n",
            "[2, 2, 1, 2, 3, 4, 5, 6]\n",
            "[3, 3, 2, 1, 2, 3, 4, 5]\n",
            "[4, 4, 3, 2, 1, 2, 3, 4]\n",
            "[5, 5, 4, 3, 2, 2, 3, 4]\n",
            "[6, 6, 5, 4, 3, 3, 2, 3]\n",
            "The final score is: 3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Language Models: N-grams"
      ],
      "metadata": {
        "id": "oIyJIQCBBOdy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Laplace smoothing, also known as add-one smoothing, is a technique used to smooth probabilities in statistical models, particularly in cases where some events have zero probability. In the context of unigram language modeling, Laplace smoothing involves adding a small value to the count of each word in the vocabulary to ensure that no word has zero probability."
      ],
      "metadata": {
        "id": "l1zll03aUAhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def laplace_smoothing_unigram(text):\n",
        "    # Tokenize the text into words\n",
        "    words = text.split()\n",
        "\n",
        "    # Count the occurrences of each word\n",
        "    word_counts = {}\n",
        "    for word in words:\n",
        "        word_counts[word] = word_counts.get(word, 0) + 1\n",
        "\n",
        "    # Calculate the total number of words\n",
        "    total_words = len(words)\n",
        "\n",
        "    # Get the vocabulary size\n",
        "    vocabulary_size = len(set(words))\n",
        "\n",
        "    # Calculate the smoothed probabilities\n",
        "    smoothed_probabilities = {}\n",
        "    alpha = 1  # Smoothing parameter (add-one smoothing)\n",
        "    for word, count in word_counts.items():\n",
        "        smoothed_probabilities[word] = (count + alpha) / (total_words + alpha * vocabulary_size)\n",
        "\n",
        "    return smoothed_probabilities\n",
        "\n",
        "# Example usage:\n",
        "text = \"the quick brown fox jumps over the lazy dog\"\n",
        "smoothed_probabilities = laplace_smoothing_unigram(text)\n",
        "print(\"Smoothed probabilities for unigrams:\")\n",
        "for word, probability in smoothed_probabilities.items():\n",
        "    print(f\"{word}: {probability}\")\n"
      ],
      "metadata": {
        "id": "JVTDvBuu_yI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "maximum likelihood estimation"
      ],
      "metadata": {
        "id": "4Is238g0Uh9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def maximum_likelihood_estimation(text):\n",
        "    # Tokenize the text into words\n",
        "    words = text.split()\n",
        "\n",
        "    # Count the occurrences of each word\n",
        "    word_counts = {}\n",
        "    for word in words:\n",
        "        word_counts[word] = word_counts.get(word, 0) + 1\n",
        "\n",
        "    # Calculate the total number of words\n",
        "    total_words = len(words)\n",
        "\n",
        "    # Calculate the probabilities using maximum likelihood estimation\n",
        "    word_probabilities = {}\n",
        "    for word, count in word_counts.items():\n",
        "        word_probabilities[word] = count / total_words\n",
        "\n",
        "    return word_probabilities\n",
        "\n",
        "# Example usage:\n",
        "text = \"the quick brown fox jumps over the lazy dog\"\n",
        "word_probabilities = maximum_likelihood_estimation(text)\n",
        "print(\"Word probabilities based on Maximum Likelihood Estimation:\")\n",
        "for word, probability in word_probabilities.items():\n",
        "    print(f\"{word}: {probability}\")\n"
      ],
      "metadata": {
        "id": "vvDJwuSkUgRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "distributional models"
      ],
      "metadata": {
        "id": "dRfZX2iRUoMb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GloVe: Global Vectors for Word Representation loading embeddings and assigning them to the glove\n",
        "variable is done in few lines of code"
      ],
      "metadata": {
        "id": "RCOTiyUqdwxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "fname = \"path/glove.6B.300d.txt\"\n",
        "glove = KeyedVectors.load_word2vec_format(fname, no_header=True)\n",
        "glove.vectors.shape #output (400000, 300)"
      ],
      "metadata": {
        "id": "P3gQrLPWUntz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GloVe: Global Vectors for Word Representation\n",
        "• the class KeyedVectors provides a method called most_similar\n",
        "that receives a word and computes its cosine similarity to all other\n",
        "embeddings, and returns the topn most-similar words. By default,\n",
        "topn is set to 10"
      ],
      "metadata": {
        "id": "kwXnDUUYd67r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove.most_similar(\"cactus\")\n",
        "# out put [('cacti', 0.6634564399719238), ('saguaro', 0.6195855140686035), ('pear', 0.5233486890792847), ('cactuses', 0.5178282260894775), ... ('peyote', 0.45344963669776917), ('succulents', 0.45127877593040466)]"
      ],
      "metadata": {
        "id": "8dfIXsJzd8sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "analogy\n",
        "• one can subtract the meaning of man and add the meaning of\n",
        "woman to obtain the definition of female royalty:\n",
        "- queen ≈ king − man + woman."
      ],
      "metadata": {
        "id": "r8kpxdmTecPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# king - man + woman\n",
        "glove.most_similar(positive=[\"king\", \"woman\"], negative=[\"man\"])  #[('queen', 0.6713277101516724), ('princess', 0.5432624220848083), ('throne', 0.5386105179786682), ... ('prince', 0.4668240249156952), ('wife', 0.46473270654678345)]"
      ],
      "metadata": {
        "id": "LrzJ--4zecrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "implementation details\n",
        "• embedding vectors are stored in the attribute vector\n",
        "from the object KeyedVectors\n",
        "- vector is thus a 2-dimensional NumPy array, where each row\n",
        "corresponds to a word in the vocabulary\n",
        "- but normalized embeddings can be obtained using the\n",
        "get_normed_vectors method."
      ],
      "metadata": {
        "id": "xmXSYV8Besu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normed_vectors = glove.get_normed_vectors()\n",
        "normed_vectors.shape"
      ],
      "metadata": {
        "id": "f-ftAm04euZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "implementation details\n",
        "• the mapping between words and the matrix rows. The KeyedVectors\n",
        "object stores this mapping in a list of terms called index_to_key,\n",
        "and a term-to-index dictionary called key_to_index."
      ],
      "metadata": {
        "id": "eggDmQY2e5SW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_list = glove.index_to_key\n",
        "print(word_list[:10])\n",
        "#glove.key_to_index\n",
        "dict_words_2_indices = glove.key_to_index\n",
        "print(list(dict_words_2_indices.items())[:10])"
      ],
      "metadata": {
        "id": "k6IbNLCTe7CY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "re-implementing word similarity\n",
        "• we want to develop a function most_similar_words that\n",
        "takes in input a word, the embeddings matrix, the vocabulary\n",
        "in the form of index_to_key list and key_to_index\n",
        "dictionary, and topn, the number of similar words to return\n",
        "(defaults to 10)"
      ],
      "metadata": {
        "id": "MCklqxbpfB0H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def most_similar_words(word, vectors, index_to_key, key_to_index, topn=10):\n",
        "# retrieve word_id corresponding to given word\n",
        "  word_id = key_to_index[word]\n",
        "# retrieve embedding for given word from the vectors matrix\n",
        "  embedding = vectors[word_id]\n",
        "# calculate similarities to all words in the input vocabulary (vectors)\n",
        "  similarities = vectors @ embedding\n",
        "# get word_ids in ascending order with respect to similarity score\n",
        "  ids_ascending = similarities.argsort()\n",
        "# reverse word_ids\n",
        "  ids_descending = ids_ascending[::-1]\n",
        "# get boolean array with element corresponding to word_id set to false\n",
        "  mask = ids_descending != word_id\n",
        "# obtain new array of indices that does not contain word_id\n",
        "# (otherwise the most similar word to the argument would be the argument itself)\n",
        "  ids_descending = ids_descending[mask]\n",
        "# get topn word_ids\n",
        "  top_ids = ids_descending[:topn]\n",
        "# retrieve topn words with their corresponding similarity score\n",
        "  top_words = [(index_to_key[i], similarities[i]) for i in top_ids]\n",
        "# return results\n",
        "  return top_words"
      ],
      "metadata": {
        "id": "7m5CKOR1fCPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "e-implementing word similarity\n",
        "• we then test with the same example that we used\n",
        "above: the most similar words to \"cactus"
      ],
      "metadata": {
        "id": "SJuRD9REfYd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectors = glove.get_normed_vectors()\n",
        "index_to_key = glove.index_to_key\n",
        "key_to_index = glove.key_to_index\n",
        "most_similar_words(\"cactus\", vectors, index_to_key, key_to_index)"
      ],
      "metadata": {
        "id": "DRb2ssMDfY9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "re-implementing word analogy\n",
        "• in this setting we take in input two lists of words that\n",
        "need be combined into a single embedding.\n",
        "- positive words are combined into a single vector\n",
        "- same is done for negative words\n",
        "- the negative vector is then subtracted from the positive one,\n",
        "and the result normalized\n",
        "• full code in the notebook for this lesson (results should\n",
        "be compared to those obtained by invoking gensim...)"
      ],
      "metadata": {
        "id": "-NYtHbSyfdMK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analogy(positive, negative, vectors, index_to_key, key_to_index, topn=10):\n",
        "# find ids for positive and negative words\n",
        "  pos_ids = [key_to_index[w] for w in positive]\n",
        "  neg_ids = [key_to_index[w] for w in negative]\n",
        "  given_word_ids = pos_ids + neg_ids\n",
        "# get embeddings for positive and negative words\n",
        "  pos_emb = vectors[pos_ids].sum(axis=0)\n",
        "  neg_emb = vectors[neg_ids].sum(axis=0)\n",
        "# get embedding for analogy\n",
        "  emb = pos_emb - neg_emb\n",
        "# normalize embedding\n",
        "  emb = emb / norm(emb)\n",
        "# calculate similarities to all words in out vocabulary\n",
        "  similarities = vectors @ emb\n",
        "# get word_ids in ascending order with respect to similarity score\n",
        "  ids_ascending = similarities.argsort()\n",
        "# reverse word_ids\n",
        "  ids_descending = ids_ascending[::-1]\n",
        "# get boolean array with element corresponding to any of given_word_ids set to false\n",
        "  given_words_mask = np.isin(ids_descending, given_word_ids, invert=True)\n",
        "# obtain new array of indices that doesn't contain any of the given_word_ids\n",
        "  ids_descending = ids_descending[given_words_mask]\n",
        "# get topn word_ids\n",
        "  top_ids = ids_descending[:topn]\n",
        "# retrieve topn words with their corresponding similarity score\n",
        "  top_words = [(index_to_key[i], similarities[i]) for i in top_ids]\n",
        "# return results\n",
        "  return top_words"
      ],
      "metadata": {
        "id": "Rd5iCRQdfdlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "re-implementing word analogy\n",
        "• same query: king−man+woman"
      ],
      "metadata": {
        "id": "k9y-awWYfs7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "positive = [\"king\", \"woman\"]\n",
        "negative = [\"man\"]\n",
        "vectors = glove.get_normed_vectors()\n",
        "index_to_key = glove.index_to_key\n",
        "key_to_index = glove.key_to_index\n",
        "analogy(positive, negative, vectors, index_to_key, key_to_index)\n"
      ],
      "metadata": {
        "id": "aaa05ux8ftio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "retrain the algorithm to also account for car reviews"
      ],
      "metadata": {
        "id": "ZeIZhYxhgTIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load hotel reviews data\n",
        "hotel_reviews_path = '/content/drive/My Drive/hotel_reviews.txt'\n",
        "with open(hotel_reviews_path, 'r') as file:\n",
        "    hotel_reviews = file.read().splitlines()\n",
        "\n",
        "# Preprocess the data\n",
        "# (Tokenization, lowercase conversion, removing stopwords, etc.)\n",
        "\n",
        "# Train Word2Vec model\n",
        "word2vec_model = Word2Vec(sentences=hotel_reviews, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Test semantic similarity\n",
        "similarity = word2vec_model.wv.similarity('good', 'excellent')\n",
        "print(f\"Semantic similarity between 'good' and 'excellent': {similarity}\")\n",
        "\n",
        "# Load car reviews data\n",
        "car_reviews_path = '/content/drive/My Drive/car_reviews.txt'\n",
        "with open(car_reviews_path, 'r') as file:\n",
        "    car_reviews = file.read().splitlines()\n",
        "\n",
        "# Preprocess car reviews data\n",
        "# (Tokenization, lowercase conversion, removing stopwords, etc.)\n",
        "\n",
        "# Retrain Word2Vec model with combined data\n",
        "word2vec_model.build_vocab(car_reviews, update=True)\n",
        "word2vec_model.train(car_reviews, total_examples=word2vec_model.corpus_count, epochs=5)\n"
      ],
      "metadata": {
        "id": "X1yQXjvBgTlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compute the similarity between words \"nice\", \"clean\", and \"room\" using Word2Vec models trained on only hotel reviews and both hotel and car reviews, we can follow these steps:\n",
        "\n",
        "Load the Word2Vec models trained on hotel reviews only and on combined hotel and car reviews.\n",
        "Compute the similarity between the words \"nice\", \"clean\", and \"room\" using each model.\n",
        "Compare the similarity results.\n",
        "Here's how to do it: compute the similarity between nice, clean and room, car and compare\n",
        "the results between vectors acquired by only employing hotel reviews and\n",
        "both hotel and car reviews"
      ],
      "metadata": {
        "id": "p8FjRJoqg4cy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load necessary libraries\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Define paths to Word2Vec models\n",
        "hotel_reviews_model_path = '/content/drive/My Drive/hotel_reviews_word2vec.model'\n",
        "combined_reviews_model_path = '/content/drive/My Drive/combined_reviews_word2vec.model'\n",
        "\n",
        "# Load Word2Vec models\n",
        "hotel_reviews_model = Word2Vec.load(hotel_reviews_model_path)\n",
        "combined_reviews_model = Word2Vec.load(combined_reviews_model_path)\n",
        "\n",
        "# Compute similarity for hotel reviews model\n",
        "similarity_hotel = hotel_reviews_model.wv.similarity('nice', 'clean')\n",
        "print(\"Similarity between 'nice' and 'clean' in hotel reviews model:\", similarity_hotel)\n",
        "\n",
        "similarity_room = hotel_reviews_model.wv.similarity('clean', 'room')\n",
        "print(\"Similarity between 'clean' and 'room' in hotel reviews model:\", similarity_room)\n",
        "\n",
        "# Compute similarity for combined reviews model\n",
        "similarity_car_hotel = combined_reviews_model.wv.similarity('nice', 'clean')\n",
        "print(\"Similarity between 'nice' and 'clean' in combined reviews model:\", similarity_car_hotel)\n",
        "\n",
        "similarity_car_room = combined_reviews_model.wv.similarity('clean', 'room')\n",
        "print(\"Similarity between 'clean' and 'room' in combined reviews model:\", similarity_car_room)\n"
      ],
      "metadata": {
        "id": "nyvsS66Mg44h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "download the 'glove-twitter-200' corpus through the gensim API, train a\n",
        "Word2Vec model on this, and compute the similarity score for the term pairs\n",
        "nice, clean and room, car This code will download the 'glove-twitter-200' corpus using the gensim API, train a Word2Vec model on it, and compute the similarity scores for the term pairs \"nice, clean\" and \"room, car\".\n",
        "\n",
        "Make sure you have an active internet connection to download the 'glove-twitter-200' corpus. The similarity scores will reflect the semantic similarity between the word vectors learned from the 'glove-twitter-200' corpus."
      ],
      "metadata": {
        "id": "XqLYMA-ZhN4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader\n",
        "\n",
        "# Download the 'glove-twitter-200' corpus\n",
        "glove_twitter_200 = gensim.downloader.load('glove-twitter-200')\n",
        "\n",
        "# Train a Word2Vec model using the 'glove-twitter-200' corpus\n",
        "word2vec_model = gensim.models.Word2Vec(glove_twitter_200)\n",
        "\n",
        "# Compute similarity for term pairs\n",
        "similarity_nice_clean = word2vec_model.wv.similarity('nice', 'clean')\n",
        "print(\"Similarity between 'nice' and 'clean':\", similarity_nice_clean)\n",
        "\n",
        "similarity_room_car = word2vec_model.wv.similarity('room', 'car')\n",
        "print(\"Similarity between 'room' and 'car':\", similarity_room_car)\n"
      ],
      "metadata": {
        "id": "Eof54YPAhKXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recommender Systems using Word Embeddings Importing the dataset"
      ],
      "metadata": {
        "id": "nfiB82b_hbc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df = pd.read_excel('./drive/MyDrive/w2v_lab/IMDB_Dataset.xlsx', sheet_name = 'Sheet1').drop(['Unnamed: 0'], axis = 1)\n",
        "df"
      ],
      "metadata": {
        "id": "QtxLAWy0hb1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Preprocessing\n",
        "Cleaning the 'Description' and storing the cleaned description in a new variable called 'Cleaned'.\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "2UuyQKedhkZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for removing ASCII characters\n",
        "def _removeNonAscii(s):\n",
        "    return \"\".join(i for i in s if  ord(i)<128)\n",
        "\n",
        "# Function for converting to lower case\n",
        "def make_lower_case(text):\n",
        "    return text.lower()\n",
        "\n",
        "# Function for removing stop words\n",
        "def remove_stop_words(text):\n",
        "    text = text.split()\n",
        "    stops = set(stopwords.words(\"english\"))\n",
        "    text = [w for w in text if not w in stops]\n",
        "    text = \" \".join(text)\n",
        "    return text\n",
        "\n",
        "# Function for removing html\n",
        "def remove_html(text):\n",
        "    html_pattern = re.compile('<.*?>')\n",
        "    return html_pattern.sub(r'', text)\n",
        "\n",
        "# Function for removing punctuation\n",
        "def remove_punctuation(text):\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    text = tokenizer.tokenize(text)\n",
        "    text = \" \".join(text)\n",
        "    return text\n",
        "\n",
        "df['Cleaned'] = df['Description'].apply(_removeNonAscii)\n",
        "df['Cleaned'] = df.Cleaned.apply(func = make_lower_case)\n",
        "df['Cleaned'] = df.Cleaned.apply(func = remove_stop_words)\n",
        "df['Cleaned'] = df.Cleaned.apply(func = remove_punctuation)\n",
        "df['Cleaned'] = df.Cleaned.apply(func = remove_html)"
      ],
      "metadata": {
        "id": "Bevqjy9ohmmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recommendation Engine\n",
        "We will be building two recommendation engines, one using Average Word2Vec and the other with TF-IDF Word2Vec word embeddings.\n",
        "\n",
        "Models creation\n",
        "We will split the descriptions into words, store it in a 'corpus', and use it for training our Word2vec model."
      ],
      "metadata": {
        "id": "kT9awksYhvML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the description into words\n",
        "\n",
        "corpus = []\n",
        "for words in df['Cleaned']:\n",
        "    corpus.append(words.split())"
      ],
      "metadata": {
        "id": "eE0ZNYf2hvn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.test.utils import common_texts\n",
        "from gensim.models import Word2Vec\n",
        "\n",
        "base_model = Word2Vec(sentences=corpus, vector_size=300, window=5, min_count=1, workers=4)\n",
        "base_model.train(corpus, total_examples=len(corpus), epochs=10)"
      ],
      "metadata": {
        "id": "8-6pULxJhykz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average Word2Vec\n",
        "We will create a function called vectors for generating average Word2Vec embeddings and storing them as a list called 'word_embeddings'."
      ],
      "metadata": {
        "id": "-1DU2Cofh441"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectors(model):\n",
        "\n",
        "    # Creating a list for storing the vectors ('Description' into vectors)\n",
        "    global word_embeddings\n",
        "    word_embeddings = []\n",
        "\n",
        "    # Reading the each 'Description'\n",
        "    for line in df['Cleaned']:\n",
        "        avgword2vec = None\n",
        "        count = 0\n",
        "        for word in line.split():\n",
        "            if word in model:\n",
        "                count += 1\n",
        "                if avgword2vec is None:\n",
        "                    avgword2vec = model[word]\n",
        "                else:\n",
        "                    avgword2vec = avgword2vec + model[word]\n",
        "\n",
        "        if avgword2vec is not None:\n",
        "            avgword2vec = avgword2vec / count\n",
        "            word_embeddings.append(avgword2vec)"
      ],
      "metadata": {
        "id": "OVFXNr4sh5Ua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 5 Recommendations using Average Word2vec"
      ],
      "metadata": {
        "id": "Wi8fE2muh8XM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommending the Top 5 similar movies\n",
        "def recommendations(movie):\n",
        "\n",
        "    # Calling the function vectors\n",
        "    vectors(fine_tuned_model.wv)\n",
        "\n",
        "    # Finding cosine similarity for the vectors\n",
        "    cosine_similarities = cosine_similarity(word_embeddings, word_embeddings)\n",
        "    print(\"similarity matrix\")\n",
        "    print(cosine_similarities)\n",
        "\n",
        "\n",
        "    # Taking the Title and Movie Image Link and store in new dataframe called 'movies'\n",
        "    movies = df[['Movie', 'ImgLink']]\n",
        "\n",
        "    # Reverse mapping of the index\n",
        "    indices = pd.Series(df.index, index = df['Movie']).drop_duplicates()\n",
        "\n",
        "    idx = indices[movie]\n",
        "    sim_scores = list(enumerate(cosine_similarities[idx]))\n",
        "    print()\n",
        "    print(\"sim_scores tuples\")\n",
        "    print(sim_scores)\n",
        "    sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)\n",
        "    print()\n",
        "    print(\"sorted sim_scores tuples\")\n",
        "    print(sim_scores)\n",
        "    sim_scores = sim_scores[1:6]\n",
        "    print()\n",
        "    print(\"first 5 movies (1 to 6 because the first is the movie itself)\")\n",
        "    print(sim_scores)\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "    recommend = movies.iloc[movie_indices]\n",
        "\n",
        "    for index, row in recommend.iterrows():\n",
        "\n",
        "        url = row['ImgLink']\n",
        "        try:\n",
        "          img = imread(url)\n",
        "          plt.figure()\n",
        "          plt.imshow(img)\n",
        "          plt.title(row['Movie'])\n",
        "          print(row['Movie'])\n",
        "        except:\n",
        "          print(f\"{row['Movie']} <-- Image not found\")\n",
        "\n"
      ],
      "metadata": {
        "id": "9dYeKWTGh8yR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF-IDF Word2Vec Model\n",
        "We will use the same corpus, with the only change being in the word embeddings."
      ],
      "metadata": {
        "id": "RRfPZCcKiCOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the TF-IDF model and calculating the TF-IDF score\n",
        "tfidf = TfidfVectorizer(analyzer = 'word', ngram_range = (1, 3), min_df = 5, stop_words = 'english')\n",
        "tfidf.fit(df['Cleaned'])\n",
        "\n",
        "# Getting the words from the TF-IDF model\n",
        "tfidf_list = dict(zip(tfidf.get_feature_names_out(), list(tfidf.idf_)))\n",
        "\n",
        "# TF-IDF words/column names\n",
        "tfidf_feature = tfidf.get_feature_names_out()"
      ],
      "metadata": {
        "id": "FlIeZD9niCoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building TF-IDF Word2vec Embeddings"
      ],
      "metadata": {
        "id": "eO5SlO2miEjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectors2(model):\n",
        "  global tfidf_vectors\n",
        "  # Storing the TFIDF Word2Vec embeddings\n",
        "  tfidf_vectors = []\n",
        "  line = 0\n",
        "\n",
        "  # For each 'Description'\n",
        "  for desc in corpus:\n",
        "\n",
        "      # Word vectors are of zero length (using 300 dimensions)\n",
        "      sent_vec = np.zeros(300)\n",
        "\n",
        "      # Number of words with a valid vector in the 'Description'\n",
        "      weight_sum =0;\n",
        "\n",
        "      # For each word in the 'Description'\n",
        "      for word in desc:\n",
        "          if word in model and word in tfidf_feature:\n",
        "              vec = model[word]\n",
        "              tf_idf = tfidf_list[word] * (desc.count(word) / len(desc))\n",
        "              sent_vec += (vec * tf_idf)\n",
        "              weight_sum += tf_idf\n",
        "      if weight_sum != 0:\n",
        "          sent_vec /= weight_sum\n",
        "      tfidf_vectors.append(sent_vec)\n",
        "      line += 1"
      ],
      "metadata": {
        "id": "8wxcjIrRiIkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 5 Recommendation using TF-IDF Word2vec"
      ],
      "metadata": {
        "id": "sem23asxiMQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Recommending top 5 similar movies\n",
        "def recommendations_2(movie):\n",
        "\n",
        "    ### CHANGE HERE THE MODEL YOU WANT TO USE\n",
        "    vectors2(fine_tuned_model.wv)\n",
        "\n",
        "    # Finding cosine similarity for the vectors\n",
        "    cosine_similarities = cosine_similarity(tfidf_vectors,  tfidf_vectors)\n",
        "    print(\"similarity matrix\")\n",
        "    print(cosine_similarities)\n",
        "\n",
        "    # Taking the Title and Image Link and store in new data frame called movies\n",
        "    movies = df[['Movie', 'ImgLink']]\n",
        "\n",
        "    # Reverse mapping of the index\n",
        "    indices = pd.Series(df.index, index = df['Movie']).drop_duplicates()\n",
        "\n",
        "    idx = indices[movie]\n",
        "    sim_scores = list(enumerate(cosine_similarities[idx]))\n",
        "    print()\n",
        "    print(\"sim_scores tuples\")\n",
        "    print(sim_scores)\n",
        "    sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)\n",
        "    print()\n",
        "    print(\"sorted sim_scores tuples\")\n",
        "    print(sim_scores)\n",
        "    sim_scores = sim_scores[1:6]\n",
        "    print()\n",
        "    print(\"first 5 movies (1 to 6 because the first is the movie itself)\")\n",
        "\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "    recommend = movies.iloc[movie_indices]\n",
        "\n",
        "    for index, row in recommend.iterrows():\n",
        "\n",
        "        url = row['ImgLink']\n",
        "        try:\n",
        "          img = imread(url)\n",
        "          plt.figure()\n",
        "          plt.imshow(img)\n",
        "          plt.title(row['Movie'])\n",
        "          print(row['Movie'])\n",
        "        except:\n",
        "          print(f\"{row['Movie']} <-- Image not found\")"
      ],
      "metadata": {
        "id": "6X8VrVQ1iM01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function that takes as input a list of integers and an argument ('o' or 'e', odd or even, respectively), and sums the elements at odd or even indices.\n",
        "Test the function with the list mylist = [1,2,3,4,5,6]"
      ],
      "metadata": {
        "id": "kFeRdFJoifqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sum_list_elems(inlist, idx='o'):\n",
        "  sumlist = []\n",
        "  if idx == 'o':\n",
        "    offset = 1\n",
        "  else:\n",
        "    offset = 0\n",
        "\n",
        "  for i in range(0, len(inlist)):\n",
        "    # print(f'i: {i}; inlist[{i}] = {inlist[i]}')\n",
        "    if idx == 'e':\n",
        "      if(i%2 == 0):\n",
        "        print(f'i: {i}; inlist[{i}] = {inlist[i]}')\n",
        "        sumlist.append(inlist[i])\n",
        "    else: # idx != 'o'\n",
        "      if(i%2 == 1):\n",
        "        print(f'i: {i}; inlist[{i}] = {inlist[i]}')\n",
        "        sumlist.append(inlist[i])\n",
        "\n",
        "  return sum(sumlist)\n",
        "\n",
        "# ##############################\n",
        "mylist = [1,2,3,4,5,6]\n",
        "\n",
        "print(f'sum_list_elems(mylist, \"o\") = {sum_list_elems(mylist, \"o\")}')\n",
        "print(f'sum_list_elems(mylist, \"e\") = {sum_list_elems(mylist, \"e\")}')"
      ],
      "metadata": {
        "id": "L0Hb3q0Jihjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function that takes a matrix as input and calculates the sum of all values in the matrix."
      ],
      "metadata": {
        "id": "s1EI9glTioEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sum_all_values(mymat):\n",
        "  sum = 0\n",
        "  for row in mymat:\n",
        "    sum += row.sum()\n",
        "  return sum\n",
        "\n",
        "# ##############################\n",
        "arr = np.arange(1, 11).reshape(5, 2)\n",
        "\n",
        "print(arr)\n",
        "print(f'sum_all_values(arr) = {sum_all_values(arr)}')"
      ],
      "metadata": {
        "id": "RN94mfVkitH6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Given the signature is_prime(num), write a function that takes an integer nof_primes and calculates the first nof_primes prime numbers."
      ],
      "metadata": {
        "id": "CXXnyUrxivCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_prime(num):\n",
        "\n",
        "  if num == 1:\n",
        "      return False\n",
        "  elif num > 1:\n",
        "    for i in range(2, num):\n",
        "      if (num % i) == 0:\n",
        "        return False\n",
        "  return True\n",
        "\n",
        "\n",
        "def find_first_primes(nof_primes):\n",
        "  done = False\n",
        "  primes = []\n",
        "  primes_count = 0\n",
        "  intval = 2\n",
        "\n",
        "  while not done:\n",
        "    if is_prime(intval):\n",
        "      primes.append(intval)\n",
        "      primes_count += 1\n",
        "      if primes_count == nof_primes:\n",
        "        done = True\n",
        "    intval += 1\n",
        "\n",
        "  return primes\n",
        "\n",
        "# ########################################\n",
        "\n",
        "print(find_first_primes(3300))"
      ],
      "metadata": {
        "id": "dIyFWRuDiwqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function that checks if a number n is a palindrome using the inversion of the corresponding string: the function should return True if n is a palindrome, and False otherwise. A palindrome means that the sequence of characters from left to right is equal to the sequence of characters from right to left."
      ],
      "metadata": {
        "id": "58kq-77Li1bi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_palin(intval):\n",
        "  astr = str(intval)\n",
        "  reversed = astr[::-1]\n",
        "  return astr == reversed\n",
        "\n",
        "\n",
        "# ####################################\n",
        "#\n",
        "print(f'check_palin(12321): {check_palin(12321)}')\n",
        "print(f'check_palin(123): {check_palin(123)}')"
      ],
      "metadata": {
        "id": "eIIOJI5ti19Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function that takes a file name as input: the function should extract the list of terms contained in the file, print the first 20 terms therein and return the top 20 most frequent tokens along with frequency counts."
      ],
      "metadata": {
        "id": "Q1KyDFehi3jG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_most_freq_terms(fname):\n",
        "  stopword = stopwords.words('english')\n",
        "  special_chars = string.punctuation\n",
        "\n",
        "  with open(fname, 'r') as f:\n",
        "    full_text = f.read().lower() # lowercasing\n",
        "    word_tokens = nltk.word_tokenize(full_text)\n",
        "\n",
        "    filtered_tokens = [word for word in word_tokens if word not in stopword and word not in special_chars]\n",
        "\n",
        "    print (f'word_tokens[:20]: {word_tokens[:20]}\\n')\n",
        "    return Counter(filtered_tokens).most_common(20)\n",
        "\n",
        "# ########################################\n",
        "\n",
        "file_name = 'moby_dick_melville.txt'\n",
        "print(f'get_most_freq_terms({file_name}): {get_most_freq_terms(file_name)}\\n')"
      ],
      "metadata": {
        "id": "R7whoQjbjCya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function that takes a term as input: the function must query WordNet and retrieve all synsets. The function must return, for each synset, the list of nouns present in the concatenation of description and examples."
      ],
      "metadata": {
        "id": "fASXaHAqjJZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_string_from_list(alist):\n",
        "  wholestring = \"\"\n",
        "  for el in alist:\n",
        "    wholestring += \" \"\n",
        "    wholestring += str(el)\n",
        "  return wholestring\n",
        "\n",
        "\n",
        "def get_nouns(instring):\n",
        "  word_tokens = nltk.word_tokenize(instring)\n",
        "  postagged_tokens = nltk.pos_tag(word_tokens)\n",
        "  nouns = [word[0] for word in postagged_tokens if 'NN' in word[1]]\n",
        "  _nouns = ''\n",
        "  for n in nouns:\n",
        "    _nouns += n\n",
        "    _nouns += ' '\n",
        "  return _nouns\n",
        "\n",
        "\n",
        "def get_nouns_from_signatures(term):\n",
        "  signatures = []\n",
        "  print(f'Exploring senses for term {term}')\n",
        "  count = 1\n",
        "  for ss in wn.synsets(term):\n",
        "    # print('\\n' + str(ss))\n",
        "    # print(ss.name(), ss.lemma_names())\n",
        "    # print('def : ' + ss.definition())\n",
        "    # print('ex : ' + str(ss.examples()))\n",
        "    # print()\n",
        "\n",
        "    str_signature = \"\"\n",
        "    str_signature += \" \"\n",
        "    str_signature += get_string_from_list(ss.lemma_names())\n",
        "    str_signature += \" \"\n",
        "    str_signature += ss.definition()\n",
        "    str_signature += \" \"\n",
        "    str_signature += get_string_from_list(ss.examples())\n",
        "\n",
        "    sig_nouns = get_nouns(str_signature)\n",
        "    sig_nouns = str(count) + \" \" + sig_nouns\n",
        "    # print(sig_nouns)\n",
        "    signatures.append(sig_nouns)\n",
        "    count += 1\n",
        "\n",
        "  print(signatures)\n",
        "\n",
        "get_nouns_from_signatures('bank')"
      ],
      "metadata": {
        "id": "FgbZ2TDMjJ0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function to train Word2Vec embeddings using the text8 corpus; the function must return the model; imports for handling W2V models"
      ],
      "metadata": {
        "id": "gyOfqrvZjV5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_W2V_model_on_text8():\n",
        "  corpus = gensim.downloader.load('text8')\n",
        "  model = Word2Vec(corpus)\n",
        "  return model\n",
        "\n",
        "\n",
        "# ########################################\n",
        "\n",
        "model = train_W2V_model_on_text8()"
      ],
      "metadata": {
        "id": "XLmDx7uijWU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function get_diff(model, term1, term2) that takes as input a model and two terms and returns the difference vector between the two input vectors; write another function print_first_dims(model, t1, t2) that takes as input a Word2Vec model and two terms: print_first_dims() must call the get_diff() function (passing model and both terms), receive the difference vector and print the first 20 dimensions of the input vector.\n",
        "Test the functions by feeding the first function with the strings 'industry' and 'loans', and feed the second function with the output of this."
      ],
      "metadata": {
        "id": "x3G7b0g3jevw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_diff(model, term1, term2):\n",
        "  vec1 = model.wv[term1]\n",
        "  vec2 = model.wv[term2]\n",
        "\n",
        "  return model.wv[term1] - model.wv[term2]\n",
        "\n",
        "def print_first_dims(model, t1, t2):\n",
        "  diff = get_diff(model, t1, t2)\n",
        "  print(diff[:20])\n",
        "\n",
        "\n",
        "# ########################################\n",
        "\n",
        "term1 = 'industry'\n",
        "term2 = 'loans'\n",
        "\n",
        "print_first_dims(model, term1, term2)"
      ],
      "metadata": {
        "id": "edC_JT1HjfMx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}